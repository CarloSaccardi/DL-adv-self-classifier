wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221117_190518-138egzkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-snowflake-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/first_runs
wandb: üöÄ View run at https://wandb.ai/self-classifier/first_runs/runs/138egzkn
wandb: ERROR Failed to sample metric: process no longer exists (pid=9931)
wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221122_130324-2gn9v7z8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-bush-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/first_runs
wandb: üöÄ View run at https://wandb.ai/self-classifier/first_runs/runs/2gn9v7z8
Namespace(arch='resnet18', batch_size=16, cls_size=[5], col_tau=0.05, config=(0.05, 0.4), cos=True, data='../imagenette2', dim=128, epochs=100, eps=1e-08, final_lr=0.0048, fixed_cls=False, global_crops_scale=(0.4, 1.0), gpu=0, hidden_dim=4096, lars=False, local_config='configs/config_first_run.yaml', local_crops_number=6, local_crops_scale=(0.05, 0.4), lr=4.8, momentum=0.9, no_leaky=False, num_cls=1, num_hidden=3, patch_size=16, pretrained=None, print_freq=16, queue_len=262144, resume='', row_tau=0.1, save_path='./saved/', seed=0, sgd=True, start_epoch=0, start_warmup=0.3, subset=0, use_amp=True, use_bn=True, wandb='first_runs', warmup_epochs=10, weight_decay=1e-06, **{'num-hidden': 2})
Model(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (mlp_head): MLPHead(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=4096, bias=True)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Linear(in_features=4096, out_features=4096, bias=True)
      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
      (6): Linear(in_features=4096, out_features=128, bias=True)
    )
  )
  (cls_0): Linear(in_features=128, out_features=5, bias=False)
)
##### USING THE GPU #####
Epoch: [0][  0/591]	Time  0.000 ( 0.758)	Data  0.616 ( 0.616)	Loss 1.7704e+00 (1.7704e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 16/591]	Time  0.000 ( 0.353)	Data  0.761 ( 0.557)	Loss 1.6158e+00 (1.7151e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 32/591]	Time  0.000 ( 0.345)	Data  0.541 ( 0.564)	Loss 1.5876e+00 (1.6543e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 48/591]	Time  0.000 ( 0.345)	Data  0.817 ( 0.572)	Loss 1.6289e+00 (1.6251e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 64/591]	Time  0.000 ( 0.347)	Data  0.732 ( 0.578)	Loss 1.5159e+00 (1.6087e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 80/591]	Time  0.000 ( 0.342)	Data  0.498 ( 0.571)	Loss 1.4717e+00 (1.5917e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][ 96/591]	Time  0.000 ( 0.338)	Data  0.549 ( 0.565)	Loss 1.4248e+00 (1.5746e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][112/591]	Time  0.000 ( 0.337)	Data  0.555 ( 0.564)	Loss 1.5921e+00 (1.5614e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][128/591]	Time  0.000 ( 0.336)	Data  0.550 ( 0.563)	Loss 1.5235e+00 (1.5532e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][144/591]	Time  0.000 ( 0.340)	Data  0.674 ( 0.571)	Loss 1.5870e+00 (1.5402e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][160/591]	Time  0.000 ( 0.339)	Data  0.488 ( 0.570)	Loss 1.4119e+00 (1.5288e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][176/591]	Time  0.000 ( 0.337)	Data  0.504 ( 0.567)	Loss 1.5131e+00 (1.5208e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][192/591]	Time  0.000 ( 0.336)	Data  0.545 ( 0.565)	Loss 1.4680e+00 (1.5158e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][208/591]	Time  0.000 ( 0.335)	Data  0.518 ( 0.563)	Loss 1.7066e+00 (1.5093e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][224/591]	Time  0.000 ( 0.334)	Data  0.523 ( 0.561)	Loss 1.4469e+00 (1.5055e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][240/591]	Time  0.000 ( 0.337)	Data  0.521 ( 0.567)	Loss 1.4178e+00 (1.5022e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][256/591]	Time  0.000 ( 0.336)	Data  0.535 ( 0.565)	Loss 1.5588e+00 (1.5001e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][272/591]	Time  0.000 ( 0.335)	Data  0.494 ( 0.564)	Loss 1.4362e+00 (1.4973e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][288/591]	Time  0.000 ( 0.334)	Data  0.546 ( 0.563)	Loss 1.4015e+00 (1.4961e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][304/591]	Time  0.000 ( 0.334)	Data  0.547 ( 0.563)	Loss 1.3414e+00 (1.4921e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][320/591]	Time  0.000 ( 0.336)	Data  0.533 ( 0.565)	Loss 1.5981e+00 (1.4915e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][336/591]	Time  0.000 ( 0.334)	Data  0.493 ( 0.563)	Loss 1.3321e+00 (1.4877e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][352/591]	Time  0.000 ( 0.334)	Data  0.497 ( 0.562)	Loss 1.5320e+00 (1.4862e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][368/591]	Time  0.000 ( 0.333)	Data  0.505 ( 0.561)	Loss 1.4946e+00 (1.4841e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][384/591]	Time  0.000 ( 0.333)	Data  0.567 ( 0.560)	Loss 1.5375e+00 (1.4805e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][400/591]	Time  0.000 ( 0.332)	Data  0.505 ( 0.559)	Loss 1.3084e+00 (1.4769e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][416/591]	Time  0.000 ( 0.333)	Data  0.516 ( 0.561)	Loss 1.4847e+00 (1.4760e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][432/591]	Time  0.000 ( 0.333)	Data  0.548 ( 0.561)	Loss 1.3047e+00 (1.4733e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][448/591]	Time  0.000 ( 0.333)	Data  0.595 ( 0.560)	Loss 1.6050e+00 (1.4721e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][464/591]	Time  0.000 ( 0.332)	Data  0.530 ( 0.560)	Loss 1.3711e+00 (1.4718e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][480/591]	Time  0.000 ( 0.332)	Data  0.485 ( 0.559)	Loss 1.5315e+00 (1.4700e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][496/591]	Time  0.000 ( 0.332)	Data  0.511 ( 0.560)	Loss 1.4041e+00 (1.4689e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][512/591]	Time  0.000 ( 0.334)	Data  0.563 ( 0.563)	Loss 1.4237e+00 (1.4669e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][528/591]	Time  0.000 ( 0.333)	Data  0.528 ( 0.562)	Loss 1.4364e+00 (1.4654e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][544/591]	Time  0.000 ( 0.333)	Data  0.533 ( 0.561)	Loss 1.5108e+00 (1.4646e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][560/591]	Time  0.000 ( 0.332)	Data  0.508 ( 0.560)	Loss 1.5069e+00 (1.4627e+00)	Acc@1   0.00 (  0.00)
Epoch: [0][576/591]	Time  0.000 ( 0.332)	Data  0.499 ( 0.559)	Loss 1.4868e+00 (1.4613e+00)	Acc@1   0.00 (  0.00)
##################################################
train_loss:  1.460361104931323
train_acc:  0
##################################################
Best model was saved.
Epoch: [1][  0/591]	Time  0.000 ( 0.410)	Data  0.711 ( 0.711)	Loss 1.3978e+00 (1.3978e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 16/591]	Time  0.000 ( 0.334)	Data  0.534 ( 0.565)	Loss 1.2446e+00 (1.3648e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 32/591]	Time  0.000 ( 0.332)	Data  0.599 ( 0.561)	Loss 1.4394e+00 (1.3814e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 48/591]	Time  0.000 ( 0.332)	Data  0.658 ( 0.561)	Loss 1.2375e+00 (1.3858e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 64/591]	Time  0.000 ( 0.329)	Data  0.507 ( 0.555)	Loss 1.4600e+00 (1.3810e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 80/591]	Time  0.000 ( 0.327)	Data  0.517 ( 0.552)	Loss 1.1868e+00 (1.3772e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][ 96/591]	Time  0.000 ( 0.331)	Data  0.477 ( 0.560)	Loss 1.4764e+00 (1.3788e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][112/591]	Time  0.000 ( 0.330)	Data  0.535 ( 0.558)	Loss 1.4036e+00 (1.3833e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][128/591]	Time  0.000 ( 0.329)	Data  0.534 ( 0.556)	Loss 1.2845e+00 (1.3843e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][144/591]	Time  0.000 ( 0.329)	Data  0.554 ( 0.555)	Loss 1.3444e+00 (1.3844e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][160/591]	Time  0.000 ( 0.330)	Data  0.562 ( 0.557)	Loss 1.3534e+00 (1.3868e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][176/591]	Time  0.000 ( 0.333)	Data  0.724 ( 0.563)	Loss 1.7064e+00 (1.3880e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][192/591]	Time  0.000 ( 0.332)	Data  0.518 ( 0.561)	Loss 1.4123e+00 (1.3921e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][208/591]	Time  0.000 ( 0.331)	Data  0.699 ( 0.559)	Loss 1.3766e+00 (1.3927e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][224/591]	Time  0.000 ( 0.331)	Data  0.613 ( 0.558)	Loss 1.3725e+00 (1.3907e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][240/591]	Time  0.000 ( 0.330)	Data  0.525 ( 0.558)	Loss 1.2402e+00 (1.3886e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][256/591]	Time  0.000 ( 0.330)	Data  0.542 ( 0.558)	Loss 1.4696e+00 (1.3927e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][272/591]	Time  0.000 ( 0.331)	Data  0.556 ( 0.560)	Loss 1.6496e+00 (1.3999e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][288/591]	Time  0.000 ( 0.331)	Data  0.530 ( 0.559)	Loss 1.5327e+00 (1.4012e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][304/591]	Time  0.000 ( 0.331)	Data  0.512 ( 0.559)	Loss 1.3834e+00 (1.4037e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][320/591]	Time  0.000 ( 0.330)	Data  0.514 ( 0.558)	Loss 1.4661e+00 (1.4050e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][336/591]	Time  0.000 ( 0.329)	Data  0.580 ( 0.556)	Loss 1.3909e+00 (1.4019e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][352/591]	Time  0.000 ( 0.329)	Data  0.494 ( 0.555)	Loss 1.5279e+00 (1.4033e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][368/591]	Time  0.000 ( 0.330)	Data  0.520 ( 0.557)	Loss 1.3538e+00 (1.4036e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][384/591]	Time  0.000 ( 0.330)	Data  0.525 ( 0.557)	Loss 1.3647e+00 (1.4020e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][400/591]	Time  0.000 ( 0.329)	Data  0.661 ( 0.556)	Loss 1.3734e+00 (1.3985e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][416/591]	Time  0.000 ( 0.329)	Data  0.537 ( 0.556)	Loss 1.3204e+00 (1.4003e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][432/591]	Time  0.000 ( 0.329)	Data  0.516 ( 0.555)	Loss 1.2252e+00 (1.3973e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][448/591]	Time  0.000 ( 0.330)	Data  0.987 ( 0.557)	Loss 1.4174e+00 (1.3975e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][464/591]	Time  0.000 ( 0.330)	Data  0.572 ( 0.557)	Loss 1.5085e+00 (1.3977e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][480/591]	Time  0.000 ( 0.330)	Data  0.507 ( 0.556)	Loss 1.4427e+00 (1.3978e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][496/591]	Time  0.000 ( 0.330)	Data  0.513 ( 0.558)	Loss 1.4429e+00 (1.3957e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][512/591]	Time  0.000 ( 0.330)	Data  0.533 ( 0.558)	Loss 1.3349e+00 (1.3953e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][528/591]	Time  0.000 ( 0.330)	Data  0.559 ( 0.558)	Loss 1.3701e+00 (1.3955e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][544/591]	Time  0.000 ( 0.331)	Data  0.565 ( 0.559)	Loss 1.3396e+00 (1.3955e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][560/591]	Time  0.000 ( 0.331)	Data  0.513 ( 0.559)	Loss 1.2750e+00 (1.3943e+00)	Acc@1   0.00 (  0.00)
Epoch: [1][576/591]	Time  0.000 ( 0.330)	Data  0.522 ( 0.558)	Loss 1.3654e+00 (1.3939e+00)	Acc@1   0.00 (  0.00)
##################################################
train_loss:  1.3929712532337144
train_acc:  0
##################################################
Best model was saved.
Epoch: [2][  0/591]	Time  0.000 ( 0.326)	Data  0.544 ( 0.544)	Loss 1.4491e+00 (1.4491e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 16/591]	Time  0.000 ( 0.327)	Data  0.517 ( 0.551)	Loss 1.5322e+00 (1.3633e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 32/591]	Time  0.000 ( 0.341)	Data  0.556 ( 0.577)	Loss 1.8037e+00 (1.3815e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 48/591]	Time  0.000 ( 0.335)	Data  0.562 ( 0.566)	Loss 1.4200e+00 (1.4029e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 64/591]	Time  0.000 ( 0.332)	Data  0.492 ( 0.560)	Loss 1.2712e+00 (1.3775e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 80/591]	Time  0.000 ( 0.331)	Data  0.552 ( 0.558)	Loss 1.2961e+00 (1.3769e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][ 96/591]	Time  0.000 ( 0.328)	Data  0.546 ( 0.554)	Loss 1.2656e+00 (1.3769e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][112/591]	Time  0.000 ( 0.329)	Data  0.599 ( 0.555)	Loss 1.3827e+00 (1.3733e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][128/591]	Time  0.000 ( 0.333)	Data  0.502 ( 0.563)	Loss 1.4561e+00 (1.3688e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][144/591]	Time  0.000 ( 0.334)	Data  0.512 ( 0.564)	Loss 1.3828e+00 (1.3645e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][160/591]	Time  0.000 ( 0.332)	Data  0.550 ( 0.561)	Loss 1.3781e+00 (1.3621e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][176/591]	Time  0.000 ( 0.332)	Data  0.593 ( 0.561)	Loss 1.4707e+00 (1.3730e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][192/591]	Time  0.000 ( 0.331)	Data  0.523 ( 0.559)	Loss 1.3958e+00 (1.3745e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][208/591]	Time  0.000 ( 0.330)	Data  0.817 ( 0.557)	Loss 1.4770e+00 (1.3747e+00)	Acc@1   0.00 (  0.00)
Epoch: [2][224/591]	Time  0.000 ( 0.331)	Data  0.527 ( 0.558)	Loss 1.2582e+00 (1.3722e+00)	Acc@1   0.00 (  0.00)wandb: ERROR Failed to sample metric: process no longer exists (pid=27790)
wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221122_133721-2o65t1dl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-frog-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/big_run
wandb: üöÄ View run at https://wandb.ai/self-classifier/big_run/runs/2o65t1dl
Namespace(arch='resnet18', batch_size=16, cls_size=[5], col_tau=0.05, config=(0.05, 0.4), cos=True, data='../imagenette2', dim=128, epochs=100, eps=1e-08, final_lr=0.0048, fixed_cls=False, global_crops_scale=(0.4, 1.0), gpu=0, hidden_dim=4096, lars=False, local_config='configs/config_first_run.yaml', local_crops_number=6, local_crops_scale=(0.05, 0.4), lr=4.8, momentum=0.9, no_leaky=False, num_cls=1, num_hidden=2, patch_size=16, pretrained=None, print_freq=16, queue_len=100, resume='', row_tau=0.1, save_path='./saved/', seed=0, sgd=True, start_epoch=0, start_warmup=0.3, subset=0, use_amp=True, use_bn=True, wandb='big_run', warmup_epochs=10, weight_decay=1e-06)
Model(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (mlp_head): MLPHead(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=4096, bias=True)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Linear(in_features=4096, out_features=128, bias=True)
    )
  )
  (cls_0): Linear(in_features=128, out_features=5, bias=False)
)
##### USING THE GPU #####
Epoch: [0][  0/591]	Time  1.465 ( 1.465)	Data  0.562 ( 0.562)	Loss 1.7429e+00 (1.7429e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 16/591]	Time  0.651 ( 0.706)	Data  0.552 ( 0.560)	Loss 1.6504e+00 (1.7454e+00)	Acc@1 12.500000 (10.625000)
Epoch: [0][ 32/591]	Time  0.676 ( 0.678)	Data  0.578 ( 0.555)	Loss 1.5831e+00 (1.6598e+00)	Acc@1 12.500000 (8.894231)
Epoch: [0][ 48/591]	Time  0.893 ( 0.680)	Data  0.795 ( 0.565)	Loss 1.4913e+00 (1.6256e+00)	Acc@1 12.500000 (8.482143)
Epoch: [0][ 64/591]	Time  0.690 ( 0.690)	Data  0.592 ( 0.578)	Loss 1.5058e+00 (1.6032e+00)	Acc@1 12.500000 (8.836206)
Epoch: [0][ 80/591]	Time  0.750 ( 0.684)	Data  0.652 ( 0.575)	Loss 1.5288e+00 (1.5844e+00)	Acc@1 12.500000 (10.304054)
Epoch: [0][ 96/591]	Time  0.754 ( 0.687)	Data  0.656 ( 0.580)	Loss 1.4516e+00 (1.5688e+00)	Acc@1 12.500000 (11.388889)
Epoch: [0][112/591]	Time  0.643 ( 0.683)	Data  0.545 ( 0.578)	Loss 1.5078e+00 (1.5617e+00)	Acc@1 6.250000 (12.264152)
Epoch: [0][128/591]	Time  0.876 ( 0.682)	Data  0.778 ( 0.577)	Loss 1.3776e+00 (1.5521e+00)	Acc@1 18.750000 (13.268442)
Epoch: [0][144/591]	Time  0.818 ( 0.685)	Data  0.720 ( 0.581)	Loss 1.6294e+00 (1.5449e+00)	Acc@1 31.250000 (13.315218)
Epoch: [0][160/591]	Time  0.647 ( 0.684)	Data  0.549 ( 0.580)	Loss 1.4004e+00 (1.5349e+00)	Acc@1 12.500000 (13.149350)
Epoch: [0][176/591]	Time  0.725 ( 0.682)	Data  0.626 ( 0.579)	Loss 1.2977e+00 (1.5251e+00)	Acc@1 12.500000 (13.382353)
Epoch: [0][192/591]	Time  0.621 ( 0.680)	Data  0.522 ( 0.577)	Loss 1.4263e+00 (1.5178e+00)	Acc@1 12.500000 (13.407258)
Epoch: [0][208/591]	Time  0.750 ( 0.680)	Data  0.648 ( 0.577)	Loss 1.3048e+00 (1.5131e+00)	Acc@1 0.000000 (13.211634)
Epoch: [0][224/591]	Time  0.642 ( 0.680)	Data  0.543 ( 0.578)	Loss 1.4884e+00 (1.5082e+00)	Acc@1 18.750000 (13.245412)
Epoch: [0][240/591]	Time  0.642 ( 0.683)	Data  0.543 ( 0.581)	Loss 1.4461e+00 (1.5033e+00)	Acc@1 6.250000 (13.381411)
Epoch: [0][256/591]	Time  0.661 ( 0.682)	Data  0.562 ( 0.580)	Loss 1.6261e+00 (1.4978e+00)	Acc@1 6.250000 (13.225000)
Epoch: [0][272/591]	Time  0.631 ( 0.680)	Data  0.532 ( 0.579)	Loss 1.4338e+00 (1.4927e+00)	Acc@1 18.750000 (13.298873)
Epoch: [0][288/591]	Time  0.588 ( 0.680)	Data  0.489 ( 0.578)	Loss 1.6118e+00 (1.4876e+00)	Acc@1 6.250000 (13.342198)
Epoch: [0][304/591]	Time  0.587 ( 0.677)	Data  0.489 ( 0.576)	Loss 1.2275e+00 (1.4823e+00)	Acc@1 25.000000 (13.296980)
Epoch: [0][320/591]	Time  0.928 ( 0.678)	Data  0.825 ( 0.577)	Loss 1.4932e+00 (1.4814e+00)	Acc@1 12.500000 (13.316083)
Epoch: [0][336/591]	Time  0.705 ( 0.678)	Data  0.606 ( 0.577)	Loss 1.4763e+00 (1.4770e+00)	Acc@1 25.000000 (13.295454)
Epoch: [0][352/591]	Time  0.635 ( 0.678)	Data  0.537 ( 0.577)	Loss 1.5018e+00 (1.4772e+00)	Acc@1 12.500000 (13.475433)
Epoch: [0][368/591]	Time  0.651 ( 0.677)	Data  0.553 ( 0.576)	Loss 1.5989e+00 (1.4733e+00)	Acc@1 6.250000 (13.622238)
Epoch: [0][384/591]	Time  0.613 ( 0.676)	Data  0.514 ( 0.575)	Loss 1.5264e+00 (1.4776e+00)	Acc@1 6.250000 (13.707010)
Epoch: [0][400/591]	Time  0.669 ( 0.674)	Data  0.572 ( 0.574)	Loss 1.6415e+00 (1.4798e+00)	Acc@1 12.500000 (13.689720)
Epoch: [0][416/591]	Time  0.636 ( 0.678)	Data  0.538 ( 0.577)	Loss 1.4370e+00 (1.4792e+00)	Acc@1 18.750000 (13.734756)
Epoch: [0][432/591]	Time  0.627 ( 0.677)	Data  0.528 ( 0.576)	Loss 1.2007e+00 (1.4747e+00)	Acc@1 12.500000 (13.849766)
Epoch: [0][448/591]	Time  0.633 ( 0.676)	Data  0.535 ( 0.575)	Loss 1.4134e+00 (1.4733e+00)	Acc@1 12.500000 (13.871607)
Epoch: [0][464/591]	Time  0.668 ( 0.675)	Data  0.570 ( 0.574)	Loss 1.3471e+00 (1.4711e+00)	Acc@1 12.500000 (13.796397)
Epoch: [0][480/591]	Time  0.618 ( 0.674)	Data  0.521 ( 0.573)	Loss 1.4720e+00 (1.4698e+00)	Acc@1 6.250000 (13.805379)
Epoch: [0][496/591]	Time  0.659 ( 0.673)	Data  0.561 ( 0.572)	Loss 1.5269e+00 (1.4684e+00)	Acc@1 12.500000 (13.903061)
Epoch: [0][512/591]	Time  0.629 ( 0.675)	Data  0.532 ( 0.574)	Loss 1.2953e+00 (1.4661e+00)	Acc@1 18.750000 (14.031621)
Epoch: [0][528/591]	Time  0.625 ( 0.673)	Data  0.527 ( 0.573)	Loss 1.3823e+00 (1.4638e+00)	Acc@1 18.750000 (14.128352)
Epoch: [0][544/591]	Time  0.705 ( 0.673)	Data  0.607 ( 0.573)	Loss 1.3699e+00 (1.4618e+00)	Acc@1 12.500000 (14.277416)
Epoch: [0][560/591]	Time  0.639 ( 0.673)	Data  0.540 ( 0.572)	Loss 1.4143e+00 (1.4609e+00)	Acc@1 6.250000 (14.293773)
Epoch: [0][576/591]	Time  0.669 ( 0.672)	Data  0.571 ( 0.572)	Loss 1.3215e+00 (1.4588e+00)	Acc@1 18.750000 (14.331141)
##################################################
train_loss:  1.4567811961101396
train_acc:  tensor(14.3193, device='cuda:0')
##################################################
Best model was saved.
Epoch: [1][  0/591]	Time  0.796 ( 0.796)	Data  0.698 ( 0.698)	Loss 1.2896e+00 (1.2896e+00)	Acc@1 31.250000 (31.250000)
Epoch: [1][ 16/591]	Time  0.597 ( 0.655)	Data  0.499 ( 0.557)	Loss 1.1821e+00 (1.3668e+00)	Acc@1 12.500000 (19.117647)
Epoch: [1][ 32/591]	Time  0.623 ( 0.651)	Data  0.525 ( 0.553)	Loss 1.2347e+00 (1.3677e+00)	Acc@1 25.000000 (18.750000)
Epoch: [1][ 48/591]	Time  0.667 ( 0.645)	Data  0.569 ( 0.547)	Loss 1.4280e+00 (1.3683e+00)	Acc@1 12.500000 (18.112244)
Epoch: [1][ 64/591]	Time  0.622 ( 0.644)	Data  0.524 ( 0.546)	Loss 1.5323e+00 (1.3647e+00)	Acc@1 0.000000 (16.923077)
Epoch: [1][ 80/591]	Time  0.859 ( 0.647)	Data  0.761 ( 0.549)	Loss 1.4191e+00 (1.3842e+00)	Acc@1 18.750000 (15.817902)
Epoch: [1][ 96/591]	Time  0.628 ( 0.660)	Data  0.530 ( 0.562)	Loss 1.3458e+00 (1.3851e+00)	Acc@1 25.000000 (15.399484)
Epoch: [1][112/591]	Time  0.619 ( 0.659)	Data  0.520 ( 0.561)	Loss 1.3119e+00 (1.3792e+00)	Acc@1 18.750000 (15.431416)
Epoch: [1][128/591]	Time  0.630 ( 0.657)	Data  0.532 ( 0.559)	Loss 1.4096e+00 (1.3753e+00)	Acc@1 18.750000 (15.261628)
Epoch: [1][144/591]	Time  0.649 ( 0.657)	Data  0.552 ( 0.558)	Loss 1.5521e+00 (1.3801e+00)	Acc@1 12.500000 (15.129311)
Epoch: [1][160/591]	Time  0.651 ( 0.657)	Data  0.553 ( 0.558)	Loss 1.4488e+00 (1.3749e+00)	Acc@1 18.750000 (15.372671)
Epoch: [1][176/591]	Time  0.650 ( 0.657)	Data  0.549 ( 0.558)	Loss 1.2068e+00 (1.3695e+00)	Acc@1 12.500000 (15.042373)
Epoch: [1][192/591]	Time  0.703 ( 0.662)	Data  0.604 ( 0.564)	Loss 1.1986e+00 (1.3634e+00)	Acc@1 12.500000 (15.058290)
Epoch: [1][208/591]	Time  0.594 ( 0.660)	Data  0.496 ( 0.561)	Loss 1.4100e+00 (1.3634e+00)	Acc@1 25.000000 (14.922248)
Epoch: [1][224/591]	Time  0.660 ( 0.658)	Data  0.562 ( 0.560)	Loss 1.2488e+00 (1.3669e+00)	Acc@1 18.750000 (14.944445)
Epoch: [1][240/591]	Time  0.673 ( 0.658)	Data  0.575 ( 0.559)	Loss 1.3477e+00 (1.3684e+00)	Acc@1 6.250000 (15.067429)
Epoch: [1][256/591]	Time  0.644 ( 0.658)	Data  0.546 ( 0.560)	Loss 1.3680e+00 (1.3690e+00)	Acc@1 12.500000 (15.029182)
Epoch: [1][272/591]	Time  0.821 ( 0.663)	Data  0.724 ( 0.564)	Loss 1.2394e+00 (1.3695e+00)	Acc@1 12.500000 (14.949634)
Epoch: [1][288/591]	Time  0.685 ( 0.662)	Data  0.587 ( 0.564)	Loss 1.2819e+00 (1.3693e+00)	Acc@1 18.750000 (15.138409)
Epoch: [1][304/591]	Time  0.685 ( 0.661)	Data  0.587 ( 0.563)	Loss 1.3747e+00 (1.3694e+00)	Acc@1 31.250000 (15.409836)
Epoch: [1][320/591]	Time  0.724 ( 0.661)	Data  0.626 ( 0.563)	Loss 1.3116e+00 (1.3707e+00)	Acc@1 0.000000 (15.537383)
Epoch: [1][336/591]	Time  0.630 ( 0.660)	Data  0.532 ( 0.562)	Loss 1.2983e+00 (1.3702e+00)	Acc@1 12.500000 (15.727003)
Epoch: [1][352/591]	Time  0.722 ( 0.661)	Data  0.625 ( 0.563)	Loss 1.6023e+00 (1.3678e+00)	Acc@1 25.000000 (15.686969)
Epoch: [1][368/591]	Time  0.587 ( 0.664)	Data  0.489 ( 0.566)	Loss 1.4540e+00 (1.3677e+00)	Acc@1 0.000000 (15.599594)
Epoch: [1][384/591]	Time  0.676 ( 0.664)	Data  0.578 ( 0.566)	Loss 1.3201e+00 (1.3654e+00)	Acc@1 6.250000 (15.487013)
Epoch: [1][400/591]	Time  0.610 ( 0.663)	Data  0.512 ( 0.565)	Loss 1.1916e+00 (1.3627e+00)	Acc@1 18.750000 (15.476933)
Epoch: [1][416/591]	Time  0.631 ( 0.662)	Data  0.533 ( 0.564)	Loss 1.2747e+00 (1.3577e+00)	Acc@1 18.750000 (15.662471)
Epoch: [1][432/591]	Time  0.898 ( 0.664)	Data  0.800 ( 0.566)	Loss 1.3836e+00 (1.3566e+00)	Acc@1 6.250000 (15.646651)
Epoch: [1][448/591]	Time  1.102 ( 0.666)	Data  0.982 ( 0.568)	Loss 1.4721e+00 (1.3571e+00)	Acc@1 6.250000 (15.645880)
Epoch: [1][464/591]	Time  0.658 ( 0.666)	Data  0.560 ( 0.568)	Loss 1.3865e+00 (1.3580e+00)	Acc@1 12.500000 (15.739247)
Epoch: [1][480/591]	Time  0.632 ( 0.667)	Data  0.534 ( 0.568)	Loss 1.3451e+00 (1.3574e+00)	Acc@1 37.500000 (15.735447)
Epoch: [1][496/591]	Time  0.650 ( 0.666)	Data  0.552 ( 0.567)	Loss 1.6461e+00 (1.3564e+00)	Acc@1 18.750000 (15.857645)
Epoch: [1][512/591]	Time  0.679 ( 0.666)	Data  0.581 ( 0.567)	Loss 1.4678e+00 (1.3571e+00)	Acc@1 12.500000 (15.935673)
Epoch: [1][528/591]	Time  0.660 ( 0.666)	Data  0.562 ( 0.568)	Loss 1.3501e+00 (1.3561e+00)	Acc@1 25.000000 (16.032610)
Epoch: [1][544/591]	Time  0.660 ( 0.668)	Data  0.562 ( 0.570)	Loss 1.2196e+00 (1.3548e+00)	Acc@1 18.750000 (15.986238)
Epoch: [1][560/591]	Time  0.631 ( 0.667)	Data  0.532 ( 0.569)	Loss 1.1556e+00 (1.3552e+00)	Acc@1 18.750000 (15.964794)
Epoch: [1][576/591]	Time  0.588 ( 0.667)	Data  0.491 ( 0.569)	Loss 1.1804e+00 (1.3535e+00)	Acc@1 25.000000 (16.020365)
##################################################
train_loss:  1.3514923216324368
train_acc:  tensor(16.0216, device='cuda:0')
##################################################
Best model was saved.
Epoch: [2][  0/591]	Time  0.615 ( 0.615)	Data  0.510 ( 0.510)	Loss 1.1158e+00 (1.1158e+00)	Acc@1 25.000000 (25.000000)
Epoch: [2][ 16/591]	Time  0.631 ( 0.646)	Data  0.533 ( 0.546)	Loss 1.1235e+00 (1.2882e+00)	Acc@1 18.750000 (16.911764)
Epoch: [2][ 32/591]	Time  0.781 ( 0.661)	Data  0.675 ( 0.562)	Loss 1.4514e+00 (1.2998e+00)	Acc@1 6.250000 (15.909091)
Epoch: [2][ 48/591]	Time  0.646 ( 0.681)	Data  0.548 ( 0.582)	Loss 1.3929e+00 (1.3004e+00)	Acc@1 6.250000 (16.709183)
Epoch: [2][ 64/591]	Time  0.639 ( 0.671)	Data  0.541 ( 0.572)	Loss 1.3596e+00 (1.3234e+00)	Acc@1 6.250000 (16.057692)
Epoch: [2][ 80/591]	Time  0.718 ( 0.671)	Data  0.620 ( 0.572)	Loss 1.4195e+00 (1.3316e+00)	Acc@1 25.000000 (16.512346)
Epoch: [2][ 96/591]	Time  0.626 ( 0.667)	Data  0.529 ( 0.568)	Loss 1.2753e+00 (1.3245e+00)	Acc@1 6.250000 (16.559278)
Epoch: [2][112/591]	Time  0.621 ( 0.665)	Data  0.523 ( 0.566)	Loss 1.2473e+00 (1.3345e+00)	Acc@1 31.250000 (15.818584)
Epoch: [2][128/591]	Time  0.619 ( 0.675)	Data  0.521 ( 0.576)	Loss 1.2936e+00 (1.3389e+00)	Acc@1 12.500000 (15.939922)
Epoch: [2][144/591]	Time  0.693 ( 0.676)	Data  0.595 ( 0.577)	Loss 1.2987e+00 (1.3316e+00)	Acc@1 25.000000 (16.034483)
Epoch: [2][160/591]	Time  0.611 ( 0.673)	Data  0.513 ( 0.574)	Loss 1.1583e+00 (1.3319e+00)	Acc@1 6.250000 (16.110249)
Epoch: [2][176/591]	Time  0.649 ( 0.672)	Data  0.551 ( 0.573)	Loss 1.5343e+00 (1.3245e+00)	Acc@1 0.000000 (16.137005)
Epoch: [2][192/591]	Time  0.865 ( 0.673)	Data  0.767 ( 0.575)	Loss 1.4344e+00 (1.3204e+00)	Acc@1 31.250000 (16.386009)
Epoch: [2][208/591]	Time  0.660 ( 0.671)	Data  0.562 ( 0.572)	Loss 1.6628e+00 (1.3206e+00)	Acc@1 25.000000 (16.267942)
Epoch: [2][224/591]	Time  0.687 ( 0.674)	Data  0.589 ( 0.575)	Loss 1.3780e+00 (1.3196e+00)	Acc@1 31.250000 (16.888889)
Epoch: [2][240/591]	Time  0.690 ( 0.674)	Data  0.590 ( 0.575)	Loss 1.2950e+00 (1.3188e+00)	Acc@1 18.750000 (16.882780)
Epoch: [2][256/591]	Time  0.643 ( 0.673)	Data  0.545 ( 0.574)	Loss 1.4934e+00 (1.3164e+00)	Acc@1 31.250000 (16.877432)
Epoch: [2][272/591]	Time  0.686 ( 0.672)	Data  0.588 ( 0.573)	Loss 1.0138e+00 (1.3187e+00)	Acc@1 18.750000 (17.032967)
Epoch: [2][288/591]	Time  0.669 ( 0.671)	Data  0.570 ( 0.572)	Loss 1.3121e+00 (1.3163e+00)	Acc@1 18.750000 (16.868513)
Epoch: [2][304/591]	Time  0.672 ( 0.674)	Data  0.574 ( 0.575)	Loss 1.5359e+00 (1.3131e+00)	Acc@1 37.500000 (16.926229)
Epoch: [2][320/591]	Time  0.611 ( 0.673)	Data  0.514 ( 0.574)	Loss 1.1106e+00 (1.3126e+00)	Acc@1 31.250000 (17.114485)
Epoch: [2][336/591]	Time  0.655 ( 0.672)	Data  0.557 ( 0.574)	Loss 1.3299e+00 (1.3156e+00)	Acc@1 25.000000 (17.099407)
Epoch: [2][352/591]	Time  0.671 ( 0.671)	Data  0.572 ( 0.573)	Loss 1.5299e+00 (1.3203e+00)	Acc@1 6.250000 (17.085693)
Epoch: [2][368/591]	Time  0.613 ( 0.671)	Data  0.514 ( 0.572)	Loss 1.3835e+00 (1.3217e+00)	Acc@1 18.750000 (17.073172)
Epoch: [2][384/591]	Time  0.596 ( 0.670)	Data  0.498 ( 0.571)	Loss 1.2047e+00 (1.3216e+00)	Acc@1 18.750000 (17.061687)
Epoch: [2][400/591]	Time  0.646 ( 0.673)	Data  0.548 ( 0.574)	Loss 1.1116e+00 (1.3198e+00)	Acc@1 31.250000 (17.331671)
Epoch: [2][416/591]	Time  0.646 ( 0.671)	Data  0.549 ( 0.573)	Loss 1.2224e+00 (1.3173e+00)	Acc@1 25.000000 (17.236212)
Epoch: [2][432/591]	Time  0.623 ( 0.670)	Data  0.525 ( 0.572)	Loss 1.2005e+00 (1.3167e+00)	Acc@1 18.750000 (17.479792)
Epoch: [2][448/591]	Time  0.627 ( 0.672)	Data  0.529 ( 0.573)	Loss 1.4259e+00 (1.3178e+00)	Acc@1 50.000000 (17.608576)
Epoch: [2][464/591]	Time  0.663 ( 0.671)	Data  0.565 ( 0.573)	Loss 1.4237e+00 (1.3185e+00)	Acc@1 25.000000 (17.540323)
Epoch: [2][480/591]	Time  1.008 ( 0.671)	Data  0.887 ( 0.572)	Loss 1.1030e+00 (1.3171e+00)	Acc@1 31.250000 (17.684511)
Epoch: [2][496/591]	Time  0.608 ( 0.671)	Data  0.510 ( 0.573)	Loss 1.4672e+00 (1.3178e+00)	Acc@1 12.500000 (17.706236)
Epoch: [2][512/591]	Time  0.624 ( 0.670)	Data  0.526 ( 0.571)	Loss 1.0298e+00 (1.3163e+00)	Acc@1 25.000000 (17.750975)
Epoch: [2][528/591]	Time  0.613 ( 0.669)	Data  0.515 ( 0.571)	Loss 1.3674e+00 (1.3155e+00)	Acc@1 12.500000 (17.934784)
Epoch: [2][544/591]	Time  0.637 ( 0.670)	Data  0.537 ( 0.572)	Loss 1.1757e+00 (1.3159e+00)	Acc@1 18.750000 (18.061926)
Epoch: [2][560/591]	Time  0.676 ( 0.670)	Data  0.578 ( 0.572)	Loss 1.2745e+00 (1.3166e+00)	Acc@1 6.250000 (18.048128)
Epoch: [2][576/591]	Time  0.629 ( 0.672)	Data  0.530 ( 0.573)	Loss 1.1216e+00 (1.3156e+00)	Acc@1 31.250000 (18.067591)
##################################################
train_loss:  1.3144950414873824
train_acc:  tensor(18.1049, device='cuda:0')
##################################################
Best model was saved.
Epoch: [3][  0/591]	Time  0.686 ( 0.686)	Data  0.588 ( 0.588)	Loss 1.1970e+00 (1.1970e+00)	Acc@1 31.250000 (31.250000)
Epoch: [3][ 16/591]	Time  0.618 ( 0.640)	Data  0.519 ( 0.542)	Loss 1.5339e+00 (1.2849e+00)	Acc@1 12.500000 (20.955883)
Epoch: [3][ 32/591]	Time  0.646 ( 0.653)	Data  0.548 ( 0.555)	Loss 1.3019e+00 (1.3134e+00)	Acc@1 25.000000 (19.318182)
Epoch: [3][ 48/591]	Time  0.676 ( 0.653)	Data  0.578 ( 0.554)	Loss 1.1859e+00 (1.3052e+00)	Acc@1 12.500000 (19.387754)
Epoch: [3][ 64/591]	Time  0.616 ( 0.657)	Data  0.517 ( 0.558)	Loss 1.1232e+00 (1.2834e+00)	Acc@1 31.250000 (20.384615)
Epoch: [3][ 80/591]	Time  0.623 ( 0.669)	Data  0.525 ( 0.570)	Loss 1.2736e+00 (1.2914e+00)	Acc@1 12.500000 (19.907408)
Epoch: [3][ 96/591]	Time  0.642 ( 0.665)	Data  0.543 ( 0.567)	Loss 9.5883e-01 (1.2741e+00)	Acc@1 31.250000 (20.489691)
Epoch: [3][112/591]	Time  0.643 ( 0.661)	Data  0.544 ( 0.562)	Loss 1.4346e+00 (1.2657e+00)	Acc@1 18.750000 (20.409292)
Epoch: [3][128/591]	Time  0.565 ( 0.659)	Data  0.466 ( 0.560)	Loss 1.1558e+00 (1.2637e+00)	Acc@1 31.250000 (20.300388)
Epoch: [3][144/591]	Time  0.603 ( 0.659)	Data  0.505 ( 0.561)	Loss 1.2913e+00 (1.2659e+00)	Acc@1 25.000000 (20.732759)
Epoch: [3][160/591]	Time  0.668 ( 0.665)	Data  0.570 ( 0.567)	Loss 1.1754e+00 (1.2625e+00)	Acc@1 25.000000 (20.807453)
Epoch: [3][176/591]	Time  0.610 ( 0.663)	Data  0.511 ( 0.565)	Loss 1.3478e+00 (1.2628e+00)	Acc@1 18.750000 (20.409605)
Epoch: [3][192/591]	Time  0.629 ( 0.662)	Data  0.531 ( 0.563)	Loss 1.2108e+00 (1.2631e+00)	Acc@1 31.250000 (19.980570)
Epoch: [3][208/591]	Time  0.656 ( 0.661)	Data  0.558 ( 0.562)	Loss 1.3650e+00 (1.2671e+00)	Acc@1 12.500000 (20.005980)
Epoch: [3][224/591]	Time  0.627 ( 0.660)	Data  0.529 ( 0.561)	Loss 9.6800e-01 (1.2655e+00)	Acc@1 18.750000 (20.055555)
Epoch: [3][240/591]	Time  1.064 ( 0.660)	Data  0.966 ( 0.562)	Loss 9.4722e-01 (1.2626e+00)	Acc@1 37.500000 (20.020748)
Epoch: [3][256/591]	Time  0.612 ( 0.663)	Data  0.514 ( 0.565)	Loss 1.1700e+00 (1.2582e+00)	Acc@1 12.500000 (20.184824)
Epoch: [3][272/591]	Time  0.659 ( 0.664)	Data  0.561 ( 0.566)	Loss 1.1794e+00 (1.2580e+00)	Acc@1 25.000000 (20.306776)
Epoch: [3][288/591]	Time  0.609 ( 0.662)	Data  0.511 ( 0.563)	Loss 1.1105e+00 (1.2580e+00)	Acc@1 31.250000 (20.328720)
Epoch: [3][304/591]	Time  0.629 ( 0.661)	Data  0.531 ( 0.563)	Loss 1.3741e+00 (1.2558e+00)	Acc@1 6.250000 (20.389345)
Epoch: [3][320/591]	Time  0.599 ( 0.661)	Data  0.501 ( 0.562)	Loss 1.1549e+00 (1.2528e+00)	Acc@1 12.500000 (20.288162)
Epoch: [3][336/591]	Time  0.668 ( 0.660)	Data  0.569 ( 0.561)	Loss 1.2066e+00 (1.2474e+00)	Acc@1 0.000000 (20.419140)
Epoch: [3][352/591]	Time  0.669 ( 0.663)	Data  0.571 ( 0.565)	Loss 1.2407e+00 (1.2475e+00)	Acc@1 12.500000 (20.343485)
Epoch: [3][368/591]	Time  0.664 ( 0.662)	Data  0.566 ( 0.564)	Loss 1.2415e+00 (1.2465e+00)	Acc@1 18.750000 (20.359079)
Epoch: [3][384/591]	Time  0.605 ( 0.662)	Data  0.507 ( 0.563)	Loss 1.0410e+00 (1.2440e+00)	Acc@1 18.750000 (20.438311)
Epoch: [3][400/591]	Time  0.635 ( 0.660)	Data  0.536 ( 0.562)	Loss 1.4266e+00 (1.2416e+00)	Acc@1 25.000000 (20.464464)
Epoch: [3][416/591]	Time  0.583 ( 0.661)	Data  0.486 ( 0.563)	Loss 1.1708e+00 (1.2415e+00)	Acc@1 6.250000 (20.218826)
Epoch: [3][432/591]	Time  0.631 ( 0.664)	Data  0.533 ( 0.565)	Loss 1.2414e+00 (1.2398e+00)	Acc@1 37.500000 (20.395496)
Epoch: [3][448/591]	Time  0.624 ( 0.665)	Data  0.526 ( 0.567)	Loss 1.2532e+00 (1.2373e+00)	Acc@1 37.500000 (20.559578)
Epoch: [3][464/591]	Time  0.593 ( 0.665)	Data  0.496 ( 0.566)	Loss 1.2239e+00 (1.2357e+00)	Acc@1 25.000000 (20.483871)
Epoch: [3][480/591]	Time  0.586 ( 0.664)	Data  0.488 ( 0.566)	Loss 1.1769e+00 (1.2352e+00)	Acc@1 12.500000 (20.543139)
Epoch: [3][496/591]	Time  0.715 ( 0.663)	Data  0.617 ( 0.565)	Loss 1.2435e+00 (1.2340e+00)	Acc@1 6.250000 (20.560865)
Epoch: [3][512/591]	Time  0.625 ( 0.665)	Data  0.527 ( 0.567)	Loss 1.2894e+00 (1.2341e+00)	Acc@1 18.750000 (20.528753)
Epoch: [3][528/591]	Time  0.620 ( 0.668)	Data  0.522 ( 0.569)	Loss 1.4149e+00 (1.2312e+00)	Acc@1 18.750000 (20.498583)
Epoch: [3][544/591]	Time  0.552 ( 0.667)	Data  0.455 ( 0.569)	Loss 1.0504e+00 (1.2299e+00)	Acc@1 18.750000 (20.527523)
Epoch: [3][560/591]	Time  0.673 ( 0.667)	Data  0.576 ( 0.568)	Loss 1.2357e+00 (1.2288e+00)	Acc@1 12.500000 (20.387699)
Epoch: [3][576/591]	Time  0.680 ( 0.666)	Data  0.582 ( 0.568)	Loss 1.0777e+00 (1.2249e+00)	Acc@1 12.500000 (20.363951)
##################################################
train_loss:  1.2240267800397275
train_acc:  tensor(20.3997, device='cuda:0')
##################################################
Best model was saved.
Epoch: [4][  0/591]	Time  0.642 ( 0.642)	Data  0.544 ( 0.544)	Loss 1.1998e+00 (1.1998e+00)	Acc@1 37.500000 (37.500000)
Epoch: [4][ 16/591]	Time  0.662 ( 0.730)	Data  0.563 ( 0.630)	Loss 9.5957e-01 (1.1738e+00)	Acc@1 31.250000 (26.102942)
Epoch: [4][ 32/591]	Time  0.614 ( 0.699)	Data  0.516 ( 0.601)	Loss 1.0999e+00 (1.1713e+00)	Acc@1 12.500000 (23.863638)
Epoch: [4][ 48/591]	Time  0.618 ( 0.677)	Data  0.520 ( 0.578)	Loss 1.2990e+00 (1.1479e+00)	Acc@1 31.250000 (23.341837)
Epoch: [4][ 64/591]	Time  0.587 ( 0.666)	Data  0.489 ( 0.568)	Loss 9.9209e-01 (1.1474e+00)	Acc@1 12.500000 (23.173077)
Epoch: [4][ 80/591]	Time  0.599 ( 0.659)	Data  0.502 ( 0.561)	Loss 1.3248e+00 (1.1584e+00)	Acc@1 31.250000 (22.530865)
Epoch: [4][ 96/591]	Time  0.598 ( 0.655)	Data  0.499 ( 0.557)	Loss 1.2298e+00 (1.1680e+00)	Acc@1 25.000000 (22.551546)
Epoch: [4][112/591]	Time  0.634 ( 0.664)	Data  0.535 ( 0.565)	Loss 1.0883e+00 (1.1674e+00)	Acc@1 25.000000 (22.676991)
Epoch: [4][128/591]	Time  0.821 ( 0.662)	Data  0.723 ( 0.564)	Loss 1.2604e+00 (1.1587e+00)	Acc@1 18.750000 (22.480619)
Epoch: [4][144/591]	Time  0.626 ( 0.664)	Data  0.528 ( 0.565)	Loss 1.3008e+00 (1.1608e+00)	Acc@1 6.250000 (22.543104)
Epoch: [4][160/591]	Time  0.670 ( 0.663)	Data  0.572 ( 0.565)	Loss 1.3790e+00 (1.1681e+00)	Acc@1 25.000000 (22.437889)
Epoch: [4][176/591]	Time  0.617 ( 0.661)	Data  0.519 ( 0.563)	Loss 1.0754e+00 (1.1708e+00)	Acc@1 25.000000 (22.669491)
Epoch: [4][192/591]	Time  0.658 ( 0.662)	Data  0.560 ( 0.563)	Loss 1.3289e+00 (1.1769e+00)	Acc@1 18.750000 (22.636009)
Epoch: [4][208/591]	Time  0.610 ( 0.669)	Data  0.512 ( 0.570)	Loss 1.2249e+00 (1.1781e+00)	Acc@1 12.500000 (22.547846)
Epoch: [4][224/591]	Time  0.901 ( 0.668)	Data  0.804 ( 0.569)	Loss 1.2793e+00 (1.1769e+00)	Acc@1 6.250000 (22.861113)
Epoch: [4][240/591]	Time  0.600 ( 0.666)	Data  0.502 ( 0.567)	Loss 1.0944e+00 (1.1741e+00)	Acc@1 25.000000 (22.821577)
Epoch: [4][256/591]	Time  0.600 ( 0.664)	Data  0.502 ( 0.566)	Loss 1.1543e+00 (1.1708e+00)	Acc@1 25.000000 (22.786964)
Epoch: [4][272/591]	Time  0.626 ( 0.663)	Data  0.528 ( 0.565)	Loss 1.0397e+00 (1.1720e+00)	Acc@1 18.750000 (22.756411)
Epoch: [4][288/591]	Time  0.640 ( 0.666)	Data  0.542 ( 0.568)	Loss 1.2676e+00 (1.1717e+00)	Acc@1 6.250000 (22.577856)
Epoch: [4][304/591]	Time  0.656 ( 0.665)	Data  0.557 ( 0.566)	Loss 1.3567e+00 (1.1712e+00)	Acc@1 18.750000 (22.540983)
Epoch: [4][320/591]	Time  0.654 ( 0.663)	Data  0.556 ( 0.565)	Loss 9.9394e-01 (1.1721e+00)	Acc@1 37.500000 (22.566198)
Epoch: [4][336/591]	Time  0.635 ( 0.664)	Data  0.537 ( 0.565)	Loss 9.7068e-01 (1.1726e+00)	Acc@1 18.750000 (22.533382)
Epoch: [4][352/591]	Time  0.745 ( 0.664)	Data  0.647 ( 0.566)	Loss 1.1951e+00 (1.1727e+00)	Acc@1 43.750000 (22.769121)
Epoch: [4][368/591]	Time  0.651 ( 0.664)	Data  0.553 ( 0.565)	Loss 1.2374e+00 (1.1736e+00)	Acc@1 6.250000 (22.730352)
Epoch: [4][384/591]	Time  0.638 ( 0.666)	Data  0.540 ( 0.567)	Loss 1.0957e+00 (1.1718e+00)	Acc@1 18.750000 (22.629869)
Epoch: [4][400/591]	Time  0.647 ( 0.665)	Data  0.549 ( 0.567)	Loss 1.1012e+00 (1.1702e+00)	Acc@1 62.500000 (22.864714)
Epoch: [4][416/591]	Time  0.639 ( 0.664)	Data  0.541 ( 0.565)	Loss 1.1141e+00 (1.1711e+00)	Acc@1 25.000000 (22.661871)
Epoch: [4][432/591]	Time  0.584 ( 0.663)	Data  0.487 ( 0.565)	Loss 1.3404e+00 (1.1674e+00)	Acc@1 31.250000 (22.704966)
Epoch: [4][448/591]	Time  0.630 ( 0.662)	Data  0.532 ( 0.564)	Loss 1.1676e+00 (1.1682e+00)	Acc@1 31.250000 (22.744989)
Epoch: [4][464/591]	Time  0.578 ( 0.662)	Data  0.480 ( 0.563)	Loss 9.7689e-01 (1.1662e+00)	Acc@1 6.250000 (22.580647)
Epoch: [4][480/591]	Time  0.647 ( 0.663)	Data  0.550 ( 0.564)	Loss 1.0897e+00 (1.1667e+00)	Acc@1 43.750000 (22.609148)
Epoch: [4][496/591]	Time  0.621 ( 0.662)	Data  0.524 ( 0.564)	Loss 1.0800e+00 (1.1673e+00)	Acc@1 37.500000 (22.585512)
Epoch: [4][512/591]	Time  0.645 ( 0.661)	Data  0.548 ( 0.562)	Loss 1.2731e+00 (1.1669e+00)	Acc@1 18.750000 (22.563353)
Epoch: [4][528/591]	Time  0.850 ( 0.660)	Data  0.752 ( 0.562)	Loss 1.2465e+00 (1.1663e+00)	Acc@1 37.500000 (22.637053)
Epoch: [4][544/591]	Time  0.602 ( 0.659)	Data  0.505 ( 0.561)	Loss 1.1846e+00 (1.1647e+00)	Acc@1 18.750000 (22.660551)
Epoch: [4][560/591]	Time  0.997 ( 0.660)	Data  0.878 ( 0.561)	Loss 1.3788e+00 (1.1632e+00)	Acc@1 18.750000 (22.727272)
Epoch: [4][576/591]	Time  0.587 ( 0.660)	Data  0.490 ( 0.562)	Loss 1.1226e+00 (1.1620e+00)	Acc@1 18.750000 (22.660313)
##################################################
train_loss:  1.1591841857848837
train_acc:  tensor(22.8638, device='cuda:0')
##################################################
Best model was saved.
Epoch: [5][  0/591]	Time  0.677 ( 0.677)	Data  0.580 ( 0.580)	Loss 1.4234e+00 (1.4234e+00)	Acc@1 25.000000 (25.000000)
Epoch: [5][ 16/591]	Time  0.743 ( 0.679)	Data  0.646 ( 0.581)	Loss 1.1134e+00 (1.1153e+00)	Acc@1 6.250000 (21.323530)
Epoch: [5][ 32/591]	Time  0.678 ( 0.666)	Data  0.580 ( 0.569)	Loss 9.7850e-01 (1.0998e+00)	Acc@1 31.250000 (23.295456)
Epoch: [5][ 48/591]	Time  0.673 ( 0.658)	Data  0.574 ( 0.560)	Loss 1.0041e+00 (1.1166e+00)	Acc@1 25.000000 (23.214285)
Epoch: [5][ 64/591]	Time  0.617 ( 0.691)	Data  0.520 ( 0.592)	Loss 1.2165e+00 (1.1211e+00)	Acc@1 25.000000 (21.730770)
Epoch: [5][ 80/591]	Time  0.630 ( 0.686)	Data  0.532 ( 0.588)	Loss 1.0904e+00 (1.1458e+00)	Acc@1 31.250000 (22.376543)
Epoch: [5][ 96/591]	Time  0.654 ( 0.681)	Data  0.557 ( 0.583)	Loss 1.0577e+00 (1.1471e+00)	Acc@1 18.750000 (22.229382)
Epoch: [5][112/591]	Time  0.616 ( 0.679)	Data  0.518 ( 0.581)	Loss 1.2421e+00 (1.1495e+00)	Acc@1 12.500000 (23.174778)
Epoch: [5][128/591]	Time  0.594 ( 0.676)	Data  0.497 ( 0.578)	Loss 1.2711e+00 (1.1459e+00)	Acc@1 25.000000 (23.740311)
Epoch: [5][144/591]	Time  1.052 ( 0.675)	Data  0.934 ( 0.577)	Loss 1.3583e+00 (1.1373e+00)	Acc@1 12.500000 (23.275862)
Epoch: [5][160/591]	Time  0.827 ( 0.675)	Data  0.730 ( 0.576)	Loss 1.0184e+00 (1.1415e+00)	Acc@1 6.250000 (22.826088)
Epoch: [5][176/591]	Time  0.611 ( 0.674)	Data  0.514 ( 0.575)	Loss 1.1728e+00 (1.1389e+00)	Acc@1 6.250000 (22.775423)
Epoch: [5][192/591]	Time  0.578 ( 0.670)	Data  0.480 ( 0.572)	Loss 1.0087e+00 (1.1324e+00)	Acc@1 37.500000 (23.121761)
Epoch: [5][208/591]	Time  0.633 ( 0.669)	Data  0.536 ( 0.571)	Loss 1.1127e+00 (1.1322e+00)	Acc@1 25.000000 (23.385166)
Epoch: [5][224/591]	Time  0.626 ( 0.666)	Data  0.529 ( 0.567)	Loss 1.2807e+00 (1.1347e+00)	Acc@1 6.250000 (23.111113)
Epoch: [5][240/591]	Time  0.979 ( 0.670)	Data  0.882 ( 0.571)	Loss 1.1745e+00 (1.1403e+00)	Acc@1 18.750000 (23.054981)
Epoch: [5][256/591]	Time  0.606 ( 0.667)	Data  0.508 ( 0.569)	Loss 1.2133e+00 (1.1384e+00)	Acc@1 18.750000 (23.224709)
Epoch: [5][272/591]	Time  0.606 ( 0.666)	Data  0.508 ( 0.567)	Loss 1.1574e+00 (1.1376e+00)	Acc@1 12.500000 (23.031136)
Epoch: [5][288/591]	Time  0.615 ( 0.663)	Data  0.518 ( 0.565)	Loss 1.2192e+00 (1.1371e+00)	Acc@1 37.500000 (23.183392)
Epoch: [5][304/591]	Time  0.610 ( 0.663)	Data  0.512 ( 0.564)	Loss 9.5963e-01 (1.1359e+00)	Acc@1 18.750000 (23.196722)
Epoch: [5][320/591]	Time  0.702 ( 0.661)	Data  0.605 ( 0.563)	Loss 1.1666e+00 (1.1360e+00)	Acc@1 18.750000 (23.189251)
Epoch: [5][336/591]	Time  0.658 ( 0.663)	Data  0.561 ( 0.565)	Loss 9.8100e-01 (1.1345e+00)	Acc@1 12.500000 (23.497774)
Epoch: [5][352/591]	Time  0.579 ( 0.660)	Data  0.482 ( 0.562)	Loss 1.1815e+00 (1.1383e+00)	Acc@1 18.750000 (23.282578)
Epoch: [5][368/591]	Time  0.644 ( 0.659)	Data  0.547 ( 0.561)	Loss 1.1154e+00 (1.1367e+00)	Acc@1 25.000000 (23.492548)
Epoch: [5][384/591]	Time  0.584 ( 0.658)	Data  0.485 ( 0.560)	Loss 1.5195e+00 (1.1338e+00)	Acc@1 18.750000 (23.522726)
Epoch: [5][400/591]	Time  0.590 ( 0.657)	Data  0.493 ( 0.559)	Loss 1.2797e+00 (1.1314e+00)	Acc@1 18.750000 (23.612844)
Epoch: [5][416/591]	Time  0.610 ( 0.655)	Data  0.512 ( 0.557)	Loss 1.1898e+00 (1.1322e+00)	Acc@1 31.250000 (23.621103)
Epoch: [5][432/591]	Time  0.604 ( 0.657)	Data  0.506 ( 0.559)	Loss 1.1475e+00 (1.1306e+00)	Acc@1 31.250000 (23.599884)
Epoch: [5][448/591]	Time  0.588 ( 0.657)	Data  0.491 ( 0.559)	Loss 1.1947e+00 (1.1308e+00)	Acc@1 25.000000 (23.594099)
Epoch: [5][464/591]	Time  0.595 ( 0.656)	Data  0.497 ( 0.558)	Loss 1.0523e+00 (1.1317e+00)	Acc@1 31.250000 (23.521505)
Epoch: [5][480/591]	Time  0.664 ( 0.655)	Data  0.567 ( 0.557)	Loss 1.0014e+00 (1.1295e+00)	Acc@1 31.250000 (23.804573)
Epoch: [5][496/591]	Time  0.629 ( 0.654)	Data  0.531 ( 0.556)	Loss 9.6658e-01 (1.1284e+00)	Acc@1 31.250000 (23.968813)
Epoch: [5][512/591]	Time  0.645 ( 0.653)	Data  0.547 ( 0.555)	Loss 9.6983e-01 (1.1279e+00)	Acc@1 25.000000 (23.879143)
Epoch: [5][528/591]	Time  0.665 ( 0.655)	Data  0.567 ( 0.557)	Loss 1.1513e+00 (1.1276e+00)	Acc@1 18.750000 (23.995747)
Epoch: [5][544/591]	Time  0.634 ( 0.654)	Data  0.537 ( 0.556)	Loss 1.2140e+00 (1.1265e+00)	Acc@1 12.500000 (23.979359)
Epoch: [5][560/591]	Time  0.604 ( 0.654)	Data  0.506 ( 0.556)	Loss 1.2480e+00 (1.1266e+00)	Acc@1 25.000000 (23.941622)
Epoch: [5][576/591]	Time  0.616 ( 0.653)	Data  0.519 ( 0.555)	Loss 1.2506e+00 (1.1273e+00)	Acc@1 25.000000 (24.003466)
##################################################
train_loss:  1.1271545445253401
train_acc:  tensor(24.0165, device='cuda:0')
##################################################
Best model was saved.
Epoch: [6][  0/591]	Time  0.618 ( 0.618)	Data  0.520 ( 0.520)	Loss 1.2691e+00 (1.2691e+00)	Acc@1 31.250000 (31.250000)
Epoch: [6][ 16/591]	Time  0.631 ( 0.687)	Data  0.534 ( 0.585)	Loss 9.5269e-01 (1.1411e+00)	Acc@1 18.750000 (19.852942)
Epoch: [6][ 32/591]	Time  0.635 ( 0.669)	Data  0.538 ( 0.569)	Loss 9.6138e-01 (1.1547e+00)	Acc@1 31.250000 (21.590910)
Epoch: [6][ 48/591]	Time  0.631 ( 0.660)	Data  0.534 ( 0.561)	Loss 9.4313e-01 (1.1462e+00)	Acc@1 25.000000 (22.576530)
Epoch: [6][ 64/591]	Time  0.598 ( 0.649)	Data  0.500 ( 0.551)	Loss 1.1023e+00 (1.1371e+00)	Acc@1 31.250000 (23.942308)
Epoch: [6][ 80/591]	Time  0.598 ( 0.648)	Data  0.501 ( 0.549)	Loss 1.1816e+00 (1.1489e+00)	Acc@1 25.000000 (23.456791)
Epoch: [6][ 96/591]	Time  0.598 ( 0.645)	Data  0.501 ( 0.547)	Loss 1.3275e+00 (1.1511e+00)	Acc@1 18.750000 (23.131443)
Epoch: [6][112/591]	Time  0.655 ( 0.654)	Data  0.557 ( 0.556)	Loss 1.1416e+00 (1.1489e+00)	Acc@1 25.000000 (23.396017)
Epoch: [6][128/591]	Time  0.638 ( 0.652)	Data  0.541 ( 0.554)	Loss 9.8386e-01 (1.1465e+00)	Acc@1 12.500000 (23.352713)
Epoch: [6][144/591]	Time  0.615 ( 0.651)	Data  0.518 ( 0.553)	Loss 1.1680e+00 (1.1484e+00)	Acc@1 18.750000 (23.232759)
Epoch: [6][160/591]	Time  0.627 ( 0.650)	Data  0.530 ( 0.552)	Loss 1.2281e+00 (1.1448e+00)	Acc@1 18.750000 (23.369566)
Epoch: [6][176/591]	Time  0.598 ( 0.648)	Data  0.500 ( 0.550)	Loss 9.2581e-01 (1.1368e+00)	Acc@1 18.750000 (23.587570)
Epoch: [6][192/591]	Time  0.629 ( 0.647)	Data  0.532 ( 0.549)	Loss 1.1866e+00 (1.1331e+00)	Acc@1 31.250000 (23.737045)
Epoch: [6][208/591]	Time  0.624 ( 0.653)	Data  0.527 ( 0.555)	Loss 9.7704e-01 (1.1318e+00)	Acc@1 18.750000 (23.773922)
Epoch: [6][224/591]	Time  0.606 ( 0.650)	Data  0.508 ( 0.552)	Loss 1.0964e+00 (1.1263e+00)	Acc@1 18.750000 (23.861113)
Epoch: [6][240/591]	Time  0.583 ( 0.649)	Data  0.486 ( 0.551)	Loss 9.4741e-01 (1.1238e+00)	Acc@1 31.250000 (23.521786)
Epoch: [6][256/591]	Time  0.615 ( 0.647)	Data  0.518 ( 0.549)	Loss 1.0142e+00 (1.1169e+00)	Acc@1 31.250000 (24.173151)
Epoch: [6][272/591]	Time  0.561 ( 0.645)	Data  0.463 ( 0.547)	Loss 1.1652e+00 (1.1173e+00)	Acc@1 18.750000 (24.381868)
Epoch: [6][288/591]	Time  0.634 ( 0.645)	Data  0.537 ( 0.547)	Loss 1.0163e+00 (1.1127e+00)	Acc@1 37.500000 (24.632353)
Epoch: [6][304/591]	Time  0.575 ( 0.647)	Data  0.478 ( 0.549)	Loss 1.1545e+00 (1.1096e+00)	Acc@1 25.000000 (24.774590)
Epoch: [6][320/591]	Time  0.642 ( 0.647)	Data  0.544 ( 0.549)	Loss 1.2312e+00 (1.1101e+00)	Acc@1 37.500000 (24.824766)
Epoch: [6][336/591]	Time  0.668 ( 0.649)	Data  0.570 ( 0.551)	Loss 8.9266e-01 (1.1111e+00)	Acc@1 12.500000 (24.870178)
Epoch: [6][352/591]	Time  0.628 ( 0.650)	Data  0.530 ( 0.552)	Loss 1.0552e+00 (1.1118e+00)	Acc@1 37.500000 (25.106232)
Epoch: [6][368/591]	Time  0.637 ( 0.649)	Data  0.540 ( 0.551)	Loss 9.9309e-01 (1.1098e+00)	Acc@1 31.250000 (25.220190)
Epoch: [6][384/591]	Time  0.968 ( 0.651)	Data  0.849 ( 0.553)	Loss 1.1091e+00 (1.1088e+00)	Acc@1 6.250000 (25.308441)
Epoch: [6][400/591]	Time  0.850 ( 0.652)	Data  0.751 ( 0.554)	Loss 8.0924e-01 (1.1063e+00)	Acc@1 37.500000 (25.109102)
Epoch: [6][416/591]	Time  0.767 ( 0.651)	Data  0.670 ( 0.553)	Loss 1.0652e+00 (1.1058e+00)	Acc@1 18.750000 (25.149881)
Epoch: [6][432/591]	Time  0.610 ( 0.650)	Data  0.512 ( 0.552)	Loss 1.1214e+00 (1.1036e+00)	Acc@1 6.250000 (25.129908)
Epoch: [6][448/591]	Time  0.598 ( 0.650)	Data  0.500 ( 0.552)	Loss 1.1261e+00 (1.1035e+00)	Acc@1 31.250000 (25.000000)
Epoch: [6][464/591]	Time  0.625 ( 0.649)	Data  0.528 ( 0.551)	Loss 1.1170e+00 (1.1031e+00)	Acc@1 12.500000 (25.120968)
Epoch: [6][480/591]	Time  0.599 ( 0.652)	Data  0.502 ( 0.554)	Loss 1.1495e+00 (1.1029e+00)	Acc@1 12.500000 (24.948025)
Epoch: [6][496/591]	Time  0.607 ( 0.651)	Data  0.509 ( 0.553)	Loss 9.4068e-01 (1.1021e+00)	Acc@1 25.000000 (24.924547)
Epoch: [6][512/591]	Time  0.602 ( 0.651)	Data  0.504 ( 0.553)	Loss 1.0900e+00 (1.1024e+00)	Acc@1 12.500000 (24.829435)
Epoch: [6][528/591]	Time  0.747 ( 0.650)	Data  0.650 ( 0.552)	Loss 1.1970e+00 (1.1016e+00)	Acc@1 18.750000 (24.905483)
Epoch: [6][544/591]	Time  0.623 ( 0.650)	Data  0.526 ( 0.552)	Loss 9.9550e-01 (1.1040e+00)	Acc@1 25.000000 (24.931192)
Epoch: [6][560/591]	Time  0.608 ( 0.650)	Data  0.511 ( 0.552)	Loss 1.0862e+00 (1.1061e+00)	Acc@1 18.750000 (25.044563)
Epoch: [6][576/591]	Time  0.604 ( 0.651)	Data  0.506 ( 0.553)	Loss 1.2395e+00 (1.1066e+00)	Acc@1 12.500000 (24.935009)
##################################################
train_loss:  1.106521868665408
train_acc:  tensor(24.8942, device='cuda:0')
##################################################
Best model was saved.
Epoch: [7][  0/591]	Time  0.609 ( 0.609)	Data  0.506 ( 0.506)	Loss 1.1286e+00 (1.1286e+00)	Acc@1 12.500000 (12.500000)
Epoch: [7][ 16/591]	Time  0.637 ( 0.640)	Data  0.540 ( 0.542)	Loss 1.0153e+00 (1.0577e+00)	Acc@1 37.500000 (27.941177)
Epoch: [7][ 32/591]	Time  0.641 ( 0.631)	Data  0.544 ( 0.534)	Loss 8.8003e-01 (1.0592e+00)	Acc@1 31.250000 (25.757576)
Epoch: [7][ 48/591]	Time  0.628 ( 0.635)	Data  0.531 ( 0.537)	Loss 1.2374e+00 (1.0890e+00)	Acc@1 6.250000 (25.000000)
Epoch: [7][ 64/591]	Time  0.635 ( 0.636)	Data  0.538 ( 0.538)	Loss 1.0198e+00 (1.0852e+00)	Acc@1 18.750000 (24.807692)
Epoch: [7][ 80/591]	Time  0.703 ( 0.650)	Data  0.606 ( 0.552)	Loss 9.1260e-01 (1.0730e+00)	Acc@1 37.500000 (24.768518)
Epoch: [7][ 96/591]	Time  0.620 ( 0.646)	Data  0.523 ( 0.548)	Loss 1.1842e+00 (1.0742e+00)	Acc@1 25.000000 (25.451031)
Epoch: [7][112/591]	Time  0.637 ( 0.648)	Data  0.540 ( 0.550)	Loss 1.1528e+00 (1.0758e+00)	Acc@1 18.750000 (25.663717)
Epoch: [7][128/591]	Time  0.584 ( 0.648)	Data  0.487 ( 0.550)	Loss 1.2121e+00 (1.0705e+00)	Acc@1 18.750000 (25.242249)
Epoch: [7][144/591]	Time  0.616 ( 0.644)	Data  0.518 ( 0.546)	Loss 1.0609e+00 (1.0703e+00)	Acc@1 18.750000 (24.698277)
Epoch: [7][160/591]	Time  0.603 ( 0.651)	Data  0.506 ( 0.553)	Loss 1.1061e+00 (1.0730e+00)	Acc@1 25.000000 (25.038820)
Epoch: [7][176/591]	Time  0.690 ( 0.649)	Data  0.593 ( 0.551)	Loss 1.2027e+00 (1.0698e+00)	Acc@1 25.000000 (25.105932)
Epoch: [7][192/591]	Time  0.638 ( 0.648)	Data  0.540 ( 0.550)	Loss 9.8888e-01 (1.0631e+00)	Acc@1 37.500000 (25.582901)
Epoch: [7][208/591]	Time  0.595 ( 0.645)	Data  0.497 ( 0.547)	Loss 1.1561e+00 (1.0668e+00)	Acc@1 31.250000 (25.687798)
Epoch: [7][224/591]	Time  0.624 ( 0.644)	Data  0.527 ( 0.547)	Loss 1.0613e+00 (1.0673e+00)	Acc@1 43.750000 (25.555555)
Epoch: [7][240/591]	Time  0.690 ( 0.647)	Data  0.592 ( 0.549)	Loss 9.5380e-01 (1.0708e+00)	Acc@1 18.750000 (25.440872)
Epoch: [7][256/591]	Time  0.671 ( 0.653)	Data  0.573 ( 0.555)	Loss 1.2946e+00 (1.0695e+00)	Acc@1 31.250000 (25.607977)
Epoch: [7][272/591]	Time  0.643 ( 0.653)	Data  0.545 ( 0.555)	Loss 1.0035e+00 (1.0669e+00)	Acc@1 12.500000 (25.549450)
Epoch: [7][288/591]	Time  0.663 ( 0.653)	Data  0.565 ( 0.555)	Loss 1.0554e+00 (1.0685e+00)	Acc@1 25.000000 (25.346022)
Epoch: [7][304/591]	Time  0.607 ( 0.652)	Data  0.509 ( 0.554)	Loss 9.9554e-01 (1.0688e+00)	Acc@1 6.250000 (25.368853)
Epoch: [7][320/591]	Time  0.633 ( 0.651)	Data  0.535 ( 0.553)	Loss 1.3557e+00 (1.0689e+00)	Acc@1 18.750000 (25.350466)
Epoch: [7][336/591]	Time  0.632 ( 0.651)	Data  0.534 ( 0.553)	Loss 9.6980e-01 (1.0722e+00)	Acc@1 12.500000 (25.204006)
Epoch: [7][352/591]	Time  0.617 ( 0.654)	Data  0.520 ( 0.556)	Loss 1.1168e+00 (1.0772e+00)	Acc@1 25.000000 (25.000000)
Epoch: [7][368/591]	Time  0.608 ( 0.653)	Data  0.511 ( 0.555)	Loss 1.0165e+00 (1.0769e+00)	Acc@1 18.750000 (24.779810)
Epoch: [7][384/591]	Time  0.606 ( 0.653)	Data  0.508 ( 0.555)	Loss 1.2619e+00 (1.0777e+00)	Acc@1 6.250000 (24.496754)
Epoch: [7][400/591]	Time  0.621 ( 0.652)	Data  0.524 ( 0.554)	Loss 1.2175e+00 (1.0787e+00)	Acc@1 12.500000 (24.438904)
Epoch: [7][416/591]	Time  0.681 ( 0.652)	Data  0.584 ( 0.554)	Loss 1.2875e+00 (1.0795e+00)	Acc@1 31.250000 (24.295565)wandb: ERROR Failed to sample metric: process no longer exists (pid=7048)
wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221122_144006-1v4vavit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-water-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/big_run
wandb: üöÄ View run at https://wandb.ai/self-classifier/big_run/runs/1v4vavit
wandb: ERROR Failed to sample metric: process no longer exists (pid=27712)
wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221122_144421-2619y6ro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-mountain-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/big_run
wandb: üöÄ View run at https://wandb.ai/self-classifier/big_run/runs/2619y6ro
Namespace(arch='resnet18', batch_size=16, cls_size=[5], col_tau=0.05, config=(0.05, 0.4), cos=True, data='../imagenette2', dim=128, epochs=50, eps=1e-08, final_lr=0.0048, fixed_cls=False, global_crops_scale=(0.4, 1.0), gpu=0, hidden_dim=4096, lars=False, local_config='configs/config_first_run.yaml', local_crops_number=6, local_crops_scale=(0.05, 0.4), lr=4.8, momentum=0.9, no_leaky=False, num_cls=1, num_hidden=2, patch_size=16, pretrained=None, print_freq=16, queue_len=1500, resume='', row_tau=0.1, save_path='./saved/', seed=0, sgd=True, start_epoch=0, start_warmup=0.3, subset=0, use_amp=True, use_bn=True, wandb='big_run', warmup_epochs=10, weight_decay=1e-06)
Model(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (mlp_head): MLPHead(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=4096, bias=True)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Linear(in_features=4096, out_features=128, bias=True)
    )
  )
  (cls_0): Linear(in_features=128, out_features=5, bias=False)
)
##### USING THE GPU #####
Epoch: [0][  0/591]	Time  1.510 ( 1.510)	Data  0.614 ( 0.614)	Loss 1.7408e+00 (1.7408e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 16/591]	Time  0.635 ( 0.691)	Data  0.537 ( 0.547)	Loss 1.6085e+00 (1.6888e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 32/591]	Time  0.608 ( 0.670)	Data  0.510 ( 0.548)	Loss 1.5896e+00 (1.6321e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 48/591]	Time  0.641 ( 0.661)	Data  0.543 ( 0.547)	Loss 1.4697e+00 (1.6053e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 64/591]	Time  0.596 ( 0.671)	Data  0.498 ( 0.560)	Loss 1.4202e+00 (1.5747e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 80/591]	Time  0.589 ( 0.667)	Data  0.491 ( 0.559)	Loss 1.4256e+00 (1.5537e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 96/591]	Time  0.590 ( 0.657)	Data  0.492 ( 0.551)	Loss 1.5324e+00 (1.5478e+00)	Acc@1 12.500000 (12.500000)
Epoch: [0][112/591]	Time  0.658 ( 0.657)	Data  0.560 ( 0.552)	Loss 1.3494e+00 (1.5371e+00)	Acc@1 6.250000 (11.184211)
Epoch: [0][128/591]	Time  0.625 ( 0.657)	Data  0.527 ( 0.552)	Loss 1.6194e+00 (1.5281e+00)	Acc@1 6.250000 (13.214286)
Epoch: [0][144/591]	Time  0.855 ( 0.657)	Data  0.749 ( 0.554)	Loss 1.3951e+00 (1.5250e+00)	Acc@1 18.750000 (13.235294)
Epoch: [0][160/591]	Time  0.732 ( 0.661)	Data  0.634 ( 0.558)	Loss 1.4578e+00 (1.5185e+00)	Acc@1 18.750000 (13.805970)
Epoch: [0][176/591]	Time  0.637 ( 0.662)	Data  0.538 ( 0.559)	Loss 1.4049e+00 (1.5082e+00)	Acc@1 6.250000 (15.060241)
Epoch: [0][192/591]	Time  0.613 ( 0.663)	Data  0.516 ( 0.561)	Loss 1.4108e+00 (1.5017e+00)	Acc@1 18.750000 (15.151515)
Epoch: [0][208/591]	Time  0.605 ( 0.662)	Data  0.507 ( 0.560)	Loss 1.5068e+00 (1.5011e+00)	Acc@1 12.500000 (15.543478)
Epoch: [0][224/591]	Time  0.628 ( 0.660)	Data  0.531 ( 0.559)	Loss 1.3663e+00 (1.4992e+00)	Acc@1 12.500000 (15.171756)
Epoch: [0][240/591]	Time  0.597 ( 0.664)	Data  0.500 ( 0.563)	Loss 1.4201e+00 (1.4991e+00)	Acc@1 0.000000 (15.008503)
Epoch: [0][256/591]	Time  0.571 ( 0.664)	Data  0.474 ( 0.563)	Loss 1.3725e+00 (1.4945e+00)	Acc@1 12.500000 (14.915644)
Epoch: [0][272/591]	Time  0.676 ( 0.664)	Data  0.578 ( 0.563)	Loss 1.3731e+00 (1.4914e+00)	Acc@1 12.500000 (14.874301)
Epoch: [0][288/591]	Time  0.636 ( 0.662)	Data  0.539 ( 0.561)	Loss 1.4816e+00 (1.4913e+00)	Acc@1 6.250000 (15.192308)
Epoch: [0][304/591]	Time  0.645 ( 0.661)	Data  0.547 ( 0.560)	Loss 1.3394e+00 (1.4881e+00)	Acc@1 12.500000 (15.077015)wandb: ERROR Failed to sample metric: process no longer exists (pid=29077)
wandb: Currently logged in as: saccardi (self-classifier). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/carlo/DL-adv-self-classifier/wandb/run-20221122_145626-s3zmgvxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-jazz-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/self-classifier/big_run
wandb: üöÄ View run at https://wandb.ai/self-classifier/big_run/runs/s3zmgvxj
Namespace(arch='resnet18', batch_size=16, cls_size=[5], col_tau=0.05, config=(0.05, 0.4), cos=True, data='../imagenette2', dim=128, epochs=50, eps=1e-08, final_lr=0.0048, fixed_cls=False, global_crops_scale=(0.4, 1.0), gpu=0, hidden_dim=4096, lars=False, local_config='configs/config_first_run.yaml', local_crops_number=6, local_crops_scale=(0.05, 0.4), lr=4.8, momentum=0.9, no_leaky=False, num_cls=1, num_hidden=2, patch_size=16, pretrained=None, print_freq=16, queue_len=10000, resume='', row_tau=0.1, save_path='./saved/', seed=0, sgd=True, start_epoch=0, start_warmup=0.3, subset=0, use_amp=True, use_bn=True, wandb='big_run', warmup_epochs=10, weight_decay=1e-06)
Model(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (mlp_head): MLPHead(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=4096, bias=True)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Linear(in_features=4096, out_features=128, bias=True)
    )
  )
  (cls_0): Linear(in_features=128, out_features=5, bias=False)
)
##### USING THE GPU #####
Epoch: [0][  0/591]	Time  1.476 ( 1.476)	Data  0.568 ( 0.568)	Loss 1.7264e+00 (1.7264e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 16/591]	Time  0.693 ( 0.713)	Data  0.595 ( 0.567)	Loss 1.4180e+00 (1.6792e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 32/591]	Time  0.609 ( 0.690)	Data  0.510 ( 0.568)	Loss 1.5924e+00 (1.6170e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 48/591]	Time  0.615 ( 0.692)	Data  0.516 ( 0.577)	Loss 1.5963e+00 (1.5889e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 64/591]	Time  0.636 ( 0.682)	Data  0.538 ( 0.571)	Loss 1.4774e+00 (1.5638e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 80/591]	Time  0.618 ( 0.672)	Data  0.521 ( 0.564)	Loss 1.5101e+00 (1.5562e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][ 96/591]	Time  0.617 ( 0.665)	Data  0.520 ( 0.559)	Loss 1.4826e+00 (1.5480e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][112/591]	Time  0.661 ( 0.663)	Data  0.563 ( 0.557)	Loss 1.5251e+00 (1.5374e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][128/591]	Time  0.620 ( 0.661)	Data  0.522 ( 0.557)	Loss 1.3689e+00 (1.5299e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][144/591]	Time  0.619 ( 0.665)	Data  0.521 ( 0.561)	Loss 1.5204e+00 (1.5233e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][160/591]	Time  0.627 ( 0.663)	Data  0.529 ( 0.559)	Loss 1.4756e+00 (1.5172e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][176/591]	Time  0.601 ( 0.662)	Data  0.503 ( 0.559)	Loss 1.3972e+00 (1.5139e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][192/591]	Time  0.601 ( 0.659)	Data  0.504 ( 0.557)	Loss 1.4029e+00 (1.5115e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][208/591]	Time  0.824 ( 0.659)	Data  0.725 ( 0.557)	Loss 1.5389e+00 (1.5101e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][224/591]	Time  0.633 ( 0.657)	Data  0.535 ( 0.556)	Loss 1.5142e+00 (1.5047e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][240/591]	Time  0.630 ( 0.663)	Data  0.532 ( 0.561)	Loss 1.3960e+00 (1.5018e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][256/591]	Time  0.650 ( 0.663)	Data  0.552 ( 0.561)	Loss 1.4672e+00 (1.5031e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][272/591]	Time  0.659 ( 0.661)	Data  0.561 ( 0.560)	Loss 1.4660e+00 (1.5022e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][288/591]	Time  0.629 ( 0.660)	Data  0.531 ( 0.558)	Loss 1.5075e+00 (1.5006e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][304/591]	Time  0.607 ( 0.663)	Data  0.508 ( 0.562)	Loss 1.3808e+00 (1.4971e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][320/591]	Time  0.601 ( 0.666)	Data  0.503 ( 0.565)	Loss 1.4796e+00 (1.4907e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][336/591]	Time  0.653 ( 0.665)	Data  0.556 ( 0.565)	Loss 1.5699e+00 (1.4873e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][352/591]	Time  0.586 ( 0.665)	Data  0.489 ( 0.564)	Loss 1.1467e+00 (1.4829e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][368/591]	Time  0.596 ( 0.664)	Data  0.498 ( 0.563)	Loss 1.5282e+00 (1.4817e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][384/591]	Time  0.649 ( 0.663)	Data  0.551 ( 0.563)	Loss 1.3327e+00 (1.4775e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][400/591]	Time  0.690 ( 0.662)	Data  0.592 ( 0.562)	Loss 1.3449e+00 (1.4766e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][416/591]	Time  0.581 ( 0.664)	Data  0.483 ( 0.564)	Loss 1.5057e+00 (1.4745e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][432/591]	Time  0.678 ( 0.665)	Data  0.580 ( 0.565)	Loss 1.4049e+00 (1.4727e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][448/591]	Time  0.635 ( 0.664)	Data  0.537 ( 0.564)	Loss 1.2878e+00 (1.4700e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][464/591]	Time  0.550 ( 0.662)	Data  0.453 ( 0.562)	Loss 1.3640e+00 (1.4675e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][480/591]	Time  0.581 ( 0.661)	Data  0.484 ( 0.561)	Loss 1.3219e+00 (1.4669e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][496/591]	Time  0.610 ( 0.660)	Data  0.513 ( 0.560)	Loss 1.4249e+00 (1.4663e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][512/591]	Time  0.666 ( 0.661)	Data  0.569 ( 0.561)	Loss 1.5087e+00 (1.4643e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][528/591]	Time  0.659 ( 0.661)	Data  0.561 ( 0.561)	Loss 1.5436e+00 (1.4637e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][544/591]	Time  0.625 ( 0.660)	Data  0.527 ( 0.560)	Loss 1.2511e+00 (1.4620e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][560/591]	Time  0.625 ( 0.659)	Data  0.527 ( 0.560)	Loss 1.3073e+00 (1.4588e+00)	Acc@1 0.000000 (0.000000)
Epoch: [0][576/591]	Time  0.687 ( 0.659)	Data  0.590 ( 0.559)	Loss 1.2044e+00 (1.4576e+00)	Acc@1 0.000000 (0.000000)
##################################################
train_loss:  1.4557359200443714
train_acc:  0
##################################################
Best model was saved.
Epoch: [1][  0/591]	Time  0.995 ( 0.995)	Data  0.877 ( 0.877)	Loss 1.2742e+00 (1.2742e+00)	Acc@1 0.000000 (0.000000)
Epoch: [1][ 16/591]	Time  0.655 ( 0.718)	Data  0.557 ( 0.618)	Loss 1.4552e+00 (1.4328e+00)	Acc@1 0.000000 (0.000000)
Epoch: [1][ 32/591]	Time  0.656 ( 0.681)	Data  0.559 ( 0.582)	Loss 1.5925e+00 (1.4294e+00)	Acc@1 0.000000 (0.000000)
Epoch: [1][ 48/591]	Time  0.613 ( 0.663)	Data  0.516 ( 0.565)	Loss 1.4653e+00 (1.4224e+00)	Acc@1 12.500000 (15.000001)
Epoch: [1][ 64/591]	Time  0.582 ( 0.654)	Data  0.485 ( 0.556)	Loss 1.5244e+00 (1.4280e+00)	Acc@1 18.750000 (14.717742)
Epoch: [1][ 80/591]	Time  0.631 ( 0.656)	Data  0.533 ( 0.558)	Loss 1.4606e+00 (1.4212e+00)	Acc@1 18.750000 (15.558510)
Epoch: [1][ 96/591]	Time  0.640 ( 0.665)	Data  0.542 ( 0.567)	Loss 1.4599e+00 (1.4257e+00)	Acc@1 18.750000 (15.575397)
Epoch: [1][112/591]	Time  0.623 ( 0.661)	Data  0.526 ( 0.563)	Loss 1.3886e+00 (1.4283e+00)	Acc@1 25.000000 (13.924051)
Epoch: [1][128/591]	Time  0.550 ( 0.661)	Data  0.452 ( 0.563)	Loss 1.3473e+00 (1.4298e+00)	Acc@1 18.750000 (14.276317)
Epoch: [1][144/591]	Time  0.617 ( 0.657)	Data  0.519 ( 0.559)	Loss 1.5373e+00 (1.4298e+00)	Acc@1 18.750000 (13.738739)
Epoch: [1][160/591]	Time  0.616 ( 0.656)	Data  0.518 ( 0.558)	Loss 1.4675e+00 (1.4276e+00)	Acc@1 6.250000 (13.877953)
Epoch: [1][176/591]	Time  0.629 ( 0.653)	Data  0.531 ( 0.555)	Loss 1.3563e+00 (1.4260e+00)	Acc@1 18.750000 (13.680070)
Epoch: [1][192/591]	Time  0.630 ( 0.657)	Data  0.533 ( 0.559)	Loss 1.2593e+00 (1.4237e+00)	Acc@1 31.250000 (13.718553)
Epoch: [1][208/591]	Time  0.608 ( 0.655)	Data  0.511 ( 0.557)	Loss 1.5255e+00 (1.4230e+00)	Acc@1 18.750000 (13.821428)
Epoch: [1][224/591]	Time  0.579 ( 0.655)	Data  0.482 ( 0.556)	Loss 1.4712e+00 (1.4218e+00)	Acc@1 6.250000 (13.710733)
Epoch: [1][240/591]	Time  0.674 ( 0.657)	Data  0.576 ( 0.559)	Loss 1.4539e+00 (1.4212e+00)	Acc@1 12.500000 (13.586956)
Epoch: [1][256/591]	Time  0.609 ( 0.655)	Data  0.510 ( 0.557)	Loss 1.3461e+00 (1.4198e+00)	Acc@1 31.250000 (13.761211)
Epoch: [1][272/591]	Time  0.609 ( 0.653)	Data  0.512 ( 0.555)	Loss 1.3569e+00 (1.4177e+00)	Acc@1 37.500000 (13.938284)
Epoch: [1][288/591]	Time  0.878 ( 0.657)	Data  0.780 ( 0.559)	Loss 1.3282e+00 (1.4194e+00)	Acc@1 0.000000 (13.799021)
Epoch: [1][304/591]	Time  0.709 ( 0.658)	Data  0.612 ( 0.560)	Loss 1.3084e+00 (1.4180e+00)	Acc@1 18.750000 (13.999078)
Epoch: [1][320/591]	Time  0.627 ( 0.657)	Data  0.528 ( 0.559)	Loss 1.3410e+00 (1.4153e+00)	Acc@1 25.000000 (14.067945)
Epoch: [1][336/591]	Time  0.699 ( 0.656)	Data  0.602 ( 0.558)	Loss 1.2147e+00 (1.4121e+00)	Acc@1 18.750000 (14.212047)
Epoch: [1][352/591]	Time  0.587 ( 0.656)	Data  0.490 ( 0.558)	Loss 1.3996e+00 (1.4102e+00)	Acc@1 18.750000 (14.106583)
Epoch: [1][368/591]	Time  0.933 ( 0.657)	Data  0.829 ( 0.558)	Loss 1.5457e+00 (1.4116e+00)	Acc@1 6.250000 (14.067164)
Epoch: [1][384/591]	Time  0.715 ( 0.658)	Data  0.617 ( 0.560)	Loss 1.2312e+00 (1.4120e+00)	Acc@1 6.250000 (14.066952)
Epoch: [1][400/591]	Time  0.614 ( 0.658)	Data  0.517 ( 0.560)	Loss 1.5402e+00 (1.4096e+00)	Acc@1 25.000000 (13.930517)
Epoch: [1][416/591]	Time  0.636 ( 0.656)	Data  0.538 ( 0.558)	Loss 1.3419e+00 (1.4087e+00)	Acc@1 12.500000 (13.838120)
Epoch: [1][432/591]	Time  0.646 ( 0.656)	Data  0.549 ( 0.558)	Loss 1.2560e+00 (1.4061e+00)	Acc@1 18.750000 (13.925439)
Epoch: [1][448/591]	Time  0.591 ( 0.656)	Data  0.493 ( 0.558)	Loss 1.1198e+00 (1.4045e+00)	Acc@1 18.750000 (13.990964)
Epoch: [1][464/591]	Time  0.745 ( 0.658)	Data  0.647 ( 0.560)	Loss 1.3525e+00 (1.4028e+00)	Acc@1 18.750000 (13.979117)
Epoch: [1][480/591]	Time  0.665 ( 0.657)	Data  0.567 ( 0.559)	Loss 1.3892e+00 (1.4034e+00)	Acc@1 0.000000 (13.940157)
Epoch: [1][496/591]	Time  0.627 ( 0.657)	Data  0.529 ( 0.559)	Loss 1.3217e+00 (1.4014e+00)	Acc@1 12.500000 (13.944384)
Epoch: [1][512/591]	Time  0.605 ( 0.657)	Data  0.508 ( 0.559)	Loss 1.2167e+00 (1.4003e+00)	Acc@1 12.500000 (13.987474)
Epoch: [1][528/591]	Time  0.605 ( 0.656)	Data  0.508 ( 0.558)	Loss 1.3098e+00 (1.3962e+00)	Acc@1 12.500000 (14.191920)
Epoch: [1][544/591]	Time  0.650 ( 0.656)	Data  0.553 ( 0.558)	Loss 1.4407e+00 (1.3951e+00)	Acc@1 18.750000 (14.102250)
Epoch: [1][560/591]	Time  0.661 ( 0.657)	Data  0.564 ( 0.558)	Loss 1.3254e+00 (1.3958e+00)	Acc@1 18.750000 (14.041745)
Epoch: [1][576/591]	Time  0.609 ( 0.656)	Data  0.511 ( 0.558)	Loss 1.4665e+00 (1.3944e+00)	Acc@1 0.000000 (14.007827)
##################################################
train_loss:  1.3936009463521633
train_acc:  tensor(14.0373, device='cuda:0')
##################################################
Best model was saved.
Epoch: [2][  0/591]	Time  0.660 ( 0.660)	Data  0.562 ( 0.562)	Loss 1.2952e+00 (1.2952e+00)	Acc@1 18.750000 (18.750000)
Epoch: [2][ 16/591]	Time  0.610 ( 0.659)	Data  0.512 ( 0.561)	Loss 1.1392e+00 (1.3272e+00)	Acc@1 18.750000 (16.176470)
Epoch: [2][ 32/591]	Time  0.622 ( 0.649)	Data  0.524 ( 0.551)	Loss 1.3633e+00 (1.3505e+00)	Acc@1 18.750000 (15.719697)
Epoch: [2][ 48/591]	Time  0.606 ( 0.640)	Data  0.508 ( 0.543)	Loss 1.4149e+00 (1.3476e+00)	Acc@1 25.000000 (15.051020)
Epoch: [2][ 64/591]	Time  0.622 ( 0.657)	Data  0.524 ( 0.558)	Loss 1.2329e+00 (1.3573e+00)	Acc@1 12.500000 (14.807693)
Epoch: [2][ 80/591]	Time  0.631 ( 0.649)	Data  0.532 ( 0.551)	Loss 1.4101e+00 (1.3435e+00)	Acc@1 12.500000 (15.123457)
Epoch: [2][ 96/591]	Time  0.589 ( 0.646)	Data  0.491 ( 0.548)	Loss 1.3982e+00 (1.3433e+00)	Acc@1 18.750000 (15.141752)
Epoch: [2][112/591]	Time  0.628 ( 0.646)	Data  0.530 ( 0.548)	Loss 1.4501e+00 (1.3419e+00)	Acc@1 12.500000 (14.878319)
Epoch: [2][128/591]	Time  0.641 ( 0.645)	Data  0.543 ( 0.547)	Loss 1.3957e+00 (1.3383e+00)	Acc@1 18.750000 (15.067829)
Epoch: [2][144/591]	Time  0.870 ( 0.648)	Data  0.767 ( 0.550)	Loss 1.3306e+00 (1.3411e+00)	Acc@1 43.750000 (15.344828)
Epoch: [2][160/591]	Time  0.617 ( 0.649)	Data  0.518 ( 0.551)	Loss 1.3710e+00 (1.3429e+00)	Acc@1 6.250000 (15.217392)
Epoch: [2][176/591]	Time  0.585 ( 0.649)	Data  0.487 ( 0.551)	Loss 1.5659e+00 (1.3470e+00)	Acc@1 0.000000 (15.148305)
Epoch: [2][192/591]	Time  0.615 ( 0.650)	Data  0.517 ( 0.552)	Loss 1.3215e+00 (1.3460e+00)	Acc@1 12.500000 (15.025907)
Epoch: [2][208/591]	Time  0.630 ( 0.650)	Data  0.533 ( 0.552)	Loss 1.3939e+00 (1.3471e+00)	Acc@1 43.750000 (14.982057)
Epoch: [2][224/591]	Time  0.629 ( 0.650)	Data  0.532 ( 0.552)	Loss 1.4319e+00 (1.3504e+00)	Acc@1 6.250000 (14.972222)
Epoch: [2][240/591]	Time  0.666 ( 0.654)	Data  0.568 ( 0.556)	Loss 1.2969e+00 (1.3553e+00)	Acc@1 12.500000 (14.911826)
Epoch: [2][256/591]	Time  0.667 ( 0.653)	Data  0.570 ( 0.555)	Loss 1.4028e+00 (1.3540e+00)	Acc@1 25.000000 (15.102140)
Epoch: [2][272/591]	Time  0.634 ( 0.651)	Data  0.536 ( 0.553)	Loss 1.4205e+00 (1.3537e+00)	Acc@1 6.250000 (15.132784)
Epoch: [2][288/591]	Time  0.616 ( 0.651)	Data  0.518 ( 0.553)	Loss 1.3396e+00 (1.3524e+00)	Acc@1 18.750000 (15.008651)
Epoch: [2][304/591]	Time  0.613 ( 0.649)	Data  0.515 ( 0.551)	Loss 1.3710e+00 (1.3515e+00)	Acc@1 18.750000 (15.184426)
Epoch: [2][320/591]	Time  0.592 ( 0.648)	Data  0.494 ( 0.550)	Loss 1.4808e+00 (1.3501e+00)	Acc@1 12.500000 (15.264797)
Epoch: [2][336/591]	Time  0.661 ( 0.650)	Data  0.563 ( 0.552)	Loss 9.7993e-01 (1.3465e+00)	Acc@1 12.500000 (15.356083)
Epoch: [2][352/591]	Time  0.625 ( 0.651)	Data  0.527 ( 0.552)	Loss 1.2752e+00 (1.3452e+00)	Acc@1 18.750000 (15.279745)
Epoch: [2][368/591]	Time  0.735 ( 0.650)	Data  0.637 ( 0.552)	Loss 1.1745e+00 (1.3418e+00)	Acc@1 18.750000 (15.379404)
Epoch: [2][384/591]	Time  0.610 ( 0.649)	Data  0.512 ( 0.551)	Loss 1.3835e+00 (1.3420e+00)	Acc@1 18.750000 (15.422077)
Epoch: [2][400/591]	Time  0.642 ( 0.649)	Data  0.544 ( 0.551)	Loss 1.3321e+00 (1.3426e+00)	Acc@1 31.250000 (15.601622)
Epoch: [2][416/591]	Time  0.617 ( 0.649)	Data  0.520 ( 0.551)	Loss 1.3318e+00 (1.3436e+00)	Acc@1 6.250000 (15.707435)
Epoch: [2][432/591]	Time  0.606 ( 0.651)	Data  0.509 ( 0.553)	Loss 1.2464e+00 (1.3442e+00)	Acc@1 18.750000 (15.661085)
Epoch: [2][448/591]	Time  0.622 ( 0.651)	Data  0.524 ( 0.553)	Loss 1.1578e+00 (1.3436e+00)	Acc@1 6.250000 (15.576282)
Epoch: [2][464/591]	Time  0.586 ( 0.651)	Data  0.488 ( 0.552)	Loss 1.4281e+00 (1.3446e+00)	Acc@1 0.000000 (15.591398)
Epoch: [2][480/591]	Time  0.620 ( 0.650)	Data  0.522 ( 0.552)	Loss 1.1730e+00 (1.3450e+00)	Acc@1 12.500000 (15.553535)
Epoch: [2][496/591]	Time  0.648 ( 0.652)	Data  0.550 ( 0.554)	Loss 1.3472e+00 (1.3430e+00)	Acc@1 12.500000 (15.518108)
Epoch: [2][512/591]	Time  0.589 ( 0.654)	Data  0.491 ( 0.555)	Loss 1.1539e+00 (1.3429e+00)	Acc@1 12.500000 (15.594542)
Epoch: [2][528/591]	Time  0.597 ( 0.653)	Data  0.500 ( 0.555)	Loss 1.4679e+00 (1.3422e+00)	Acc@1 6.250000 (15.465502)
Epoch: [2][544/591]	Time  0.640 ( 0.652)	Data  0.543 ( 0.554)	Loss 1.4077e+00 (1.3405e+00)	Acc@1 6.250000 (15.493119)
Epoch: [2][560/591]	Time  0.636 ( 0.653)	Data  0.538 ( 0.555)	Loss 1.3715e+00 (1.3408e+00)	Acc@1 25.000000 (15.508021)
Epoch: [2][576/591]	Time  0.603 ( 0.653)	Data  0.505 ( 0.555)	Loss 1.3251e+00 (1.3405e+00)	Acc@1 18.750000 (15.489601)
##################################################
train_loss:  1.3394415896959515
train_acc:  tensor(15.5457, device='cuda:0')
##################################################
Best model was saved.
Epoch: [3][  0/591]	Time  0.628 ( 0.628)	Data  0.530 ( 0.530)	Loss 1.3994e+00 (1.3994e+00)	Acc@1 18.750000 (18.750000)
Epoch: [3][ 16/591]	Time  0.570 ( 0.722)	Data  0.472 ( 0.622)	Loss 1.2370e+00 (1.3530e+00)	Acc@1 18.750000 (15.441176)
Epoch: [3][ 32/591]	Time  0.638 ( 0.685)	Data  0.539 ( 0.586)	Loss 1.2105e+00 (1.3429e+00)	Acc@1 31.250000 (15.909091)
Epoch: [3][ 48/591]	Time  0.582 ( 0.667)	Data  0.484 ( 0.568)	Loss 1.2850e+00 (1.3232e+00)	Acc@1 12.500000 (16.071428)
Epoch: [3][ 64/591]	Time  0.625 ( 0.657)	Data  0.527 ( 0.558)	Loss 1.2784e+00 (1.3146e+00)	Acc@1 12.500000 (16.538462)
Epoch: [3][ 80/591]	Time  0.653 ( 0.653)	Data  0.556 ( 0.554)	Loss 1.3334e+00 (1.3220e+00)	Acc@1 12.500000 (16.049383)
Epoch: [3][ 96/591]	Time  0.611 ( 0.648)	Data  0.513 ( 0.550)	Loss 1.4713e+00 (1.3236e+00)	Acc@1 25.000000 (16.365978)
Epoch: [3][112/591]	Time  0.609 ( 0.659)	Data  0.512 ( 0.561)	Loss 1.2437e+00 (1.3156e+00)	Acc@1 18.750000 (16.482302)
Epoch: [3][128/591]	Time  0.625 ( 0.655)	Data  0.527 ( 0.557)	Loss 1.3168e+00 (1.3116e+00)	Acc@1 18.750000 (16.472868)
Epoch: [3][144/591]	Time  0.644 ( 0.653)	Data  0.546 ( 0.555)	Loss 1.2932e+00 (1.3134e+00)	Acc@1 6.250000 (16.465517)
Epoch: [3][160/591]	Time  0.583 ( 0.653)	Data  0.485 ( 0.555)	Loss 1.4553e+00 (1.3183e+00)	Acc@1 25.000000 (16.343168)
Epoch: [3][176/591]	Time  0.604 ( 0.652)	Data  0.506 ( 0.554)	Loss 1.3267e+00 (1.3170e+00)	Acc@1 6.250000 (16.313559)
Epoch: [3][192/591]	Time  0.982 ( 0.657)	Data  0.866 ( 0.559)	Loss 1.2570e+00 (1.3155e+00)	Acc@1 18.750000 (16.256475)
Epoch: [3][208/591]	Time  0.621 ( 0.655)	Data  0.524 ( 0.557)	Loss 1.0972e+00 (1.3122e+00)	Acc@1 18.750000 (16.537081)
Epoch: [3][224/591]	Time  0.612 ( 0.653)	Data  0.515 ( 0.554)	Loss 1.3390e+00 (1.3089e+00)	Acc@1 6.250000 (16.694445)
Epoch: [3][240/591]	Time  0.640 ( 0.651)	Data  0.542 ( 0.553)	Loss 1.3819e+00 (1.3103e+00)	Acc@1 18.750000 (16.830914)
Epoch: [3][256/591]	Time  0.608 ( 0.652)	Data  0.511 ( 0.554)	Loss 1.3694e+00 (1.3110e+00)	Acc@1 18.750000 (16.877432)
Epoch: [3][272/591]	Time  0.638 ( 0.651)	Data  0.541 ( 0.553)	Loss 1.2002e+00 (1.3123e+00)	Acc@1 25.000000 (16.987179)
Epoch: [3][288/591]	Time  0.590 ( 0.653)	Data  0.493 ( 0.555)	Loss 1.2884e+00 (1.3110e+00)	Acc@1 6.250000 (17.084776)
Epoch: [3][304/591]	Time  0.618 ( 0.652)	Data  0.521 ( 0.554)	Loss 9.9750e-01 (1.3099e+00)	Acc@1 18.750000 (17.110655)
Epoch: [3][320/591]	Time  0.653 ( 0.652)	Data  0.556 ( 0.554)	Loss 1.3720e+00 (1.3081e+00)	Acc@1 12.500000 (17.289719)
Epoch: [3][336/591]	Time  0.645 ( 0.652)	Data  0.547 ( 0.554)	Loss 1.1169e+00 (1.3050e+00)	Acc@1 25.000000 (17.525965)
Epoch: [3][352/591]	Time  0.663 ( 0.653)	Data  0.566 ( 0.555)	Loss 1.2352e+00 (1.3045e+00)	Acc@1 25.000000 (17.422096)
Epoch: [3][368/591]	Time  0.669 ( 0.653)	Data  0.572 ( 0.555)	Loss 1.2846e+00 (1.3028e+00)	Acc@1 12.500000 (17.293362)
Epoch: [3][384/591]	Time  0.850 ( 0.656)	Data  0.751 ( 0.558)	Loss 1.3618e+00 (1.3049e+00)	Acc@1 12.500000 (17.337662)
Epoch: [3][400/591]	Time  0.585 ( 0.654)	Data  0.487 ( 0.556)	Loss 1.2444e+00 (1.3061e+00)	Acc@1 37.500000 (17.409601)
Epoch: [3][416/591]	Time  0.631 ( 0.654)	Data  0.533 ( 0.556)	Loss 1.4250e+00 (1.3083e+00)	Acc@1 0.000000 (17.311152)
Epoch: [3][432/591]	Time  0.660 ( 0.653)	Data  0.562 ( 0.555)	Loss 1.0452e+00 (1.3091e+00)	Acc@1 6.250000 (17.234411)
Epoch: [3][448/591]	Time  0.598 ( 0.652)	Data  0.499 ( 0.554)	Loss 1.2669e+00 (1.3071e+00)	Acc@1 18.750000 (17.135302)
Epoch: [3][464/591]	Time  0.840 ( 0.654)	Data  0.736 ( 0.556)	Loss 1.1491e+00 (1.3037e+00)	Acc@1 25.000000 (17.096775)
Epoch: [3][480/591]	Time  0.645 ( 0.655)	Data  0.548 ( 0.557)	Loss 1.3726e+00 (1.3045e+00)	Acc@1 6.250000 (16.995842)
Epoch: [3][496/591]	Time  0.591 ( 0.655)	Data  0.493 ( 0.557)	Loss 1.2900e+00 (1.3041e+00)	Acc@1 6.250000 (16.951710)
Epoch: [3][512/591]	Time  0.618 ( 0.654)	Data  0.519 ( 0.556)	Loss 1.4404e+00 (1.3054e+00)	Acc@1 25.000000 (16.983431)
Epoch: [3][528/591]	Time  0.577 ( 0.654)	Data  0.479 ( 0.556)	Loss 1.2973e+00 (1.3038e+00)	Acc@1 18.750000 (16.954159)
Epoch: [3][544/591]	Time  0.675 ( 0.654)	Data  0.577 ( 0.556)	Loss 1.0781e+00 (1.3032e+00)	Acc@1 31.250000 (17.110092)
Epoch: [3][560/591]	Time  0.658 ( 0.656)	Data  0.560 ( 0.558)	Loss 1.2931e+00 (1.3047e+00)	Acc@1 12.500000 (17.000891)
Epoch: [3][576/591]	Time  0.614 ( 0.655)	Data  0.516 ( 0.557)	Loss 1.4022e+00 (1.3049e+00)	Acc@1 18.750000 (16.973570)
##################################################
train_loss:  1.3045643273545602
train_acc:  tensor(16.9628, device='cuda:0')
##################################################
Best model was saved.
Epoch: [4][  0/591]	Time  0.650 ( 0.650)	Data  0.552 ( 0.552)	Loss 1.4463e+00 (1.4463e+00)	Acc@1 18.750000 (18.750000)
Epoch: [4][ 16/591]	Time  0.618 ( 0.626)	Data  0.521 ( 0.528)	Loss 1.2744e+00 (1.3140e+00)	Acc@1 12.500000 (15.808824)
Epoch: [4][ 32/591]	Time  0.643 ( 0.628)	Data  0.546 ( 0.530)	Loss 1.1286e+00 (1.2951e+00)	Acc@1 25.000000 (17.613636)
Epoch: [4][ 48/591]	Time  0.588 ( 0.632)	Data  0.490 ( 0.535)	Loss 1.2598e+00 (1.2875e+00)	Acc@1 37.500000 (16.836735)
Epoch: [4][ 64/591]	Time  0.680 ( 0.647)	Data  0.582 ( 0.548)	Loss 1.3615e+00 (1.2738e+00)	Acc@1 18.750000 (16.250000)
Epoch: [4][ 80/591]	Time  0.619 ( 0.643)	Data  0.521 ( 0.545)	Loss 1.0487e+00 (1.2820e+00)	Acc@1 37.500000 (17.669754)
Epoch: [4][ 96/591]	Time  0.617 ( 0.643)	Data  0.519 ( 0.545)	Loss 1.1202e+00 (1.2770e+00)	Acc@1 25.000000 (18.105669)
Epoch: [4][112/591]	Time  0.672 ( 0.644)	Data  0.574 ( 0.546)	Loss 1.3153e+00 (1.2794e+00)	Acc@1 12.500000 (18.141592)
Epoch: [4][128/591]	Time  0.681 ( 0.643)	Data  0.583 ( 0.545)	Loss 1.2364e+00 (1.2779e+00)	Acc@1 6.250000 (17.732557)
Epoch: [4][144/591]	Time  0.584 ( 0.645)	Data  0.486 ( 0.547)	Loss 1.0752e+00 (1.2753e+00)	Acc@1 0.000000 (17.801723)
Epoch: [4][160/591]	Time  0.641 ( 0.651)	Data  0.542 ( 0.553)	Loss 1.3625e+00 (1.2791e+00)	Acc@1 31.250000 (17.934782)
Epoch: [4][176/591]	Time  0.559 ( 0.650)	Data  0.461 ( 0.552)	Loss 1.3481e+00 (1.2817e+00)	Acc@1 18.750000 (17.549435)
Epoch: [4][192/591]	Time  0.597 ( 0.647)	Data  0.499 ( 0.549)	Loss 1.2682e+00 (1.2776e+00)	Acc@1 25.000000 (17.519430)
Epoch: [4][208/591]	Time  0.592 ( 0.645)	Data  0.494 ( 0.546)	Loss 1.3922e+00 (1.2780e+00)	Acc@1 37.500000 (17.733253)
Epoch: [4][224/591]	Time  0.590 ( 0.644)	Data  0.492 ( 0.546)	Loss 1.3830e+00 (1.2792e+00)	Acc@1 6.250000 (17.527779)
Epoch: [4][240/591]	Time  0.950 ( 0.648)	Data  0.844 ( 0.549)	Loss 1.1276e+00 (1.2816e+00)	Acc@1 25.000000 (17.997927)
Epoch: [4][256/591]	Time  0.626 ( 0.651)	Data  0.528 ( 0.553)	Loss 1.0944e+00 (1.2820e+00)	Acc@1 25.000000 (18.020428)
Epoch: [4][272/591]	Time  0.656 ( 0.650)	Data  0.559 ( 0.552)	Loss 1.4606e+00 (1.2819e+00)	Acc@1 12.500000 (18.154762)
Epoch: [4][288/591]	Time  0.601 ( 0.651)	Data  0.503 ( 0.553)	Loss 1.1313e+00 (1.2803e+00)	Acc@1 18.750000 (18.576990)
Epoch: [4][304/591]	Time  0.747 ( 0.652)	Data  0.649 ( 0.553)	Loss 1.2150e+00 (1.2785e+00)	Acc@1 31.250000 (18.668034)
Epoch: [4][320/591]	Time  0.621 ( 0.651)	Data  0.523 ( 0.553)	Loss 1.4219e+00 (1.2820e+00)	Acc@1 31.250000 (18.750000)
Epoch: [4][336/591]	Time  0.606 ( 0.653)	Data  0.508 ( 0.555)	Loss 1.3171e+00 (1.2825e+00)	Acc@1 31.250000 (18.675816)
Epoch: [4][352/591]	Time  0.620 ( 0.652)	Data  0.522 ( 0.554)	Loss 1.2835e+00 (1.2840e+00)	Acc@1 25.000000 (18.626062)
Epoch: [4][368/591]	Time  0.586 ( 0.652)	Data  0.489 ( 0.554)	Loss 1.4382e+00 (1.2839e+00)	Acc@1 12.500000 (18.445122)
Epoch: [4][384/591]	Time  0.603 ( 0.652)	Data  0.505 ( 0.554)	Loss 1.0736e+00 (1.2841e+00)	Acc@1 25.000000 (18.457792)
Epoch: [4][400/591]	Time  0.906 ( 0.652)	Data  0.808 ( 0.554)	Loss 1.0482e+00 (1.2830e+00)	Acc@1 25.000000 (18.438280)
Epoch: [4][416/591]	Time  0.647 ( 0.653)	Data  0.550 ( 0.555)	Loss 1.2483e+00 (1.2834e+00)	Acc@1 25.000000 (18.390287)
Epoch: [4][432/591]	Time  0.612 ( 0.656)	Data  0.514 ( 0.558)	Loss 1.1828e+00 (1.2835e+00)	Acc@1 25.000000 (18.547922)
Epoch: [4][448/591]	Time  0.606 ( 0.655)	Data  0.508 ( 0.557)	Loss 1.1523e+00 (1.2803e+00)	Acc@1 25.000000 (18.736080)
Epoch: [4][464/591]	Time  0.632 ( 0.654)	Data  0.534 ( 0.556)	Loss 1.3922e+00 (1.2799e+00)	Acc@1 31.250000 (18.924732)
Epoch: [4][480/591]	Time  0.742 ( 0.654)	Data  0.644 ( 0.556)	Loss 1.2963e+00 (1.2802e+00)	Acc@1 12.500000 (18.983889)
Epoch: [4][496/591]	Time  0.629 ( 0.653)	Data  0.532 ( 0.555)	Loss 1.4736e+00 (1.2774e+00)	Acc@1 6.250000 (18.938631)
Epoch: [4][512/591]	Time  0.616 ( 0.653)	Data  0.517 ( 0.555)	Loss 1.2751e+00 (1.2782e+00)	Acc@1 31.250000 (19.005848)
Epoch: [4][528/591]	Time  0.660 ( 0.654)	Data  0.563 ( 0.556)	Loss 1.0441e+00 (1.2786e+00)	Acc@1 25.000000 (19.151701)
Epoch: [4][544/591]	Time  0.637 ( 0.654)	Data  0.540 ( 0.556)	Loss 1.1789e+00 (1.2760e+00)	Acc@1 18.750000 (19.162844)
Epoch: [4][560/591]	Time  0.606 ( 0.654)	Data  0.509 ( 0.555)	Loss 1.2612e+00 (1.2753e+00)	Acc@1 25.000000 (19.217915)
Epoch: [4][576/591]	Time  0.572 ( 0.653)	Data  0.475 ( 0.555)	Loss 1.2528e+00 (1.2749e+00)	Acc@1 18.750000 (19.291594)
##################################################
train_loss:  1.2738632649536261
train_acc:  tensor(19.3211, device='cuda:0')
##################################################
Best model was saved.
Epoch: [5][  0/591]	Time  0.621 ( 0.621)	Data  0.516 ( 0.516)	Loss 1.2559e+00 (1.2559e+00)	Acc@1 37.500000 (37.500000)
Epoch: [5][ 16/591]	Time  0.603 ( 0.708)	Data  0.505 ( 0.608)	Loss 1.4141e+00 (1.2192e+00)	Acc@1 25.000000 (22.426470)
Epoch: [5][ 32/591]	Time  0.629 ( 0.667)	Data  0.532 ( 0.568)	Loss 1.0434e+00 (1.2215e+00)	Acc@1 18.750000 (21.022728)
Epoch: [5][ 48/591]	Time  0.608 ( 0.665)	Data  0.511 ( 0.567)	Loss 1.3512e+00 (1.2253e+00)	Acc@1 12.500000 (21.428572)
Epoch: [5][ 64/591]	Time  0.652 ( 0.659)	Data  0.554 ( 0.561)	Loss 1.3414e+00 (1.2239e+00)	Acc@1 0.000000 (22.019230)
Epoch: [5][ 80/591]	Time  0.596 ( 0.658)	Data  0.499 ( 0.559)	Loss 1.2710e+00 (1.2365e+00)	Acc@1 0.000000 (21.373457)
Epoch: [5][ 96/591]	Time  0.671 ( 0.655)	Data  0.573 ( 0.557)	Loss 1.1277e+00 (1.2366e+00)	Acc@1 25.000000 (21.456184)
Epoch: [5][112/591]	Time  0.623 ( 0.662)	Data  0.526 ( 0.563)	Loss 1.3215e+00 (1.2403e+00)	Acc@1 12.500000 (20.962389)
Epoch: [5][128/591]	Time  0.633 ( 0.658)	Data  0.535 ( 0.560)	Loss 1.3191e+00 (1.2342e+00)	Acc@1 12.500000 (20.155039)
Epoch: [5][144/591]	Time  0.641 ( 0.657)	Data  0.543 ( 0.559)	Loss 1.2437e+00 (1.2360e+00)	Acc@1 6.250000 (20.043104)
Epoch: [5][160/591]	Time  0.616 ( 0.656)	Data  0.517 ( 0.558)	Loss 1.2562e+00 (1.2342e+00)	Acc@1 37.500000 (20.302795)
Epoch: [5][176/591]	Time  0.649 ( 0.656)	Data  0.552 ( 0.558)	Loss 1.3014e+00 (1.2350e+00)	Acc@1 25.000000 (19.915255)
Epoch: [5][192/591]	Time  0.760 ( 0.656)	Data  0.660 ( 0.558)	Loss 1.2404e+00 (1.2354e+00)	Acc@1 31.250000 (19.915802)
Epoch: [5][208/591]	Time  0.629 ( 0.661)	Data  0.532 ( 0.563)	Loss 1.0455e+00 (1.2358e+00)	Acc@1 25.000000 (20.125597)
Epoch: [5][224/591]	Time  0.646 ( 0.660)	Data  0.548 ( 0.562)	Loss 1.4599e+00 (1.2408e+00)	Acc@1 12.500000 (20.472223)
Epoch: [5][240/591]	Time  0.626 ( 0.659)	Data  0.529 ( 0.561)	Loss 1.2819e+00 (1.2423e+00)	Acc@1 12.500000 (20.539421)
Epoch: [5][256/591]	Time  0.638 ( 0.656)	Data  0.540 ( 0.558)	Loss 1.3255e+00 (1.2414e+00)	Acc@1 25.000000 (20.598249)
Epoch: [5][272/591]	Time  0.603 ( 0.655)	Data  0.505 ( 0.556)	Loss 1.2644e+00 (1.2453e+00)	Acc@1 25.000000 (20.306776)
Epoch: [5][288/591]	Time  0.915 ( 0.657)	Data  0.811 ( 0.558)	Loss 1.1136e+00 (1.2449e+00)	Acc@1 25.000000 (20.220589)
Epoch: [5][304/591]	Time  0.627 ( 0.656)	Data  0.530 ( 0.558)	Loss 1.4213e+00 (1.2485e+00)	Acc@1 31.250000 (20.204918)
Epoch: [5][320/591]	Time  0.590 ( 0.655)	Data  0.493 ( 0.557)	Loss 1.2109e+00 (1.2477e+00)	Acc@1 0.000000 (20.288162)
Epoch: [5][336/591]	Time  0.578 ( 0.654)	Data  0.481 ( 0.556)	Loss 1.1779e+00 (1.2451e+00)	Acc@1 12.500000 (20.159496)
Epoch: [5][352/591]	Time  0.612 ( 0.653)	Data  0.515 ( 0.555)	Loss 1.2192e+00 (1.2449e+00)	Acc@1 25.000000 (20.113314)
Epoch: [5][368/591]	Time  0.582 ( 0.653)	Data  0.484 ( 0.555)	Loss 1.4031e+00 (1.2429e+00)	Acc@1 25.000000 (20.105015)
Epoch: [5][384/591]	Time  0.643 ( 0.655)	Data  0.545 ( 0.557)	Loss 9.0406e-01 (1.2412e+00)	Acc@1 25.000000 (20.032467)
Epoch: [5][400/591]	Time  0.710 ( 0.654)	Data  0.613 ( 0.556)	Loss 1.2704e+00 (1.2420e+00)	Acc@1 18.750000 (19.918953)
Epoch: [5][416/591]	Time  0.732 ( 0.655)	Data  0.635 ( 0.557)	Loss 1.1638e+00 (1.2427e+00)	Acc@1 18.750000 (19.754196)
Epoch: [5][432/591]	Time  0.622 ( 0.654)	Data  0.524 ( 0.556)	Loss 1.2241e+00 (1.2383e+00)	Acc@1 18.750000 (19.875866)
Epoch: [5][448/591]	Time  0.611 ( 0.655)	Data  0.514 ( 0.557)	Loss 1.3348e+00 (1.2353e+00)	Acc@1 25.000000 (20.030624)
Epoch: [5][464/591]	Time  0.652 ( 0.654)	Data  0.554 ( 0.556)	Loss 1.0828e+00 (1.2326e+00)	Acc@1 25.000000 (20.147850)
Epoch: [5][480/591]	Time  0.620 ( 0.656)	Data  0.523 ( 0.558)	Loss 1.2405e+00 (1.2304e+00)	Acc@1 25.000000 (20.270271)
Epoch: [5][496/591]	Time  0.597 ( 0.655)	Data  0.500 ( 0.557)	Loss 1.1446e+00 (1.2284e+00)	Acc@1 12.500000 (20.347082)
Epoch: [5][512/591]	Time  0.839 ( 0.655)	Data  0.740 ( 0.557)	Loss 1.2834e+00 (1.2274e+00)	Acc@1 18.750000 (20.443470)
Epoch: [5][528/591]	Time  0.611 ( 0.655)	Data  0.514 ( 0.556)	Loss 1.1907e+00 (1.2267e+00)	Acc@1 18.750000 (20.309547)
Epoch: [5][544/591]	Time  0.683 ( 0.654)	Data  0.585 ( 0.555)	Loss 1.0642e+00 (1.2224e+00)	Acc@1 31.250000 (20.389908)
Epoch: [5][560/591]	Time  0.593 ( 0.653)	Data  0.495 ( 0.554)	Loss 1.0954e+00 (1.2196e+00)	Acc@1 31.250000 (20.510248)
Epoch: [5][576/591]	Time  0.658 ( 0.654)	Data  0.561 ( 0.556)	Loss 1.1810e+00 (1.2183e+00)	Acc@1 25.000000 (20.537262)
##################################################
train_loss:  1.2171357572582975
train_acc:  tensor(20.5795, device='cuda:0')
##################################################
Best model was saved.
Epoch: [6][  0/591]	Time  0.642 ( 0.642)	Data  0.545 ( 0.545)	Loss 1.4992e+00 (1.4992e+00)	Acc@1 18.750000 (18.750000)
Epoch: [6][ 16/591]	Time  0.637 ( 0.625)	Data  0.539 ( 0.528)	Loss 1.1565e+00 (1.1835e+00)	Acc@1 6.250000 (18.750000)
Epoch: [6][ 32/591]	Time  0.641 ( 0.640)	Data  0.543 ( 0.543)	Loss 1.1577e+00 (1.2014e+00)	Acc@1 18.750000 (20.075758)
Epoch: [6][ 48/591]	Time  0.608 ( 0.631)	Data  0.510 ( 0.533)	Loss 1.0561e+00 (1.2029e+00)	Acc@1 25.000000 (21.683674)
Epoch: [6][ 64/591]	Time  1.029 ( 0.655)	Data  0.922 ( 0.557)	Loss 1.4014e+00 (1.1972e+00)	Acc@1 18.750000 (20.769230)
Epoch: [6][ 80/591]	Time  0.602 ( 0.663)	Data  0.503 ( 0.565)	Loss 1.0635e+00 (1.2025e+00)	Acc@1 18.750000 (21.219135)
Epoch: [6][ 96/591]	Time  0.596 ( 0.656)	Data  0.499 ( 0.558)	Loss 1.0812e+00 (1.1880e+00)	Acc@1 43.750000 (20.876287)
Epoch: [6][112/591]	Time  0.639 ( 0.652)	Data  0.541 ( 0.554)	Loss 9.9015e-01 (1.1886e+00)	Acc@1 25.000000 (20.519911)
Epoch: [6][128/591]	Time  0.612 ( 0.651)	Data  0.515 ( 0.553)	Loss 1.1456e+00 (1.1887e+00)	Acc@1 12.500000 (20.591085)
Epoch: [6][144/591]	Time  0.589 ( 0.650)	Data  0.491 ( 0.552)	Loss 1.0876e+00 (1.1903e+00)	Acc@1 37.500000 (20.474138)
Epoch: [6][160/591]	Time  0.611 ( 0.656)	Data  0.514 ( 0.558)	Loss 1.3684e+00 (1.1917e+00)	Acc@1 12.500000 (20.147516)
Epoch: [6][176/591]	Time  0.592 ( 0.657)	Data  0.495 ( 0.559)	Loss 1.2841e+00 (1.1963e+00)	Acc@1 12.500000 (19.915255)
Epoch: [6][192/591]	Time  0.604 ( 0.654)	Data  0.506 ( 0.557)	Loss 9.5554e-01 (1.1944e+00)	Acc@1 12.500000 (20.077721)
Epoch: [6][208/591]	Time  0.611 ( 0.652)	Data  0.512 ( 0.554)	Loss 1.0590e+00 (1.1923e+00)	Acc@1 12.500000 (20.005980)
Epoch: [6][224/591]	Time  0.713 ( 0.652)	Data  0.615 ( 0.554)	Loss 1.0690e+00 (1.1880e+00)	Acc@1 25.000000 (19.777779)
Epoch: [6][240/591]	Time  0.602 ( 0.649)	Data  0.504 ( 0.552)	Loss 1.1647e+00 (1.1860e+00)	Acc@1 12.500000 (19.917013)
Epoch: [6][256/591]	Time  0.614 ( 0.655)	Data  0.517 ( 0.557)	Loss 1.1290e+00 (1.1845e+00)	Acc@1 18.750000 (20.111868)
Epoch: [6][272/591]	Time  0.601 ( 0.654)	Data  0.504 ( 0.556)	Loss 1.3165e+00 (1.1826e+00)	Acc@1 6.250000 (20.146521)
Epoch: [6][288/591]	Time  0.619 ( 0.653)	Data  0.522 ( 0.555)	Loss 1.1426e+00 (1.1810e+00)	Acc@1 25.000000 (20.436852)
Epoch: [6][304/591]	Time  0.617 ( 0.652)	Data  0.519 ( 0.554)	Loss 1.0243e+00 (1.1799e+00)	Acc@1 18.750000 (20.348360)
Epoch: [6][320/591]	Time  0.892 ( 0.652)	Data  0.795 ( 0.554)	Loss 1.3102e+00 (1.1767e+00)	Acc@1 18.750000 (20.073986)
Epoch: [6][336/591]	Time  0.614 ( 0.652)	Data  0.517 ( 0.554)	Loss 1.4377e+00 (1.1751e+00)	Acc@1 31.250000 (19.992582)
Epoch: [6][352/591]	Time  0.662 ( 0.654)	Data  0.565 ( 0.556)	Loss 1.1251e+00 (1.1724e+00)	Acc@1 31.250000 (19.953966)
Epoch: [6][368/591]	Time  0.602 ( 0.652)	Data  0.505 ( 0.554)	Loss 1.0452e+00 (1.1692e+00)	Acc@1 31.250000 (20.274391)
Epoch: [6][384/591]	Time  0.823 ( 0.651)	Data  0.725 ( 0.553)	Loss 1.2437e+00 (1.1672e+00)	Acc@1 18.750000 (20.178572)
Epoch: [6][400/591]	Time  0.642 ( 0.651)	Data  0.544 ( 0.553)	Loss 1.1683e+00 (1.1642e+00)	Acc@1 12.500000 (20.168329)
Epoch: [6][416/591]	Time  0.622 ( 0.650)	Data  0.525 ( 0.552)	Loss 1.0367e+00 (1.1624e+00)	Acc@1 31.250000 (20.398682)
Epoch: [6][432/591]	Time  0.954 ( 0.650)	Data  0.846 ( 0.552)	Loss 1.2800e+00 (1.1620e+00)	Acc@1 37.500000 (20.525404)
Epoch: [6][448/591]	Time  0.600 ( 0.651)	Data  0.502 ( 0.553)	Loss 1.0403e+00 (1.1603e+00)	Acc@1 37.500000 (20.712696)
Epoch: [6][464/591]	Time  0.650 ( 0.651)	Data  0.553 ( 0.553)	Loss 1.2819e+00 (1.1597e+00)	Acc@1 43.750000 (20.913979)
Epoch: [6][480/591]	Time  0.617 ( 0.650)	Data  0.519 ( 0.552)	Loss 1.2869e+00 (1.1581e+00)	Acc@1 25.000000 (21.062889)
Epoch: [6][496/591]	Time  0.630 ( 0.649)	Data  0.532 ( 0.551)	Loss 1.0407e+00 (1.1549e+00)	Acc@1 12.500000 (21.114183)
Epoch: [6][512/591]	Time  0.649 ( 0.648)	Data  0.552 ( 0.550)	Loss 9.8754e-01 (1.1534e+00)	Acc@1 12.500000 (21.211014)
Epoch: [6][528/591]	Time  0.680 ( 0.649)	Data  0.583 ( 0.551)	Loss 9.7712e-01 (1.1547e+00)	Acc@1 12.500000 (21.112949)
Epoch: [6][544/591]	Time  0.609 ( 0.648)	Data  0.511 ( 0.550)	Loss 1.0744e+00 (1.1524e+00)	Acc@1 12.500000 (21.123854)
Epoch: [6][560/591]	Time  0.609 ( 0.648)	Data  0.511 ( 0.550)	Loss 1.0700e+00 (1.1516e+00)	Acc@1 18.750000 (21.111853)
Epoch: [6][576/591]	Time  0.776 ( 0.650)	Data  0.678 ( 0.552)	Loss 7.4894e-01 (1.1506e+00)	Acc@1 6.250000 (21.100519)
##################################################
train_loss:  1.1499437170383693
train_acc:  tensor(21.0448, device='cuda:0')
##################################################
Best model was saved.
Epoch: [7][  0/591]	Time  0.834 ( 0.834)	Data  0.736 ( 0.736)	Loss 1.0661e+00 (1.0661e+00)	Acc@1 37.500000 (37.500000)
Epoch: [7][ 16/591]	Time  0.642 ( 0.645)	Data  0.545 ( 0.547)	Loss 1.0290e+00 (1.1234e+00)	Acc@1 25.000000 (21.323530)
Epoch: [7][ 32/591]	Time  0.590 ( 0.665)	Data  0.493 ( 0.566)	Loss 1.0240e+00 (1.1025e+00)	Acc@1 25.000000 (22.159092)
Epoch: [7][ 48/591]	Time  0.583 ( 0.680)	Data  0.486 ( 0.582)	Loss 9.8239e-01 (1.1209e+00)	Acc@1 12.500000 (21.428572)
Epoch: [7][ 64/591]	Time  0.650 ( 0.672)	Data  0.550 ( 0.573)	Loss 1.0756e+00 (1.1182e+00)	Acc@1 6.250000 (21.730770)
Epoch: [7][ 80/591]	Time  0.577 ( 0.669)	Data  0.480 ( 0.570)	Loss 1.1760e+00 (1.1057e+00)	Acc@1 18.750000 (21.759260)
Epoch: [7][ 96/591]	Time  0.598 ( 0.666)	Data  0.501 ( 0.568)	Loss 9.1375e-01 (1.1031e+00)	Acc@1 25.000000 (22.036081)
Epoch: [7][112/591]	Time  1.026 ( 0.671)	Data  0.922 ( 0.572)	Loss 9.8214e-01 (1.1053e+00)	Acc@1 12.500000 (21.460176)
Epoch: [7][128/591]	Time  0.623 ( 0.666)	Data  0.525 ( 0.567)	Loss 1.1628e+00 (1.1021e+00)	Acc@1 25.000000 (21.656977)
Epoch: [7][144/591]	Time  0.588 ( 0.665)	Data  0.490 ( 0.567)	Loss 1.2020e+00 (1.1065e+00)	Acc@1 18.750000 (21.293104)
Epoch: [7][160/591]	Time  0.622 ( 0.663)	Data  0.523 ( 0.564)	Loss 1.2924e+00 (1.1064e+00)	Acc@1 18.750000 (21.273293)
Epoch: [7][176/591]	Time  0.655 ( 0.660)	Data  0.557 ( 0.561)	Loss 1.0060e+00 (1.1125e+00)	Acc@1 43.750000 (21.362995)
Epoch: [7][192/591]	Time  0.637 ( 0.658)	Data  0.539 ( 0.560)	Loss 1.0975e+00 (1.1108e+00)	Acc@1 31.250000 (21.632124)
Epoch: [7][208/591]	Time  0.589 ( 0.661)	Data  0.491 ( 0.562)	Loss 1.0297e+00 (1.1114e+00)	Acc@1 37.500000 (21.620813)
Epoch: [7][224/591]	Time  0.611 ( 0.658)	Data  0.513 ( 0.560)	Loss 8.9939e-01 (1.1105e+00)	Acc@1 31.250000 (21.527779)
Epoch: [7][240/591]	Time  0.683 ( 0.659)	Data  0.586 ( 0.560)	Loss 1.0266e+00 (1.1098e+00)	Acc@1 25.000000 (21.654566)
Epoch: [7][256/591]	Time  0.624 ( 0.658)	Data  0.523 ( 0.559)	Loss 1.3984e+00 (1.1119e+00)	Acc@1 25.000000 (21.668287)
Epoch: [7][272/591]	Time  0.620 ( 0.656)	Data  0.522 ( 0.558)	Loss 1.0659e+00 (1.1145e+00)	Acc@1 37.500000 (21.520147)
Epoch: [7][288/591]	Time  0.633 ( 0.655)	Data  0.535 ( 0.557)	Loss 1.2013e+00 (1.1118e+00)	Acc@1 12.500000 (21.647924)
Epoch: [7][304/591]	Time  0.609 ( 0.658)	Data  0.512 ( 0.560)	Loss 9.0958e-01 (1.1130e+00)	Acc@1 18.750000 (21.454918)
Epoch: [7][320/591]	Time  0.691 ( 0.656)	Data  0.593 ( 0.558)	Loss 1.1752e+00 (1.1129e+00)	Acc@1 25.000000 (21.378504)
Epoch: [7][336/591]	Time  0.629 ( 0.656)	Data  0.532 ( 0.557)	Loss 9.6785e-01 (1.1160e+00)	Acc@1 25.000000 (21.457714)
Epoch: [7][352/591]	Time  0.620 ( 0.655)	Data  0.522 ( 0.557)	Loss 1.2674e+00 (1.1163e+00)	Acc@1 18.750000 (21.405807)
Epoch: [7][368/591]	Time  0.752 ( 0.656)	Data  0.653 ( 0.558)	Loss 1.0196e+00 (1.1145e+00)	Acc@1 31.250000 (21.409214)
Epoch: [7][384/591]	Time  0.671 ( 0.657)	Data  0.574 ( 0.558)	Loss 9.0097e-01 (1.1149e+00)	Acc@1 43.750000 (21.379869)
Epoch: [7][400/591]	Time  0.628 ( 0.659)	Data  0.531 ( 0.561)	Loss 1.0360e+00 (1.1140e+00)	Acc@1 18.750000 (21.446384)
Epoch: [7][416/591]	Time  0.665 ( 0.658)	Data  0.568 ( 0.560)	Loss 9.2018e-01 (1.1127e+00)	Acc@1 18.750000 (21.552759)
Epoch: [7][432/591]	Time  0.631 ( 0.659)	Data  0.534 ( 0.560)	Loss 9.9238e-01 (1.1107e+00)	Acc@1 18.750000 (21.694572)
Epoch: [7][448/591]	Time  0.703 ( 0.659)	Data  0.606 ( 0.561)	Loss 1.2520e+00 (1.1115e+00)	Acc@1 18.750000 (21.687082)
Epoch: [7][464/591]	Time  0.918 ( 0.658)	Data  0.820 ( 0.560)	Loss 1.0412e+00 (1.1109e+00)	Acc@1 25.000000 (21.706989)
Epoch: [7][480/591]	Time  0.611 ( 0.659)	Data  0.514 ( 0.561)	Loss 1.1991e+00 (1.1100e+00)	Acc@1 18.750000 (21.491684)
Epoch: [7][496/591]	Time  0.625 ( 0.659)	Data  0.527 ( 0.561)	Loss 9.6293e-01 (1.1087e+00)	Acc@1 12.500000 (21.415995)
Epoch: [7][512/591]	Time  0.777 ( 0.658)	Data  0.679 ( 0.560)	Loss 1.1382e+00 (1.1091e+00)	Acc@1 37.500000 (21.466862)
Epoch: [7][528/591]	Time  0.623 ( 0.658)	Data  0.526 ( 0.560)	Loss 1.2287e+00 (1.1103e+00)	Acc@1 25.000000 (21.538280)
Epoch: [7][544/591]	Time  0.701 ( 0.657)	Data  0.604 ( 0.559)	Loss 8.8040e-01 (1.1086e+00)	Acc@1 31.250000 (21.651377)
Epoch: [7][560/591]	Time  0.628 ( 0.656)	Data  0.531 ( 0.558)	Loss 1.1685e+00 (1.1076e+00)	Acc@1 31.250000 (21.802584)
Epoch: [7][576/591]	Time  0.622 ( 0.657)	Data  0.524 ( 0.559)	Loss 1.1967e+00 (1.1071e+00)	Acc@1 18.750000 (21.847919)
##################################################
train_loss:  1.1058232539196304
train_acc:  tensor(21.9014, device='cuda:0')
##################################################
Best model was saved.
Epoch: [8][  0/591]	Time  0.623 ( 0.623)	Data  0.519 ( 0.519)	Loss 1.2437e+00 (1.2437e+00)	Acc@1 18.750000 (18.750000)
Epoch: [8][ 16/591]	Time  0.580 ( 0.621)	Data  0.483 ( 0.523)	Loss 9.6776e-01 (1.1309e+00)	Acc@1 12.500000 (27.573530)
Epoch: [8][ 32/591]	Time  0.711 ( 0.647)	Data  0.613 ( 0.549)	Loss 1.3168e+00 (1.1046e+00)	Acc@1 31.250000 (24.810606)
Epoch: [8][ 48/591]	Time  0.631 ( 0.645)	Data  0.534 ( 0.547)	Loss 1.2705e+00 (1.0879e+00)	Acc@1 37.500000 (25.892857)
Epoch: [8][ 64/591]	Time  0.620 ( 0.640)	Data  0.522 ( 0.542)	Loss 1.1991e+00 (1.0901e+00)	Acc@1 25.000000 (25.576923)
Epoch: [8][ 80/591]	Time  0.654 ( 0.653)	Data  0.556 ( 0.555)	Loss 1.0527e+00 (1.0814e+00)	Acc@1 43.750000 (25.308641)
Epoch: [8][ 96/591]	Time  0.608 ( 0.650)	Data  0.511 ( 0.552)	Loss 9.3155e-01 (1.0734e+00)	Acc@1 18.750000 (25.000000)
Epoch: [8][112/591]	Time  0.620 ( 0.649)	Data  0.522 ( 0.551)	Loss 7.9273e-01 (1.0593e+00)	Acc@1 31.250000 (24.723452)
Epoch: [8][128/591]	Time  0.616 ( 0.646)	Data  0.519 ( 0.548)	Loss 1.0794e+00 (1.0602e+00)	Acc@1 31.250000 (25.048450)
Epoch: [8][144/591]	Time  0.619 ( 0.645)	Data  0.521 ( 0.547)	Loss 7.7315e-01 (1.0602e+00)	Acc@1 31.250000 (24.913794)
Epoch: [8][160/591]	Time  0.928 ( 0.647)	Data  0.819 ( 0.549)	Loss 1.2411e+00 (1.0693e+00)	Acc@1 6.250000 (24.689442)
Epoch: [8][176/591]	Time  0.628 ( 0.650)	Data  0.530 ( 0.552)	Loss 8.5327e-01 (1.0618e+00)	Acc@1 37.500000 (24.540960)
Epoch: [8][192/591]	Time  0.694 ( 0.649)	Data  0.596 ( 0.550)	Loss 8.7153e-01 (1.0659e+00)	Acc@1 25.000000 (24.449482)
Epoch: [8][208/591]	Time  0.611 ( 0.646)	Data  0.513 ( 0.547)	Loss 1.1632e+00 (1.0666e+00)	Acc@1 37.500000 (24.252392)
Epoch: [8][224/591]	Time  0.701 ( 0.644)	Data  0.604 ( 0.546)	Loss 1.1162e+00 (1.0674e+00)	Acc@1 25.000000 (24.388889)
Epoch: [8][240/591]	Time  0.651 ( 0.643)	Data  0.553 ( 0.545)	Loss 5.6161e-01 (1.0705e+00)	Acc@1 37.500000 (24.170126)
Epoch: [8][256/591]	Time  0.684 ( 0.648)	Data  0.586 ( 0.549)	Loss 9.7634e-01 (1.0704e+00)	Acc@1 18.750000 (24.027237)
Epoch: [8][272/591]	Time  0.650 ( 0.647)	Data  0.553 ( 0.548)	Loss 1.2985e+00 (1.0730e+00)	Acc@1 25.000000 (24.038462)
Epoch: [8][288/591]	Time  0.634 ( 0.649)	Data  0.537 ( 0.551)	Loss 1.1712e+00 (1.0744e+00)	Acc@1 25.000000 (23.875433)
Epoch: [8][304/591]	Time  0.632 ( 0.648)	Data  0.534 ( 0.550)	Loss 1.1348e+00 (1.0751e+00)	Acc@1 18.750000 (24.057377)
Epoch: [8][320/591]	Time  0.752 ( 0.649)	Data  0.654 ( 0.551)	Loss 1.1642e+00 (1.0740e+00)	Acc@1 18.750000 (24.007010)
Epoch: [8][336/591]	Time  0.613 ( 0.648)	Data  0.515 ( 0.550)	Loss 9.1600e-01 (1.0762e+00)	Acc@1 37.500000 (23.942879)
Epoch: [8][352/591]	Time  0.607 ( 0.651)	Data  0.509 ( 0.553)	Loss 9.3280e-01 (1.0765e+00)	Acc@1 6.250000 (24.043909)
Epoch: [8][368/591]	Time  0.666 ( 0.650)	Data  0.568 ( 0.552)	Loss 1.0137e+00 (1.0783e+00)	Acc@1 18.750000 (24.034554)
Epoch: [8][384/591]	Time  0.817 ( 0.651)	Data  0.719 ( 0.553)	Loss 1.1484e+00 (1.0738e+00)	Acc@1 37.500000 (24.188311)
Epoch: [8][400/591]	Time  0.720 ( 0.650)	Data  0.623 ( 0.552)	Loss 8.8243e-01 (1.0738e+00)	Acc@1 18.750000 (23.924564)
Epoch: [8][416/591]	Time  0.585 ( 0.649)	Data  0.487 ( 0.551)	Loss 1.0271e+00 (1.0715e+00)	Acc@1 31.250000 (24.010792)
Epoch: [8][432/591]	Time  0.686 ( 0.650)	Data  0.588 ( 0.551)	Loss 8.6189e-01 (1.0705e+00)	Acc@1 12.500000 (23.845266)
Epoch: [8][448/591]	Time  0.651 ( 0.651)	Data  0.554 ( 0.553)	Loss 1.1116e+00 (1.0698e+00)	Acc@1 18.750000 (23.747217)
Epoch: [8][464/591]	Time  0.629 ( 0.651)	Data  0.531 ( 0.553)	Loss 9.6647e-01 (1.0707e+00)	Acc@1 18.750000 (23.776882)
Epoch: [8][480/591]	Time  0.633 ( 0.650)	Data  0.535 ( 0.552)	Loss 8.7507e-01 (1.0721e+00)	Acc@1 25.000000 (23.986486)
Epoch: [8][496/591]	Time  0.642 ( 0.650)	Data  0.545 ( 0.552)	Loss 9.9505e-01 (1.0705e+00)	Acc@1 31.250000 (24.044264)
Epoch: [8][512/591]	Time  0.662 ( 0.650)	Data  0.564 ( 0.552)	Loss 1.1459e+00 (1.0708e+00)	Acc@1 18.750000 (23.976608)
Epoch: [8][528/591]	Time  0.991 ( 0.650)	Data  0.886 ( 0.552)	Loss 1.1613e+00 (1.0712e+00)	Acc@1 25.000000 (23.983932)
Epoch: [8][544/591]	Time  0.619 ( 0.651)	Data  0.521 ( 0.553)	Loss 9.9437e-01 (1.0718e+00)	Acc@1 31.250000 (23.967890)
Epoch: [8][560/591]	Time  0.623 ( 0.650)	Data  0.526 ( 0.552)	Loss 1.2420e+00 (1.0716e+00)	Acc@1 31.250000 (24.119875)
Epoch: [8][576/591]	Time  0.645 ( 0.650)	Data  0.548 ( 0.552)	Loss 8.4082e-01 (1.0705e+00)	Acc@1 25.000000 (24.111786)
##################################################
train_loss:  1.0684860315419695
train_acc:  tensor(24.2069, device='cuda:0')
##################################################
Best model was saved.
Epoch: [9][  0/591]	Time  0.657 ( 0.657)	Data  0.559 ( 0.559)	Loss 7.5915e-01 (7.5915e-01)	Acc@1 43.750000 (43.750000)
Epoch: [9][ 16/591]	Time  0.608 ( 0.623)	Data  0.510 ( 0.526)	Loss 1.2710e+00 (1.0440e+00)	Acc@1 12.500000 (26.102942)
Epoch: [9][ 32/591]	Time  0.635 ( 0.662)	Data  0.538 ( 0.563)	Loss 1.2605e+00 (1.0679e+00)	Acc@1 0.000000 (22.916668)
Epoch: [9][ 48/591]	Time  0.650 ( 0.658)	Data  0.552 ( 0.559)	Loss 1.3045e+00 (1.0784e+00)	Acc@1 12.500000 (21.556122)
Epoch: [9][ 64/591]	Time  0.602 ( 0.654)	Data  0.505 ( 0.555)	Loss 9.7736e-01 (1.0746e+00)	Acc@1 25.000000 (22.307692)
Epoch: [9][ 80/591]	Time  0.638 ( 0.659)	Data  0.541 ( 0.561)	Loss 1.0978e+00 (1.0720e+00)	Acc@1 31.250000 (22.608025)
Epoch: [9][ 96/591]	Time  0.609 ( 0.656)	Data  0.512 ( 0.558)	Loss 1.3062e+00 (1.0690e+00)	Acc@1 37.500000 (23.260309)
Epoch: [9][112/591]	Time  0.654 ( 0.656)	Data  0.557 ( 0.558)	Loss 1.1101e+00 (1.0646e+00)	Acc@1 12.500000 (23.396017)
Epoch: [9][128/591]	Time  0.627 ( 0.663)	Data  0.530 ( 0.565)	Loss 1.0815e+00 (1.0617e+00)	Acc@1 6.250000 (23.304264)
Epoch: [9][144/591]	Time  0.586 ( 0.660)	Data  0.488 ( 0.561)	Loss 1.1065e+00 (1.0697e+00)	Acc@1 31.250000 (23.362068)
Epoch: [9][160/591]	Time  0.618 ( 0.658)	Data  0.520 ( 0.559)	Loss 1.1783e+00 (1.0729e+00)	Acc@1 25.000000 (23.524845)
Epoch: [9][176/591]	Time  0.617 ( 0.655)	Data  0.517 ( 0.557)	Loss 1.2832e+00 (1.0762e+00)	Acc@1 18.750000 (23.340395)
Epoch: [9][192/591]	Time  0.606 ( 0.657)	Data  0.507 ( 0.559)	Loss 8.1742e-01 (1.0743e+00)	Acc@1 18.750000 (23.154144)
Epoch: [9][208/591]	Time  0.639 ( 0.659)	Data  0.539 ( 0.561)	Loss 9.4468e-01 (1.0735e+00)	Acc@1 12.500000 (22.966507)
Epoch: [9][224/591]	Time  0.612 ( 0.662)	Data  0.515 ( 0.564)	Loss 9.5136e-01 (1.0739e+00)	Acc@1 25.000000 (22.944445)
Epoch: [9][240/591]	Time  0.591 ( 0.659)	Data  0.493 ( 0.561)	Loss 9.7992e-01 (1.0737e+00)	Acc@1 18.750000 (23.029047)
Epoch: [9][256/591]	Time  0.599 ( 0.658)	Data  0.502 ( 0.560)	Loss 1.0874e+00 (1.0712e+00)	Acc@1 6.250000 (22.859922)
Epoch: [9][272/591]	Time  0.662 ( 0.656)	Data  0.565 ( 0.558)	Loss 1.0960e+00 (1.0708e+00)	Acc@1 18.750000 (22.962454)
Epoch: [9][288/591]	Time  0.681 ( 0.656)	Data  0.583 ( 0.558)	Loss 1.0904e+00 (1.0709e+00)	Acc@1 31.250000 (23.140139)
Epoch: [9][304/591]	Time  0.633 ( 0.660)	Data  0.536 ( 0.561)	Loss 1.1770e+00 (1.0647e+00)	Acc@1 31.250000 (23.381147)
Epoch: [9][320/591]	Time  0.609 ( 0.658)	Data  0.511 ( 0.560)	Loss 1.2974e+00 (1.0681e+00)	Acc@1 18.750000 (23.383955)
Epoch: [9][336/591]	Time  0.626 ( 0.657)	Data  0.526 ( 0.559)	Loss 7.4275e-01 (1.0652e+00)	Acc@1 12.500000 (23.293768)
Epoch: [9][352/591]	Time  0.618 ( 0.656)	Data  0.520 ( 0.558)	Loss 1.2114e+00 (1.0634e+00)	Acc@1 12.500000 (23.371105)
Epoch: [9][368/591]	Time  0.665 ( 0.655)	Data  0.567 ( 0.557)	Loss 9.6418e-01 (1.0652e+00)	Acc@1 37.500000 (23.373983)
Epoch: [9][384/591]	Time  0.721 ( 0.654)	Data  0.623 ( 0.556)	Loss 1.1275e+00 (1.0614e+00)	Acc@1 0.000000 (23.198051)
Epoch: [9][400/591]	Time  0.623 ( 0.655)	Data  0.525 ( 0.557)	Loss 1.1564e+00 (1.0618e+00)	Acc@1 12.500000 (23.098505)
Epoch: [9][416/591]	Time  0.620 ( 0.654)	Data  0.522 ( 0.556)	Loss 9.1922e-01 (1.0613e+00)	Acc@1 18.750000 (23.036572)
Epoch: [9][432/591]	Time  0.620 ( 0.654)	Data  0.522 ( 0.556)	Loss 1.0893e+00 (1.0610e+00)	Acc@1 25.000000 (23.195726)
Epoch: [9][448/591]	Time  0.606 ( 0.654)	Data  0.508 ( 0.556)	Loss 1.1490e+00 (1.0599e+00)	Acc@1 6.250000 (23.190424)
Epoch: [9][464/591]	Time  0.575 ( 0.653)	Data  0.478 ( 0.555)	Loss 9.6762e-01 (1.0600e+00)	Acc@1 37.500000 (23.400537)
Epoch: [9][480/591]	Time  0.636 ( 0.652)	Data  0.539 ( 0.554)	Loss 8.8693e-01 (1.0577e+00)	Acc@1 12.500000 (23.466736)
Epoch: [9][496/591]	Time  0.635 ( 0.654)	Data  0.538 ( 0.556)	Loss 9.3983e-01 (1.0570e+00)	Acc@1 18.750000 (23.578974)
Epoch: [9][512/591]	Time  0.694 ( 0.654)	Data  0.596 ( 0.556)	Loss 9.4674e-01 (1.0554e+00)	Acc@1 18.750000 (23.574562)
Epoch: [9][528/591]	Time  0.631 ( 0.654)	Data  0.532 ( 0.556)	Loss 1.1413e+00 (1.0543e+00)	Acc@1 50.000000 (23.853970)
Epoch: [9][544/591]	Time  0.564 ( 0.653)	Data  0.466 ( 0.555)	Loss 1.0801e+00 (1.0539e+00)	Acc@1 31.250000 (23.979359)
Epoch: [9][560/591]	Time  0.648 ( 0.652)	Data  0.549 ( 0.554)	Loss 8.7883e-01 (1.0511e+00)	Acc@1 37.500000 (24.075312)
Epoch: [9][576/591]	Time  0.681 ( 0.651)	Data  0.583 ( 0.553)	Loss 1.0215e+00 (1.0510e+00)	Acc@1 25.000000 (24.100954)
##################################################
train_loss:  1.0523423186413527
train_acc:  tensor(24.2069, device='cuda:0')
##################################################
Best model was saved.
Epoch: [10][  0/591]	Time  0.852 ( 0.852)	Data  0.754 ( 0.754)	Loss 1.1499e+00 (1.1499e+00)	Acc@1 12.500000 (12.500000)
Epoch: [10][ 16/591]	Time  0.614 ( 0.634)	Data  0.516 ( 0.537)	Loss 1.2250e+00 (9.7302e-01)	Acc@1 31.250000 (25.735294)
Epoch: [10][ 32/591]	Time  0.688 ( 0.632)	Data  0.590 ( 0.534)	Loss 9.5379e-01 (1.0151e+00)	Acc@1 25.000000 (25.378788)
Epoch: [10][ 48/591]	Time  0.565 ( 0.646)	Data  0.467 ( 0.548)	Loss 8.7760e-01 (1.0086e+00)	Acc@1 6.250000 (25.637754)
Epoch: [10][ 64/591]	Time  0.610 ( 0.642)	Data  0.512 ( 0.544)	Loss 8.0921e-01 (1.0316e+00)	Acc@1 25.000000 (24.903847)
Epoch: [10][ 80/591]	Time  1.008 ( 0.648)	Data  0.898 ( 0.550)	Loss 1.0614e+00 (1.0225e+00)	Acc@1 31.250000 (25.231482)
Epoch: [10][ 96/591]	Time  0.623 ( 0.649)	Data  0.526 ( 0.551)	Loss 1.0228e+00 (1.0177e+00)	Acc@1 37.500000 (25.515463)
Epoch: [10][112/591]	Time  0.662 ( 0.647)	Data  0.564 ( 0.549)	Loss 1.1131e+00 (1.0220e+00)	Acc@1 25.000000 (25.884956)
Epoch: [10][128/591]	Time  0.736 ( 0.650)	Data  0.639 ( 0.552)	Loss 8.7405e-01 (1.0216e+00)	Acc@1 18.750000 (25.823643)
Epoch: [10][144/591]	Time  0.601 ( 0.648)	Data  0.503 ( 0.550)	Loss 9.9903e-01 (1.0232e+00)	Acc@1 25.000000 (26.293104)
Epoch: [10][160/591]	Time  0.641 ( 0.646)	Data  0.544 ( 0.548)	Loss 1.0301e+00 (1.0231e+00)	Acc@1 37.500000 (25.931677)
Epoch: [10][176/591]	Time  0.608 ( 0.653)	Data  0.510 ( 0.555)	Loss 1.2044e+00 (1.0213e+00)	Acc@1 6.250000 (25.882769)
Epoch: [10][192/591]	Time  0.598 ( 0.651)	Data  0.500 ( 0.553)	Loss 7.8857e-01 (1.0211e+00)	Acc@1 43.750000 (26.133419)
Epoch: [10][208/591]	Time  0.639 ( 0.651)	Data  0.541 ( 0.553)	Loss 7.9180e-01 (1.0249e+00)	Acc@1 25.000000 (25.927032)
Epoch: [10][224/591]	Time  0.618 ( 0.649)	Data  0.519 ( 0.551)	Loss 1.1303e+00 (1.0306e+00)	Acc@1 43.750000 (26.222223)
Epoch: [10][240/591]	Time  0.611 ( 0.647)	Data  0.514 ( 0.549)	Loss 1.1136e+00 (1.0281e+00)	Acc@1 31.250000 (26.089212)
Epoch: [10][256/591]	Time  0.679 ( 0.645)	Data  0.580 ( 0.547)	Loss 9.6821e-01 (1.0261e+00)	Acc@1 25.000000 (26.021400)
Epoch: [10][272/591]	Time  0.590 ( 0.649)	Data  0.492 ( 0.551)	Loss 1.0754e+00 (1.0274e+00)	Acc@1 31.250000 (26.030220)
Epoch: [10][288/591]	Time  0.803 ( 0.648)	Data  0.706 ( 0.550)	Loss 9.6841e-01 (1.0278e+00)	Acc@1 25.000000 (25.929932)
Epoch: [10][304/591]	Time  0.652 ( 0.649)	Data  0.552 ( 0.551)	Loss 8.2407e-01 (1.0254e+00)	Acc@1 37.500000 (25.922131)
Epoch: [10][320/591]	Time  0.602 ( 0.648)	Data  0.505 ( 0.550)	Loss 1.1907e+00 (1.0275e+00)	Acc@1 18.750000 (25.876167)
Epoch: [10][336/591]	Time  0.611 ( 0.647)	Data  0.513 ( 0.549)	Loss 1.0093e+00 (1.0280e+00)	Acc@1 18.750000 (25.908754)
Epoch: [10][352/591]	Time  0.618 ( 0.647)	Data  0.520 ( 0.548)	Loss 1.0349e+00 (1.0280e+00)	Acc@1 25.000000 (25.902975)
Epoch: [10][368/591]	Time  0.722 ( 0.649)	Data  0.624 ( 0.551)	Loss 1.0343e+00 (1.0246e+00)	Acc@1 25.000000 (25.948509)
Epoch: [10][384/591]	Time  0.772 ( 0.649)	Data  0.674 ( 0.551)	Loss 1.0417e+00 (1.0236e+00)	Acc@1 25.000000 (25.811687)
Epoch: [10][400/591]	Time  0.680 ( 0.648)	Data  0.582 ( 0.550)	Loss 1.1256e+00 (1.0213e+00)	Acc@1 31.250000 (26.028679)
Epoch: [10][416/591]	Time  0.627 ( 0.648)	Data  0.529 ( 0.550)	Loss 1.0455e+00 (1.0210e+00)	Acc@1 25.000000 (26.109114)
Epoch: [10][432/591]	Time  0.706 ( 0.647)	Data  0.608 ( 0.549)	Loss 1.1573e+00 (1.0192e+00)	Acc@1 12.500000 (26.255774)
Epoch: [10][448/591]	Time  1.413 ( 0.649)	Data  1.301 ( 0.551)	Loss 1.0867e+00 (1.0174e+00)	Acc@1 6.250000 (26.364143)
Epoch: [10][464/591]	Time  0.608 ( 0.650)	Data  0.510 ( 0.552)	Loss 8.8877e-01 (1.0160e+00)	Acc@1 25.000000 (26.384409)
Epoch: [10][480/591]	Time  0.631 ( 0.650)	Data  0.534 ( 0.551)	Loss 9.7696e-01 (1.0150e+00)	Acc@1 50.000000 (26.611227)
Epoch: [10][496/591]	Time  0.624 ( 0.649)	Data  0.526 ( 0.551)	Loss 8.9503e-01 (1.0152e+00)	Acc@1 25.000000 (26.647383)
Epoch: [10][512/591]	Time  0.667 ( 0.650)	Data  0.569 ( 0.552)	Loss 1.1552e+00 (1.0194e+00)	Acc@1 43.750000 (26.717836)
Epoch: [10][528/591]	Time  0.597 ( 0.650)	Data  0.499 ( 0.551)	Loss 1.1963e+00 (1.0204e+00)	Acc@1 31.250000 (26.618620)
Epoch: [10][544/591]	Time  0.578 ( 0.652)	Data  0.480 ( 0.554)	Loss 9.6205e-01 (1.0198e+00)	Acc@1 18.750000 (26.582569)
Epoch: [10][560/591]	Time  0.634 ( 0.652)	Data  0.536 ( 0.554)	Loss 1.2015e+00 (1.0203e+00)	Acc@1 18.750000 (26.771389)
Epoch: [10][576/591]	Time  0.616 ( 0.652)	Data  0.518 ( 0.553)	Loss 1.2653e+00 (1.0211e+00)	Acc@1 31.250000 (26.743935)
##################################################
train_loss:  1.022408180430456
train_acc:  tensor(26.6286, device='cuda:0')
##################################################
Best model was saved.
Epoch: [11][  0/591]	Time  0.609 ( 0.609)	Data  0.512 ( 0.512)	Loss 1.2133e+00 (1.2133e+00)	Acc@1 31.250000 (31.250000)
Epoch: [11][ 16/591]	Time  0.555 ( 0.663)	Data  0.457 ( 0.564)	Loss 1.0168e+00 (1.0591e+00)	Acc@1 37.500000 (30.147058)
Epoch: [11][ 32/591]	Time  0.577 ( 0.656)	Data  0.479 ( 0.559)	Loss 9.3970e-01 (1.0396e+00)	Acc@1 31.250000 (29.166668)
Epoch: [11][ 48/591]	Time  0.858 ( 0.680)	Data  0.760 ( 0.581)	Loss 9.1086e-01 (1.0020e+00)	Acc@1 18.750000 (29.719387)
Epoch: [11][ 64/591]	Time  0.595 ( 0.670)	Data  0.498 ( 0.572)	Loss 1.0070e+00 (9.9925e-01)	Acc@1 12.500000 (30.480770)
Epoch: [11][ 80/591]	Time  0.615 ( 0.663)	Data  0.517 ( 0.565)	Loss 8.3396e-01 (9.8674e-01)	Acc@1 18.750000 (29.398148)
Epoch: [11][ 96/591]	Time  0.640 ( 0.657)	Data  0.542 ( 0.559)	Loss 7.7957e-01 (9.8302e-01)	Acc@1 25.000000 (28.930412)
Epoch: [11][112/591]	Time  0.587 ( 0.654)	Data  0.489 ( 0.556)	Loss 1.3043e+00 (9.8622e-01)	Acc@1 37.500000 (28.318584)
Epoch: [11][128/591]	Time  0.964 ( 0.657)	Data  0.858 ( 0.558)	Loss 1.3934e+00 (9.9492e-01)	Acc@1 12.500000 (28.149225)
Epoch: [11][144/591]	Time  0.620 ( 0.659)	Data  0.522 ( 0.560)	Loss 1.0403e+00 (9.9273e-01)	Acc@1 12.500000 (27.241379)
Epoch: [11][160/591]	Time  0.667 ( 0.656)	Data  0.568 ( 0.558)	Loss 9.2009e-01 (9.9501e-01)	Acc@1 37.500000 (27.950312)
Epoch: [11][176/591]	Time  0.678 ( 0.655)	Data  0.581 ( 0.556)	Loss 8.3798e-01 (9.9836e-01)	Acc@1 31.250000 (28.319208)
Epoch: [11][192/591]	Time  0.619 ( 0.652)	Data  0.521 ( 0.553)	Loss 1.1014e+00 (1.0025e+00)	Acc@1 25.000000 (27.849741)
Epoch: [11][208/591]	Time  0.649 ( 0.652)	Data  0.550 ( 0.553)	Loss 1.1028e+00 (1.0029e+00)	Acc@1 18.750000 (27.870811)
Epoch: [11][224/591]	Time  0.610 ( 0.655)	Data  0.511 ( 0.557)	Loss 8.5238e-01 (1.0015e+00)	Acc@1 37.500000 (27.277779)
Epoch: [11][240/591]	Time  0.746 ( 0.656)	Data  0.649 ( 0.557)	Loss 1.3304e+00 (1.0020e+00)	Acc@1 18.750000 (27.308092)
Epoch: [11][256/591]	Time  0.617 ( 0.656)	Data  0.520 ( 0.558)	Loss 1.1603e+00 (1.0029e+00)	Acc@1 25.000000 (27.213036)
Epoch: [11][272/591]	Time  0.610 ( 0.654)	Data  0.513 ( 0.556)	Loss 1.0282e+00 (1.0004e+00)	Acc@1 25.000000 (27.106228)
Epoch: [11][288/591]	Time  0.678 ( 0.653)	Data  0.580 ( 0.555)	Loss 1.1824e+00 (1.0012e+00)	Acc@1 25.000000 (26.924742)
Epoch: [11][304/591]	Time  0.692 ( 0.653)	Data  0.595 ( 0.555)	Loss 8.3056e-01 (1.0023e+00)	Acc@1 25.000000 (26.680328)
Epoch: [11][320/591]	Time  0.620 ( 0.655)	Data  0.522 ( 0.557)	Loss 9.4059e-01 (1.0022e+00)	Acc@1 25.000000 (26.752337)
Epoch: [11][336/591]	Time  0.591 ( 0.654)	Data  0.493 ( 0.556)	Loss 7.7495e-01 (1.0023e+00)	Acc@1 25.000000 (26.594955)
Epoch: [11][352/591]	Time  0.628 ( 0.653)	Data  0.530 ( 0.555)	Loss 7.4201e-01 (1.0002e+00)	Acc@1 12.500000 (26.398726)
Epoch: [11][368/591]	Time  0.680 ( 0.653)	Data  0.583 ( 0.555)	Loss 1.0933e+00 (1.0024e+00)	Acc@1 12.500000 (26.134825)
Epoch: [11][384/591]	Time  0.621 ( 0.653)	Data  0.524 ( 0.555)	Loss 9.5946e-01 (1.0023e+00)	Acc@1 37.500000 (26.314934)
Epoch: [11][400/591]	Time  0.642 ( 0.654)	Data  0.544 ( 0.556)	Loss 9.4605e-01 (1.0006e+00)	Acc@1 12.500000 (26.137781)
Epoch: [11][416/591]	Time  0.608 ( 0.656)	Data  0.510 ( 0.558)	Loss 1.0005e+00 (9.9848e-01)	Acc@1 37.500000 (26.064150)
Epoch: [11][432/591]	Time  0.637 ( 0.656)	Data  0.540 ( 0.558)	Loss 8.7316e-01 (1.0006e+00)	Acc@1 18.750000 (26.212471)
Epoch: [11][448/591]	Time  0.599 ( 0.656)	Data  0.501 ( 0.557)	Loss 1.0114e+00 (1.0014e+00)	Acc@1 18.750000 (26.030067)
Epoch: [11][464/591]	Time  0.607 ( 0.655)	Data  0.510 ( 0.557)	Loss 1.0425e+00 (1.0022e+00)	Acc@1 18.750000 (26.008064)
Epoch: [11][480/591]	Time  0.592 ( 0.655)	Data  0.494 ( 0.556)	Loss 1.0679e+00 (1.0015e+00)	Acc@1 37.500000 (25.987526)
Epoch: [11][496/591]	Time  0.957 ( 0.656)	Data  0.859 ( 0.558)	Loss 1.1111e+00 (1.0026e+00)	Acc@1 6.250000 (25.930582)
Epoch: [11][512/591]	Time  0.631 ( 0.656)	Data  0.534 ( 0.558)	Loss 1.1231e+00 (1.0009e+00)	Acc@1 37.500000 (25.950293)
Epoch: [11][528/591]	Time  0.669 ( 0.656)	Data  0.572 ( 0.558)	Loss 1.1031e+00 (1.0026e+00)	Acc@1 6.250000 (25.815218)
Epoch: [11][544/591]	Time  0.647 ( 0.656)	Data  0.550 ( 0.557)	Loss 9.0066e-01 (1.0029e+00)	Acc@1 12.500000 (25.883028)
Epoch: [11][560/591]	Time  0.604 ( 0.655)	Data  0.507 ( 0.557)	Loss 1.0734e+00 (1.0028e+00)	Acc@1 25.000000 (25.958111)
Epoch: [11][576/591]	Time  0.653 ( 0.654)	Data  0.556 ( 0.556)	Loss 1.0179e+00 (1.0007e+00)	Acc@1 56.250000 (26.148180)
##################################################
train_loss:  1.0010499212947594
train_acc:  tensor(26.0998, device='cuda:0')
##################################################
Best model was saved.
Epoch: [12][  0/591]	Time  0.693 ( 0.693)	Data  0.595 ( 0.595)	Loss 8.1892e-01 (8.1892e-01)	Acc@1 31.250000 (31.250000)
Epoch: [12][ 16/591]	Time  0.629 ( 0.649)	Data  0.531 ( 0.551)	Loss 1.0193e+00 (9.5632e-01)	Acc@1 43.750000 (29.044117)
Epoch: [12][ 32/591]	Time  0.656 ( 0.635)	Data  0.558 ( 0.538)	Loss 8.0800e-01 (9.7242e-01)	Acc@1 56.250000 (31.060608)
Epoch: [12][ 48/591]	Time  0.640 ( 0.635)	Data  0.543 ( 0.537)	Loss 1.1200e+00 (9.7690e-01)	Acc@1 6.250000 (28.443876)
Epoch: [12][ 64/591]	Time  0.616 ( 0.632)	Data  0.518 ( 0.534)	Loss 1.0816e+00 (9.7766e-01)	Acc@1 31.250000 (28.365385)
Epoch: [12][ 80/591]	Time  0.601 ( 0.633)	Data  0.503 ( 0.535)	Loss 1.1788e+00 (9.9103e-01)	Acc@1 6.250000 (27.623457)
Epoch: [12][ 96/591]	Time  0.616 ( 0.643)	Data  0.518 ( 0.545)	Loss 7.9604e-01 (9.8074e-01)	Acc@1 25.000000 (27.835051)
Epoch: [12][112/591]	Time  0.622 ( 0.645)	Data  0.524 ( 0.547)	Loss 9.9054e-01 (9.8418e-01)	Acc@1 37.500000 (28.042036)
Epoch: [12][128/591]	Time  0.704 ( 0.643)	Data  0.606 ( 0.545)	Loss 1.1434e+00 (9.8467e-01)	Acc@1 12.500000 (27.470930)
Epoch: [12][144/591]	Time  0.604 ( 0.643)	Data  0.506 ( 0.544)	Loss 1.0687e+00 (9.8505e-01)	Acc@1 37.500000 (27.672413)
Epoch: [12][160/591]	Time  0.628 ( 0.643)	Data  0.531 ( 0.545)	Loss 1.0030e+00 (9.8129e-01)	Acc@1 18.750000 (27.445652)
Epoch: [12][176/591]	Time  0.975 ( 0.644)	Data  0.869 ( 0.546)	Loss 9.4221e-01 (9.8460e-01)	Acc@1 18.750000 (27.365820)
Epoch: [12][192/591]	Time  0.635 ( 0.652)	Data  0.537 ( 0.554)	Loss 1.2209e+00 (9.8328e-01)	Acc@1 6.250000 (27.428757)
Epoch: [12][208/591]	Time  0.649 ( 0.652)	Data  0.550 ( 0.554)	Loss 6.5229e-01 (9.8171e-01)	Acc@1 31.250000 (27.272726)
Epoch: [12][224/591]	Time  0.603 ( 0.652)	Data  0.505 ( 0.554)	Loss 9.4551e-01 (9.7730e-01)	Acc@1 12.500000 (27.222223)
Epoch: [12][240/591]	Time  0.653 ( 0.650)	Data  0.555 ( 0.552)	Loss 1.0147e+00 (9.7988e-01)	Acc@1 12.500000 (27.334026)
Epoch: [12][256/591]	Time  0.613 ( 0.650)	Data  0.515 ( 0.552)	Loss 1.1589e+00 (9.7939e-01)	Acc@1 25.000000 (27.334631)
Epoch: [12][272/591]	Time  0.575 ( 0.654)	Data  0.477 ( 0.556)	Loss 9.6856e-01 (9.7547e-01)	Acc@1 18.750000 (27.312271)
Epoch: [12][288/591]	Time  0.622 ( 0.653)	Data  0.524 ( 0.555)	Loss 8.5499e-01 (9.7332e-01)	Acc@1 43.750000 (27.443773)
Epoch: [12][304/591]	Time  0.611 ( 0.652)	Data  0.513 ( 0.554)	Loss 1.0654e+00 (9.7361e-01)	Acc@1 31.250000 (27.315575)
Epoch: [12][320/591]	Time  0.604 ( 0.651)	Data  0.506 ( 0.553)	Loss 8.4652e-01 (9.7635e-01)	Acc@1 25.000000 (27.316977)
Epoch: [12][336/591]	Time  0.624 ( 0.651)	Data  0.527 ( 0.553)	Loss 8.8364e-01 (9.7818e-01)	Acc@1 31.250000 (27.392433)
Epoch: [12][352/591]	Time  0.570 ( 0.651)	Data  0.472 ( 0.553)	Loss 9.6216e-01 (9.7911e-01)	Acc@1 18.750000 (27.425636)
Epoch: [12][368/591]	Time  0.638 ( 0.654)	Data  0.541 ( 0.556)	Loss 1.0014e+00 (9.7723e-01)	Acc@1 25.000000 (27.608402)
Epoch: [12][384/591]	Time  0.616 ( 0.653)	Data  0.519 ( 0.555)	Loss 1.0508e+00 (9.7795e-01)	Acc@1 43.750000 (27.792208)
Epoch: [12][400/591]	Time  0.613 ( 0.652)	Data  0.516 ( 0.554)	Loss 9.8477e-01 (9.7479e-01)	Acc@1 12.500000 (27.727556)
Epoch: [12][416/591]	Time  0.655 ( 0.650)	Data  0.557 ( 0.552)	Loss 1.0942e+00 (9.7560e-01)	Acc@1 25.000000 (27.517986)
Epoch: [12][432/591]	Time  0.636 ( 0.650)	Data  0.539 ( 0.552)	Loss 1.0004e+00 (9.7630e-01)	Acc@1 25.000000 (27.655890)
Epoch: [12][448/591]	Time  0.611 ( 0.649)	Data  0.513 ( 0.551)	Loss 8.7478e-01 (9.7685e-01)	Acc@1 37.500000 (27.658688)
Epoch: [12][464/591]	Time  0.942 ( 0.652)	Data  0.844 ( 0.554)	Loss 8.6791e-01 (9.7873e-01)	Acc@1 25.000000 (27.688173)
Epoch: [12][480/591]	Time  0.603 ( 0.651)	Data  0.506 ( 0.553)	Loss 7.9418e-01 (9.7959e-01)	Acc@1 25.000000 (27.650728)
Epoch: [12][496/591]	Time  0.602 ( 0.652)	Data  0.505 ( 0.554)	Loss 8.8200e-01 (9.8024e-01)	Acc@1 25.000000 (27.577967)
Epoch: [12][512/591]	Time  0.621 ( 0.652)	Data  0.521 ( 0.554)	Loss 1.2383e+00 (9.8212e-01)	Acc@1 43.750000 (27.692495)
Epoch: [12][528/591]	Time  0.933 ( 0.653)	Data  0.835 ( 0.555)	Loss 9.1807e-01 (9.8109e-01)	Acc@1 18.750000 (27.681948)
Epoch: [12][544/591]	Time  0.638 ( 0.655)	Data  0.534 ( 0.557)	Loss 1.0939e+00 (9.8094e-01)	Acc@1 25.000000 (27.614679)
Epoch: [12][560/591]	Time  0.607 ( 0.654)	Data  0.510 ( 0.556)	Loss 8.8769e-01 (9.7990e-01)	Acc@1 25.000000 (27.595810)
Epoch: [12][576/591]	Time  0.634 ( 0.653)	Data  0.537 ( 0.555)	Loss 7.9642e-01 (9.7908e-01)	Acc@1 31.250000 (27.642981)
##################################################
train_loss:  0.9784800922608415
train_acc:  tensor(27.5592, device='cuda:0')
##################################################
Best model was saved.
Epoch: [13][  0/591]	Time  0.617 ( 0.617)	Data  0.519 ( 0.519)	Loss 1.0184e+00 (1.0184e+00)	Acc@1 31.250000 (31.250000)
Epoch: [13][ 16/591]	Time  0.639 ( 0.637)	Data  0.542 ( 0.539)	Loss 1.0183e+00 (1.0207e+00)	Acc@1 18.750000 (25.367647)
Epoch: [13][ 32/591]	Time  0.603 ( 0.650)	Data  0.505 ( 0.552)	Loss 1.2734e+00 (1.0175e+00)	Acc@1 12.500000 (25.946970)
Epoch: [13][ 48/591]	Time  0.625 ( 0.669)	Data  0.527 ( 0.570)	Loss 6.8766e-01 (1.0005e+00)	Acc@1 37.500000 (26.658163)
Epoch: [13][ 64/591]	Time  0.619 ( 0.661)	Data  0.522 ( 0.562)	Loss 8.4330e-01 (9.8641e-01)	Acc@1 18.750000 (26.634615)
Epoch: [13][ 80/591]	Time  0.672 ( 0.663)	Data  0.575 ( 0.565)	Loss 9.4180e-01 (9.9026e-01)	Acc@1 31.250000 (26.080248)
Epoch: [13][ 96/591]	Time  0.727 ( 0.660)	Data  0.629 ( 0.561)	Loss 7.6936e-01 (9.9115e-01)	Acc@1 25.000000 (26.417524)
Epoch: [13][112/591]	Time  0.694 ( 0.664)	Data  0.597 ( 0.565)	Loss 8.9930e-01 (9.8802e-01)	Acc@1 37.500000 (26.825222)
Epoch: [13][128/591]	Time  0.614 ( 0.659)	Data  0.517 ( 0.561)	Loss 1.1992e+00 (9.8393e-01)	Acc@1 31.250000 (26.744186)
Epoch: [13][144/591]	Time  0.645 ( 0.665)	Data  0.547 ( 0.566)	Loss 9.5088e-01 (9.7464e-01)	Acc@1 18.750000 (26.465517)
Epoch: [13][160/591]	Time  0.727 ( 0.663)	Data  0.629 ( 0.565)	Loss 1.1058e+00 (9.7160e-01)	Acc@1 25.000000 (26.669254)
Epoch: [13][176/591]	Time  0.591 ( 0.662)	Data  0.493 ( 0.563)	Loss 9.1091e-01 (9.7060e-01)	Acc@1 18.750000 (27.189266)
Epoch: [13][192/591]	Time  0.590 ( 0.659)	Data  0.493 ( 0.560)	Loss 9.9080e-01 (9.7509e-01)	Acc@1 43.750000 (27.202072)
Epoch: [13][208/591]	Time  0.606 ( 0.656)	Data  0.509 ( 0.558)	Loss 8.9587e-01 (9.7238e-01)	Acc@1 18.750000 (26.883970)
Epoch: [13][224/591]	Time  0.914 ( 0.657)	Data  0.809 ( 0.559)	Loss 7.3915e-01 (9.6748e-01)	Acc@1 50.000000 (27.055555)
Epoch: [13][240/591]	Time  0.642 ( 0.659)	Data  0.545 ( 0.561)	Loss 1.1437e+00 (9.6735e-01)	Acc@1 37.500000 (27.178425)
Epoch: [13][256/591]	Time  0.683 ( 0.657)	Data  0.584 ( 0.559)	Loss 9.0761e-01 (9.6674e-01)	Acc@1 18.750000 (27.553501)
Epoch: [13][272/591]	Time  0.691 ( 0.658)	Data  0.592 ( 0.560)	Loss 6.4569e-01 (9.6190e-01)	Acc@1 43.750000 (27.495420)
Epoch: [13][288/591]	Time  0.617 ( 0.657)	Data  0.519 ( 0.559)	Loss 8.8210e-01 (9.6025e-01)	Acc@1 37.500000 (27.530277)
Epoch: [13][304/591]	Time  0.642 ( 0.655)	Data  0.544 ( 0.557)	Loss 9.8725e-01 (9.6119e-01)	Acc@1 31.250000 (27.561476)
Epoch: [13][320/591]	Time  0.644 ( 0.658)	Data  0.546 ( 0.560)	Loss 7.9423e-01 (9.6107e-01)	Acc@1 31.250000 (27.336449)
Epoch: [13][336/591]	Time  0.637 ( 0.657)	Data  0.540 ( 0.559)	Loss 9.8732e-01 (9.6075e-01)	Acc@1 25.000000 (27.299704)
Epoch: [13][352/591]	Time  0.637 ( 0.656)	Data  0.539 ( 0.558)	Loss 9.8630e-01 (9.6079e-01)	Acc@1 37.500000 (27.425636)
Epoch: [13][368/591]	Time  0.612 ( 0.656)	Data  0.514 ( 0.558)	Loss 1.0045e+00 (9.6127e-01)	Acc@1 18.750000 (27.405149)
Epoch: [13][384/591]	Time  0.593 ( 0.655)	Data  0.495 ( 0.556)	Loss 9.4080e-01 (9.5977e-01)	Acc@1 25.000000 (27.678572)
Epoch: [13][400/591]	Time  0.601 ( 0.654)	Data  0.503 ( 0.555)	Loss 9.6490e-01 (9.5795e-01)	Acc@1 37.500000 (27.914589)
Epoch: [13][416/591]	Time  0.673 ( 0.656)	Data  0.576 ( 0.558)	Loss 8.7476e-01 (9.5924e-01)	Acc@1 37.500000 (27.922663)
Epoch: [13][432/591]	Time  0.636 ( 0.655)	Data  0.539 ( 0.556)	Loss 5.8684e-01 (9.5922e-01)	Acc@1 43.750000 (27.872402)
Epoch: [13][448/591]	Time  0.601 ( 0.654)	Data  0.503 ( 0.556)	Loss 8.2990e-01 (9.5918e-01)	Acc@1 43.750000 (27.909243)
Epoch: [13][464/591]	Time  0.702 ( 0.653)	Data  0.604 ( 0.555)	Loss 1.1886e+00 (9.6126e-01)	Acc@1 43.750000 (27.983871)
Epoch: [13][480/591]	Time  0.552 ( 0.653)	Data  0.455 ( 0.555)	Loss 1.0505e+00 (9.6138e-01)	Acc@1 25.000000 (28.092516)
Epoch: [13][496/591]	Time  0.682 ( 0.653)	Data  0.583 ( 0.554)	Loss 9.8257e-01 (9.6411e-01)	Acc@1 18.750000 (28.055834)
Epoch: [13][512/591]	Time  0.598 ( 0.654)	Data  0.500 ( 0.556)	Loss 8.3872e-01 (9.6428e-01)	Acc@1 37.500000 (28.045809)
Epoch: [13][528/591]	Time  0.631 ( 0.654)	Data  0.533 ( 0.556)	Loss 8.7382e-01 (9.6440e-01)	Acc@1 37.500000 (28.024576)
Epoch: [13][544/591]	Time  0.583 ( 0.654)	Data  0.485 ( 0.555)	Loss 1.1878e+00 (9.6547e-01)	Acc@1 25.000000 (27.901377)
Epoch: [13][560/591]	Time  0.680 ( 0.653)	Data  0.582 ( 0.555)	Loss 1.0929e+00 (9.6641e-01)	Acc@1 12.500000 (27.840908)
Epoch: [13][576/591]	Time  0.869 ( 0.654)	Data  0.771 ( 0.556)	Loss 8.3168e-01 (9.6542e-01)	Acc@1 37.500000 (27.729635)
##################################################
train_loss:  0.9671185251621627
train_acc:  tensor(27.6438, device='cuda:0')
##################################################
Best model was saved.
Epoch: [14][  0/591]	Time  0.864 ( 0.864)	Data  0.766 ( 0.766)	Loss 1.0853e+00 (1.0853e+00)	Acc@1 43.750000 (43.750000)
Epoch: [14][ 16/591]	Time  0.628 ( 0.646)	Data  0.530 ( 0.548)	Loss 8.7756e-01 (9.4035e-01)	Acc@1 31.250000 (28.676470)
Epoch: [14][ 32/591]	Time  0.615 ( 0.631)	Data  0.518 ( 0.533)	Loss 1.2711e+00 (9.2393e-01)	Acc@1 50.000000 (28.787880)
Epoch: [14][ 48/591]	Time  0.745 ( 0.635)	Data  0.648 ( 0.537)	Loss 7.8309e-01 (9.3860e-01)	Acc@1 37.500000 (27.295918)
Epoch: [14][ 64/591]	Time  0.619 ( 0.637)	Data  0.521 ( 0.539)	Loss 1.2156e+00 (9.4660e-01)	Acc@1 37.500000 (26.057692)
Epoch: [14][ 80/591]	Time  0.789 ( 0.638)	Data  0.692 ( 0.540)	Loss 9.7564e-01 (9.5433e-01)	Acc@1 12.500000 (26.774691)
Epoch: [14][ 96/591]	Time  0.592 ( 0.650)	Data  0.494 ( 0.552)	Loss 9.3077e-01 (9.5890e-01)	Acc@1 18.750000 (27.384020)
Epoch: [14][112/591]	Time  0.646 ( 0.652)	Data  0.548 ( 0.554)	Loss 7.2932e-01 (9.5380e-01)	Acc@1 18.750000 (27.378319)
Epoch: [14][128/591]	Time  0.637 ( 0.652)	Data  0.540 ( 0.554)	Loss 1.1885e+00 (9.5643e-01)	Acc@1 31.250000 (27.228682)
Epoch: [14][144/591]	Time  0.631 ( 0.651)	Data  0.533 ( 0.553)	Loss 1.0282e+00 (9.6176e-01)	Acc@1 43.750000 (27.155172)
Epoch: [14][160/591]	Time  0.585 ( 0.648)	Data  0.487 ( 0.550)	Loss 1.1599e+00 (9.6191e-01)	Acc@1 25.000000 (27.445652)
Epoch: [14][176/591]	Time  0.579 ( 0.647)	Data  0.482 ( 0.549)	Loss 9.0706e-01 (9.6359e-01)	Acc@1 31.250000 (27.048023)
Epoch: [14][192/591]	Time  0.790 ( 0.653)	Data  0.692 ( 0.555)	Loss 9.2710e-01 (9.6160e-01)	Acc@1 18.750000 (27.590673)
Epoch: [14][208/591]	Time  0.601 ( 0.655)	Data  0.503 ( 0.557)	Loss 1.1134e+00 (9.5901e-01)	Acc@1 12.500000 (27.930620)
Epoch: [14][224/591]	Time  0.601 ( 0.653)	Data  0.503 ( 0.555)	Loss 9.2969e-01 (9.5710e-01)	Acc@1 31.250000 (27.694445)
Epoch: [14][240/591]	Time  0.711 ( 0.651)	Data  0.613 ( 0.553)	Loss 7.4452e-01 (9.5624e-01)	Acc@1 25.000000 (27.567429)
Epoch: [14][256/591]	Time  0.616 ( 0.650)	Data  0.518 ( 0.552)	Loss 1.1801e+00 (9.5843e-01)	Acc@1 31.250000 (27.431906)
Epoch: [14][272/591]	Time  0.602 ( 0.649)	Data  0.502 ( 0.551)	Loss 1.0145e+00 (9.5906e-01)	Acc@1 18.750000 (27.266483)
Epoch: [14][288/591]	Time  0.604 ( 0.653)	Data  0.506 ( 0.555)	Loss 1.0113e+00 (9.6090e-01)	Acc@1 25.000000 (27.465399)
Epoch: [14][304/591]	Time  0.623 ( 0.652)	Data  0.525 ( 0.553)	Loss 7.8018e-01 (9.5780e-01)	Acc@1 31.250000 (27.581966)
Epoch: [14][320/591]	Time  0.631 ( 0.650)	Data  0.533 ( 0.552)	Loss 9.9201e-01 (9.5652e-01)	Acc@1 18.750000 (27.394859)
Epoch: [14][336/591]	Time  0.623 ( 0.650)	Data  0.525 ( 0.552)	Loss 9.7978e-01 (9.5862e-01)	Acc@1 18.750000 (27.355341)
Epoch: [14][352/591]	Time  0.636 ( 0.651)	Data  0.538 ( 0.552)	Loss 1.0247e+00 (9.6061e-01)	Acc@1 31.250000 (27.230877)
Epoch: [14][368/591]	Time  0.826 ( 0.652)	Data  0.728 ( 0.554)	Loss 8.3554e-01 (9.6033e-01)	Acc@1 43.750000 (27.252710)
Epoch: [14][384/591]	Time  0.661 ( 0.652)	Data  0.563 ( 0.554)	Loss 7.3510e-01 (9.5682e-01)	Acc@1 31.250000 (27.402597)
Epoch: [14][400/591]	Time  0.599 ( 0.652)	Data  0.502 ( 0.553)	Loss 7.9343e-01 (9.5328e-01)	Acc@1 18.750000 (27.322321)
Epoch: [14][416/591]	Time  0.609 ( 0.651)	Data  0.511 ( 0.553)	Loss 1.1170e+00 (9.5350e-01)	Acc@1 12.500000 (27.203238)
Epoch: [14][432/591]	Time  0.605 ( 0.653)	Data  0.507 ( 0.554)	Loss 9.9497e-01 (9.5306e-01)	Acc@1 31.250000 (27.136259)
Epoch: [14][448/591]	Time  0.629 ( 0.653)	Data  0.531 ( 0.555)	Loss 8.2734e-01 (9.5046e-01)	Acc@1 37.500000 (27.129734)
Epoch: [14][464/591]	Time  0.666 ( 0.654)	Data  0.569 ( 0.556)	Loss 1.2027e+00 (9.4951e-01)	Acc@1 25.000000 (27.150537)
Epoch: [14][480/591]	Time  0.614 ( 0.653)	Data  0.516 ( 0.555)	Loss 8.5929e-01 (9.4987e-01)	Acc@1 31.250000 (27.066008)
Epoch: [14][496/591]	Time  0.615 ( 0.653)	Data  0.518 ( 0.555)	Loss 7.8225e-01 (9.4865e-01)	Acc@1 37.500000 (27.074949)
Epoch: [14][512/591]	Time  0.617 ( 0.652)	Data  0.519 ( 0.554)	Loss 8.3733e-01 (9.4923e-01)	Acc@1 12.500000 (27.156433)
Epoch: [14][528/591]	Time  0.572 ( 0.652)	Data  0.474 ( 0.554)	Loss 8.9899e-01 (9.4944e-01)	Acc@1 12.500000 (27.173914)
Epoch: [14][544/591]	Time  0.589 ( 0.651)	Data  0.492 ( 0.553)	Loss 8.3430e-01 (9.4984e-01)	Acc@1 31.250000 (27.236238)
Epoch: [14][560/591]	Time  0.638 ( 0.653)	Data  0.540 ( 0.554)	Loss 8.9690e-01 (9.4985e-01)	Acc@1 37.500000 (27.272726)
Epoch: [14][576/591]	Time  0.659 ( 0.652)	Data  0.561 ( 0.554)	Loss 9.1619e-01 (9.5122e-01)	Acc@1 6.250000 (27.285528)
##################################################
train_loss:  0.9513597051706008
train_acc:  tensor(27.1362, device='cuda:0')
##################################################
Best model was saved.
Epoch: [15][  0/591]	Time  0.628 ( 0.628)	Data  0.531 ( 0.531)	Loss 1.0314e+00 (1.0314e+00)	Acc@1 25.000000 (25.000000)
Epoch: [15][ 16/591]	Time  0.625 ( 0.644)	Data  0.527 ( 0.547)	Loss 1.0090e+00 (9.8399e-01)	Acc@1 37.500000 (31.617647)
Epoch: [15][ 32/591]	Time  0.609 ( 0.654)	Data  0.511 ( 0.556)	Loss 7.4450e-01 (9.1326e-01)	Acc@1 25.000000 (26.515152)
Epoch: [15][ 48/591]	Time  0.861 ( 0.659)	Data  0.756 ( 0.561)	Loss 1.0241e+00 (9.4834e-01)	Acc@1 25.000000 (28.061224)
Epoch: [15][ 64/591]	Time  0.617 ( 0.669)	Data  0.520 ( 0.571)	Loss 9.4229e-01 (9.5985e-01)	Acc@1 56.250000 (27.115385)
Epoch: [15][ 80/591]	Time  0.594 ( 0.662)	Data  0.496 ( 0.564)	Loss 1.0064e+00 (9.4790e-01)	Acc@1 31.250000 (26.388889)
Epoch: [15][ 96/591]	Time  0.654 ( 0.658)	Data  0.555 ( 0.560)	Loss 1.1047e+00 (9.5084e-01)	Acc@1 31.250000 (27.126287)
Epoch: [15][112/591]	Time  0.583 ( 0.652)	Data  0.485 ( 0.554)	Loss 8.2280e-01 (9.5186e-01)	Acc@1 43.750000 (27.433628)
Epoch: [15][128/591]	Time  0.585 ( 0.650)	Data  0.487 ( 0.552)	Loss 1.1957e+00 (9.5482e-01)	Acc@1 37.500000 (27.325581)
Epoch: [15][144/591]	Time  0.659 ( 0.654)	Data  0.562 ( 0.556)	Loss 9.6313e-01 (9.4572e-01)	Acc@1 12.500000 (27.025862)
Epoch: [15][160/591]	Time  0.585 ( 0.652)	Data  0.487 ( 0.554)	Loss 8.9002e-01 (9.4164e-01)	Acc@1 31.250000 (27.290373)
Epoch: [15][176/591]	Time  0.562 ( 0.649)	Data  0.463 ( 0.551)	Loss 9.3422e-01 (9.3966e-01)	Acc@1 31.250000 (26.977402)
Epoch: [15][192/591]	Time  0.649 ( 0.648)	Data  0.552 ( 0.550)	Loss 1.0671e+00 (9.4082e-01)	Acc@1 12.500000 (26.651554)
Epoch: [15][208/591]	Time  0.616 ( 0.648)	Data  0.518 ( 0.550)	Loss 9.8473e-01 (9.4065e-01)	Acc@1 37.500000 (26.824162)
Epoch: [15][224/591]	Time  0.578 ( 0.649)	Data  0.481 ( 0.551)	Loss 9.4539e-01 (9.4302e-01)	Acc@1 18.750000 (27.166668)
Epoch: [15][240/591]	Time  0.628 ( 0.651)	Data  0.530 ( 0.553)	Loss 8.5531e-01 (9.3854e-01)	Acc@1 50.000000 (27.385893)
Epoch: [15][256/591]	Time  0.713 ( 0.650)	Data  0.616 ( 0.552)	Loss 6.1044e-01 (9.3606e-01)	Acc@1 31.250000 (27.626459)
Epoch: [15][272/591]	Time  0.905 ( 0.651)	Data  0.807 ( 0.553)	Loss 8.0999e-01 (9.3612e-01)	Acc@1 18.750000 (27.815933)
Epoch: [15][288/591]	Time  0.609 ( 0.650)	Data  0.512 ( 0.552)	Loss 1.0279e+00 (9.3424e-01)	Acc@1 31.250000 (27.789793)
Epoch: [15][304/591]	Time  0.707 ( 0.651)	Data  0.609 ( 0.553)	Loss 9.4943e-01 (9.3335e-01)	Acc@1 56.250000 (27.950819)
Epoch: [15][320/591]	Time  0.614 ( 0.650)	Data  0.517 ( 0.553)	Loss 8.4018e-01 (9.3390e-01)	Acc@1 18.750000 (27.998442)
Epoch: [15][336/591]	Time  0.611 ( 0.653)	Data  0.513 ( 0.555)	Loss 8.1584e-01 (9.3521e-01)	Acc@1 18.750000 (28.041542)
Epoch: [15][352/591]	Time  0.597 ( 0.653)	Data  0.499 ( 0.555)	Loss 1.0771e+00 (9.3376e-01)	Acc@1 25.000000 (27.956799)
Epoch: [15][368/591]	Time  0.620 ( 0.652)	Data  0.522 ( 0.554)	Loss 7.2290e-01 (9.3205e-01)	Acc@1 25.000000 (28.201220)
Epoch: [15][384/591]	Time  0.710 ( 0.652)	Data  0.613 ( 0.554)	Loss 9.8811e-01 (9.3298e-01)	Acc@1 18.750000 (28.133116)
Epoch: [15][400/591]	Time  0.633 ( 0.652)	Data  0.535 ( 0.554)	Loss 1.0985e+00 (9.3342e-01)	Acc@1 31.250000 (28.491272)
Epoch: [15][416/591]	Time  0.931 ( 0.652)	Data  0.826 ( 0.554)	Loss 8.0528e-01 (9.3148e-01)	Acc@1 18.750000 (28.387291)
Epoch: [15][432/591]	Time  0.618 ( 0.653)	Data  0.520 ( 0.554)	Loss 1.0502e+00 (9.3227e-01)	Acc@1 25.000000 (28.521940)
Epoch: [15][448/591]	Time  0.614 ( 0.652)	Data  0.517 ( 0.553)	Loss 1.1116e+00 (9.3270e-01)	Acc@1 31.250000 (28.688753)
Epoch: [15][464/591]	Time  0.618 ( 0.651)	Data  0.521 ( 0.553)	Loss 1.0923e+00 (9.3214e-01)	Acc@1 18.750000 (28.763441)
Epoch: [15][480/591]	Time  0.637 ( 0.651)	Data  0.540 ( 0.553)	Loss 8.8347e-01 (9.3230e-01)	Acc@1 37.500000 (28.976091)
Epoch: [15][496/591]	Time  0.633 ( 0.650)	Data  0.536 ( 0.552)	Loss 1.1855e+00 (9.3324e-01)	Acc@1 6.250000 (29.061871)
Epoch: [15][512/591]	Time  0.682 ( 0.652)	Data  0.585 ( 0.554)	Loss 8.2058e-01 (9.3234e-01)	Acc@1 18.750000 (29.142300)
Epoch: [15][528/591]	Time  0.675 ( 0.652)	Data  0.577 ( 0.554)	Loss 1.3523e+00 (9.3276e-01)	Acc@1 18.750000 (29.087902)
Epoch: [15][544/591]	Time  0.661 ( 0.651)	Data  0.564 ( 0.553)	Loss 8.2220e-01 (9.3437e-01)	Acc@1 37.500000 (29.002295)
Epoch: [15][560/591]	Time  0.599 ( 0.651)	Data  0.502 ( 0.553)	Loss 1.0700e+00 (9.3451e-01)	Acc@1 6.250000 (28.888145)
Epoch: [15][576/591]	Time  0.606 ( 0.651)	Data  0.508 ( 0.553)	Loss 1.1561e+00 (9.3537e-01)	Acc@1 25.000000 (28.834488)
##################################################
train_loss:  0.9358275356228178
train_acc:  tensor(28.9234, device='cuda:0')
##################################################
Best model was saved.
Epoch: [16][  0/591]	Time  0.613 ( 0.613)	Data  0.515 ( 0.515)	Loss 8.5409e-01 (8.5409e-01)	Acc@1 12.500000 (12.500000)
Epoch: [16][ 16/591]	Time  0.636 ( 0.695)	Data  0.539 ( 0.595)	Loss 8.8547e-01 (9.0413e-01)	Acc@1 37.500000 (27.205883)
Epoch: [16][ 32/591]	Time  0.594 ( 0.666)	Data  0.496 ( 0.567)	Loss 1.0876e+00 (9.1397e-01)	Acc@1 31.250000 (28.977274)
Epoch: [16][ 48/591]	Time  0.601 ( 0.654)	Data  0.504 ( 0.556)	Loss 8.8335e-01 (9.2525e-01)	Acc@1 43.750000 (28.316326)
Epoch: [16][ 64/591]	Time  0.613 ( 0.650)	Data  0.516 ( 0.552)	Loss 1.1552e+00 (9.2791e-01)	Acc@1 31.250000 (28.365385)
Epoch: [16][ 80/591]	Time  0.600 ( 0.647)	Data  0.499 ( 0.549)	Loss 8.8139e-01 (9.1583e-01)	Acc@1 31.250000 (28.472223)
Epoch: [16][ 96/591]	Time  0.682 ( 0.643)	Data  0.585 ( 0.545)	Loss 8.8320e-01 (9.1655e-01)	Acc@1 50.000000 (28.865978)
Epoch: [16][112/591]	Time  0.646 ( 0.652)	Data  0.548 ( 0.554)	Loss 6.6851e-01 (9.1352e-01)	Acc@1 25.000000 (28.152655)
Epoch: [16][128/591]	Time  0.611 ( 0.649)	Data  0.513 ( 0.551)	Loss 1.0016e+00 (9.1329e-01)	Acc@1 43.750000 (28.343023)
Epoch: [16][144/591]	Time  0.678 ( 0.655)	Data  0.580 ( 0.557)	Loss 8.9452e-01 (9.1553e-01)	Acc@1 6.250000 (27.758621)
Epoch: [16][160/591]	Time  0.648 ( 0.653)	Data  0.550 ( 0.555)	Loss 1.1185e+00 (9.1885e-01)	Acc@1 37.500000 (27.678572)
Epoch: [16][176/591]	Time  0.650 ( 0.651)	Data  0.553 ( 0.553)	Loss 8.6560e-01 (9.2066e-01)	Acc@1 31.250000 (27.718927)
Epoch: [16][192/591]	Time  0.939 ( 0.653)	Data  0.826 ( 0.555)	Loss 9.7012e-01 (9.2239e-01)	Acc@1 25.000000 (28.011658)
Epoch: [16][208/591]	Time  0.559 ( 0.653)	Data  0.462 ( 0.554)	Loss 1.0182e+00 (9.2241e-01)	Acc@1 18.750000 (28.020334)
Epoch: [16][224/591]	Time  0.663 ( 0.652)	Data  0.565 ( 0.553)	Loss 9.3929e-01 (9.2461e-01)	Acc@1 37.500000 (27.916668)
Epoch: [16][240/591]	Time  0.715 ( 0.653)	Data  0.617 ( 0.555)	Loss 9.9194e-01 (9.2598e-01)	Acc@1 18.750000 (27.956432)
Epoch: [16][256/591]	Time  0.596 ( 0.654)	Data  0.498 ( 0.555)	Loss 8.4665e-01 (9.2757e-01)	Acc@1 43.750000 (28.404669)
Epoch: [16][272/591]	Time  0.644 ( 0.652)	Data  0.542 ( 0.554)	Loss 8.3587e-01 (9.2786e-01)	Acc@1 25.000000 (28.571428)
Epoch: [16][288/591]	Time  0.635 ( 0.655)	Data  0.538 ( 0.556)	Loss 1.0955e+00 (9.2830e-01)	Acc@1 6.250000 (28.352077)
Epoch: [16][304/591]	Time  0.611 ( 0.653)	Data  0.513 ( 0.555)	Loss 9.9668e-01 (9.2790e-01)	Acc@1 31.250000 (28.483606)
Epoch: [16][320/591]	Time  0.620 ( 0.652)	Data  0.523 ( 0.554)	Loss 1.0118e+00 (9.2514e-01)	Acc@1 12.500000 (28.563084)
Epoch: [16][336/591]	Time  0.653 ( 0.651)	Data  0.556 ( 0.553)	Loss 8.9744e-01 (9.2520e-01)	Acc@1 37.500000 (28.505192)
Epoch: [16][352/591]	Time  0.584 ( 0.650)	Data  0.486 ( 0.552)	Loss 9.0615e-01 (9.2458e-01)	Acc@1 12.500000 (28.346317)
Epoch: [16][368/591]	Time  0.648 ( 0.650)	Data  0.551 ( 0.552)	Loss 8.1420e-01 (9.2676e-01)	Acc@1 43.750000 (28.319784)
Epoch: [16][384/591]	Time  0.618 ( 0.654)	Data  0.521 ( 0.555)	Loss 7.6558e-01 (9.2751e-01)	Acc@1 18.750000 (28.441559)
Epoch: [16][400/591]	Time  0.731 ( 0.655)	Data  0.634 ( 0.557)	Loss 9.5906e-01 (9.2737e-01)	Acc@1 18.750000 (28.460100)
Epoch: [16][416/591]	Time  0.583 ( 0.654)	Data  0.486 ( 0.556)	Loss 1.0781e+00 (9.2485e-01)	Acc@1 12.500000 (28.372303)
Epoch: [16][432/591]	Time  0.615 ( 0.654)	Data  0.517 ( 0.555)	Loss 7.0957e-01 (9.2285e-01)	Acc@1 37.500000 (28.637413)
Epoch: [16][448/591]	Time  0.571 ( 0.652)	Data  0.473 ( 0.554)	Loss 9.9578e-01 (9.2370e-01)	Acc@1 31.250000 (28.549555)
Epoch: [16][464/591]	Time  0.619 ( 0.651)	Data  0.521 ( 0.553)	Loss 7.9679e-01 (9.2365e-01)	Acc@1 31.250000 (28.454302)
Epoch: [16][480/591]	Time  0.603 ( 0.653)	Data  0.506 ( 0.555)	Loss 9.7418e-01 (9.2370e-01)	Acc@1 12.500000 (28.209459)
Epoch: [16][496/591]	Time  0.623 ( 0.652)	Data  0.525 ( 0.554)	Loss 1.1521e+00 (9.2464e-01)	Acc@1 25.000000 (28.257042)
Epoch: [16][512/591]	Time  0.774 ( 0.652)	Data  0.677 ( 0.554)	Loss 1.1295e+00 (9.2655e-01)	Acc@1 31.250000 (28.216375)
Epoch: [16][528/591]	Time  0.620 ( 0.651)	Data  0.523 ( 0.553)	Loss 8.8778e-01 (9.2812e-01)	Acc@1 18.750000 (28.260870)
Epoch: [16][544/591]	Time  0.628 ( 0.651)	Data  0.530 ( 0.553)	Loss 7.2859e-01 (9.2727e-01)	Acc@1 18.750000 (28.325687)
Epoch: [16][560/591]	Time  0.861 ( 0.652)	Data  0.753 ( 0.554)	Loss 8.1584e-01 (9.2860e-01)	Acc@1 6.250000 (28.308823)
Epoch: [16][576/591]	Time  0.615 ( 0.653)	Data  0.517 ( 0.555)	Loss 9.7184e-01 (9.3052e-01)	Acc@1 37.500000 (28.390381)
##################################################
train_loss:  0.9304026527654903
train_acc:  tensor(28.5427, device='cuda:0')
##################################################
Best model was saved.
Epoch: [17][  0/591]	Time  0.656 ( 0.656)	Data  0.559 ( 0.559)	Loss 5.1667e-01 (5.1667e-01)	Acc@1 50.000000 (50.000000)
Epoch: [17][ 16/591]	Time  0.642 ( 0.643)	Data  0.545 ( 0.545)	Loss 8.3156e-01 (9.2882e-01)	Acc@1 31.250000 (28.308825)
Epoch: [17][ 32/591]	Time  0.614 ( 0.632)	Data  0.516 ( 0.534)	Loss 1.0470e+00 (9.2813e-01)	Acc@1 18.750000 (27.840910)
Epoch: [17][ 48/591]	Time  0.692 ( 0.631)	Data  0.595 ( 0.533)	Loss 9.6874e-01 (9.5279e-01)	Acc@1 25.000000 (27.040815)
Epoch: [17][ 64/591]	Time  0.580 ( 0.646)	Data  0.482 ( 0.547)	Loss 6.9065e-01 (9.3702e-01)	Acc@1 37.500000 (28.173077)
Epoch: [17][ 80/591]	Time  0.578 ( 0.640)	Data  0.480 ( 0.542)	Loss 1.0035e+00 (9.5119e-01)	Acc@1 12.500000 (27.469135)
Epoch: [17][ 96/591]	Time  0.597 ( 0.643)	Data  0.499 ( 0.545)	Loss 1.0378e+00 (9.3699e-01)	Acc@1 18.750000 (27.706184)
Epoch: [17][112/591]	Time  0.642 ( 0.647)	Data  0.544 ( 0.549)	Loss 8.4852e-01 (9.3621e-01)	Acc@1 37.500000 (27.931416)
Epoch: [17][128/591]	Time  0.648 ( 0.645)	Data  0.551 ( 0.547)	Loss 8.2706e-01 (9.3911e-01)	Acc@1 31.250000 (28.052326)
Epoch: [17][144/591]	Time  0.729 ( 0.645)	Data  0.631 ( 0.547)	Loss 1.0280e+00 (9.3307e-01)	Acc@1 31.250000 (28.318966)
Epoch: [17][160/591]	Time  0.634 ( 0.651)	Data  0.537 ( 0.553)	Loss 9.1886e-01 (9.3058e-01)	Acc@1 18.750000 (28.260870)
Epoch: [17][176/591]	Time  0.632 ( 0.649)	Data  0.534 ( 0.551)	Loss 1.0893e+00 (9.2977e-01)	Acc@1 18.750000 (28.425140)
Epoch: [17][192/591]	Time  0.611 ( 0.648)	Data  0.513 ( 0.550)	Loss 8.0476e-01 (9.3158e-01)	Acc@1 37.500000 (27.979275)
Epoch: [17][208/591]	Time  0.604 ( 0.647)	Data  0.507 ( 0.549)	Loss 1.1441e+00 (9.3181e-01)	Acc@1 50.000000 (27.960526)
Epoch: [17][224/591]	Time  0.765 ( 0.648)	Data  0.667 ( 0.550)	Loss 8.3263e-01 (9.3199e-01)	Acc@1 18.750000 (28.027779)
Epoch: [17][240/591]	Time  0.604 ( 0.647)	Data  0.506 ( 0.549)	Loss 1.0299e+00 (9.3083e-01)	Acc@1 37.500000 (28.319504)
Epoch: [17][256/591]	Time  0.581 ( 0.649)	Data  0.484 ( 0.551)	Loss 9.1768e-01 (9.2982e-01)	Acc@1 43.750000 (28.356031)
Epoch: [17][272/591]	Time  0.622 ( 0.648)	Data  0.522 ( 0.550)	Loss 1.0510e+00 (9.3001e-01)	Acc@1 31.250000 (28.411173)
Epoch: [17][288/591]	Time  0.609 ( 0.647)	Data  0.511 ( 0.549)	Loss 9.4829e-01 (9.2981e-01)	Acc@1 18.750000 (28.698097)
Epoch: [17][304/591]	Time  0.611 ( 0.648)	Data  0.513 ( 0.550)	Loss 8.6503e-01 (9.2707e-01)	Acc@1 43.750000 (28.565575)
Epoch: [17][320/591]	Time  0.571 ( 0.648)	Data  0.473 ( 0.550)	Loss 9.4868e-01 (9.2699e-01)	Acc@1 25.000000 (28.640965)
Epoch: [17][336/591]	Time  1.906 ( 0.653)	Data  1.809 ( 0.555)	Loss 7.6154e-01 (9.2646e-01)	Acc@1 50.000000 (28.709198)
Epoch: [17][352/591]	Time  0.592 ( 0.652)	Data  0.494 ( 0.554)	Loss 6.8382e-01 (9.2389e-01)	Acc@1 37.500000 (28.895184)
Epoch: [17][368/591]	Time  0.611 ( 0.652)	Data  0.513 ( 0.553)	Loss 8.8082e-01 (9.2506e-01)	Acc@1 12.500000 (28.827913)
Epoch: [17][384/591]	Time  0.585 ( 0.650)	Data  0.488 ( 0.552)	Loss 9.4219e-01 (9.2569e-01)	Acc@1 25.000000 (28.668831)
Epoch: [17][400/591]	Time  0.649 ( 0.649)	Data  0.551 ( 0.551)	Loss 1.2379e+00 (9.2595e-01)	Acc@1 31.250000 (28.693892)
Epoch: [17][416/591]	Time  0.609 ( 0.649)	Data  0.511 ( 0.551)	Loss 9.1060e-01 (9.2488e-01)	Acc@1 37.500000 (28.702040)
Epoch: [17][432/591]	Time  0.659 ( 0.651)	Data  0.562 ( 0.553)	Loss 7.2850e-01 (9.2290e-01)	Acc@1 43.750000 (28.868361)
Epoch: [17][448/591]	Time  0.641 ( 0.650)	Data  0.543 ( 0.552)	Loss 1.1460e+00 (9.2404e-01)	Acc@1 37.500000 (28.994989)
Epoch: [17][464/591]	Time  0.636 ( 0.651)	Data  0.537 ( 0.553)	Loss 7.5136e-01 (9.2436e-01)	Acc@1 25.000000 (29.018818)
Epoch: [17][480/591]	Time  0.659 ( 0.651)	Data  0.562 ( 0.553)	Loss 9.5344e-01 (9.2208e-01)	Acc@1 62.500000 (29.300936)
Epoch: [17][496/591]	Time  0.677 ( 0.651)	Data  0.579 ( 0.552)	Loss 9.0817e-01 (9.2139e-01)	Acc@1 43.750000 (29.439135)
Epoch: [17][512/591]	Time  0.651 ( 0.650)	Data  0.554 ( 0.552)	Loss 8.5667e-01 (9.2204e-01)	Acc@1 37.500000 (29.471249)
Epoch: [17][528/591]	Time  0.677 ( 0.651)	Data  0.580 ( 0.553)	Loss 1.0592e+00 (9.2123e-01)	Acc@1 18.750000 (29.406900)
Epoch: [17][544/591]	Time  0.589 ( 0.651)	Data  0.492 ( 0.553)	Loss 8.1654e-01 (9.2043e-01)	Acc@1 18.750000 (29.472477)
Epoch: [17][560/591]	Time  0.583 ( 0.650)	Data  0.485 ( 0.552)	Loss 1.0085e+00 (9.1992e-01)	Acc@1 31.250000 (29.467468)
Epoch: [17][576/591]	Time  0.650 ( 0.650)	Data  0.552 ( 0.552)	Loss 9.2930e-01 (9.2278e-01)	Acc@1 18.750000 (29.419411)
##################################################
train_loss:  0.9237098790667384
train_acc:  tensor(29.3359, device='cuda:0')
##################################################
Best model was saved.
Epoch: [18][  0/591]	Time  0.660 ( 0.660)	Data  0.562 ( 0.562)	Loss 9.0586e-01 (9.0586e-01)	Acc@1 25.000000 (25.000000)
Epoch: [18][ 16/591]	Time  0.613 ( 0.638)	Data  0.515 ( 0.540)	Loss 9.9284e-01 (9.4295e-01)	Acc@1 25.000000 (34.926472)
Epoch: [18][ 32/591]	Time  0.672 ( 0.668)	Data  0.574 ( 0.569)	Loss 9.5421e-01 (9.3450e-01)	Acc@1 25.000000 (32.007576)
Epoch: [18][ 48/591]	Time  0.692 ( 0.655)	Data  0.594 ( 0.557)	Loss 9.7271e-01 (9.2783e-01)	Acc@1 31.250000 (30.484694)
Epoch: [18][ 64/591]	Time  0.663 ( 0.656)	Data  0.566 ( 0.558)	Loss 9.3833e-01 (9.2055e-01)	Acc@1 43.750000 (29.711538)
Epoch: [18][ 80/591]	Time  0.616 ( 0.653)	Data  0.518 ( 0.555)	Loss 9.5858e-01 (9.2890e-01)	Acc@1 18.750000 (29.398148)
Epoch: [18][ 96/591]	Time  0.640 ( 0.649)	Data  0.543 ( 0.551)	Loss 1.0776e+00 (9.2543e-01)	Acc@1 43.750000 (29.574741)
Epoch: [18][112/591]	Time  0.944 ( 0.655)	Data  0.833 ( 0.556)	Loss 1.0248e+00 (9.1852e-01)	Acc@1 31.250000 (29.258850)
Epoch: [18][128/591]	Time  0.589 ( 0.654)	Data  0.491 ( 0.555)	Loss 9.6071e-01 (9.1588e-01)	Acc@1 43.750000 (29.505814)
Epoch: [18][144/591]	Time  0.646 ( 0.653)	Data  0.548 ( 0.555)	Loss 1.1705e+00 (9.1312e-01)	Acc@1 12.500000 (29.353449)
Epoch: [18][160/591]	Time  0.621 ( 0.652)	Data  0.524 ( 0.554)	Loss 1.1213e+00 (9.1440e-01)	Acc@1 31.250000 (29.619566)
Epoch: [18][176/591]	Time  0.596 ( 0.650)	Data  0.498 ( 0.552)	Loss 8.7442e-01 (9.1150e-01)	Acc@1 37.500000 (29.766949)
Epoch: [18][192/591]	Time  0.651 ( 0.648)	Data  0.553 ( 0.549)	Loss 8.8029e-01 (9.1120e-01)	Acc@1 25.000000 (29.404144)
Epoch: [18][208/591]	Time  0.571 ( 0.651)	Data  0.473 ( 0.553)	Loss 7.6672e-01 (9.1461e-01)	Acc@1 31.250000 (29.635166)
Epoch: [18][224/591]	Time  0.663 ( 0.651)	Data  0.565 ( 0.552)	Loss 1.0934e+00 (9.1524e-01)	Acc@1 31.250000 (29.888889)
Epoch: [18][240/591]	Time  0.617 ( 0.649)	Data  0.519 ( 0.550)	Loss 6.2235e-01 (9.1646e-01)	Acc@1 25.000000 (30.134857)
Epoch: [18][256/591]	Time  0.637 ( 0.649)	Data  0.539 ( 0.551)	Loss 7.0817e-01 (9.1345e-01)	Acc@1 31.250000 (30.520428)
Epoch: [18][272/591]	Time  0.610 ( 0.649)	Data  0.512 ( 0.551)	Loss 8.2614e-01 (9.1412e-01)	Acc@1 18.750000 (30.425825)
Epoch: [18][288/591]	Time  0.584 ( 0.648)	Data  0.486 ( 0.550)	Loss 9.8782e-01 (9.1811e-01)	Acc@1 18.750000 (30.233564)
Epoch: [18][304/591]	Time  0.624 ( 0.651)	Data  0.526 ( 0.552)	Loss 1.1149e+00 (9.1708e-01)	Acc@1 43.750000 (30.040983)
Epoch: [18][320/591]	Time  0.603 ( 0.651)	Data  0.506 ( 0.553)	Loss 1.0502e+00 (9.1710e-01)	Acc@1 12.500000 (30.198597)
Epoch: [18][336/591]	Time  0.600 ( 0.651)	Data  0.502 ( 0.553)	Loss 8.8975e-01 (9.1736e-01)	Acc@1 50.000000 (30.267061)
Epoch: [18][352/591]	Time  0.832 ( 0.653)	Data  0.735 ( 0.555)	Loss 9.1196e-01 (9.1733e-01)	Acc@1 18.750000 (30.258497)
Epoch: [18][368/591]	Time  0.632 ( 0.652)	Data  0.534 ( 0.554)	Loss 8.8980e-01 (9.1647e-01)	Acc@1 31.250000 (30.436993)
Epoch: [18][384/591]	Time  0.644 ( 0.651)	Data  0.546 ( 0.553)	Loss 9.1201e-01 (9.1751e-01)	Acc@1 25.000000 (30.438311)
Epoch: [18][400/591]	Time  0.656 ( 0.652)	Data  0.558 ( 0.554)	Loss 9.3281e-01 (9.1832e-01)	Acc@1 25.000000 (30.346010)
Epoch: [18][416/591]	Time  0.635 ( 0.653)	Data  0.537 ( 0.554)	Loss 8.9002e-01 (9.1782e-01)	Acc@1 43.750000 (30.350719)
Epoch: [18][432/591]	Time  0.674 ( 0.652)	Data  0.575 ( 0.554)	Loss 8.3519e-01 (9.1669e-01)	Acc@1 43.750000 (30.456120)
Epoch: [18][448/591]	Time  0.611 ( 0.653)	Data  0.513 ( 0.554)	Loss 1.0483e+00 (9.1835e-01)	Acc@1 31.250000 (30.275614)
Epoch: [18][464/591]	Time  0.596 ( 0.651)	Data  0.498 ( 0.553)	Loss 8.0379e-01 (9.1715e-01)	Acc@1 43.750000 (30.255377)
Epoch: [18][480/591]	Time  0.998 ( 0.653)	Data  0.878 ( 0.555)	Loss 9.3469e-01 (9.1692e-01)	Acc@1 31.250000 (30.249481)
Epoch: [18][496/591]	Time  0.600 ( 0.652)	Data  0.502 ( 0.554)	Loss 1.0882e+00 (9.1747e-01)	Acc@1 31.250000 (30.306841)
Epoch: [18][512/591]	Time  0.584 ( 0.652)	Data  0.486 ( 0.554)	Loss 9.6502e-01 (9.1795e-01)	Acc@1 25.000000 (30.153509)
Epoch: [18][528/591]	Time  0.642 ( 0.652)	Data  0.543 ( 0.554)	Loss 7.7337e-01 (9.1661e-01)	Acc@1 25.000000 (30.151230)
Epoch: [18][544/591]	Time  0.609 ( 0.652)	Data  0.511 ( 0.554)	Loss 7.0593e-01 (9.1691e-01)	Acc@1 18.750000 (30.160551)
Epoch: [18][560/591]	Time  0.605 ( 0.651)	Data  0.507 ( 0.553)	Loss 9.5744e-01 (9.1795e-01)	Acc@1 18.750000 (30.102495)
Epoch: [18][576/591]	Time  0.582 ( 0.653)	Data  0.484 ( 0.555)	Loss 7.3070e-01 (9.1719e-01)	Acc@1 31.250000 (30.069324)
##################################################
train_loss:  0.918086331810443
train_acc:  tensor(30.1925, device='cuda:0')
##################################################
Best model was saved.
Epoch: [19][  0/591]	Time  0.613 ( 0.613)	Data  0.515 ( 0.515)	Loss 8.7899e-01 (8.7899e-01)	Acc@1 18.750000 (18.750000)
Epoch: [19][ 16/591]	Time  0.643 ( 0.642)	Data  0.546 ( 0.544)	Loss 1.1435e+00 (9.2438e-01)	Acc@1 31.250000 (25.735294)
Epoch: [19][ 32/591]	Time  0.656 ( 0.639)	Data  0.559 ( 0.541)	Loss 9.5295e-01 (9.5187e-01)	Acc@1 37.500000 (27.840910)
Epoch: [19][ 48/591]	Time  0.592 ( 0.631)	Data  0.494 ( 0.533)	Loss 9.7046e-01 (9.2870e-01)	Acc@1 56.250000 (29.081633)
Epoch: [19][ 64/591]	Time  0.626 ( 0.630)	Data  0.528 ( 0.533)	Loss 8.9718e-01 (9.1677e-01)	Acc@1 31.250000 (28.750000)
Epoch: [19][ 80/591]	Time  0.605 ( 0.647)	Data  0.508 ( 0.549)	Loss 7.1726e-01 (9.2142e-01)	Acc@1 12.500000 (28.163580)
Epoch: [19][ 96/591]	Time  0.707 ( 0.651)	Data  0.608 ( 0.553)	Loss 8.5229e-01 (9.2839e-01)	Acc@1 25.000000 (28.543814)
Epoch: [19][112/591]	Time  0.630 ( 0.648)	Data  0.532 ( 0.550)	Loss 1.0219e+00 (9.2705e-01)	Acc@1 43.750000 (29.037611)
Epoch: [19][128/591]	Time  0.613 ( 0.648)	Data  0.515 ( 0.550)	Loss 1.0076e+00 (9.2540e-01)	Acc@1 31.250000 (28.875969)
Epoch: [19][144/591]	Time  0.661 ( 0.646)	Data  0.563 ( 0.548)	Loss 1.0332e+00 (9.3046e-01)	Acc@1 43.750000 (29.094828)
Epoch: [19][160/591]	Time  0.677 ( 0.644)	Data  0.552 ( 0.546)	Loss 7.5140e-01 (9.3449e-01)	Acc@1 37.500000 (29.503107)
Epoch: [19][176/591]	Time  0.613 ( 0.649)	Data  0.515 ( 0.551)	Loss 6.6271e-01 (9.3422e-01)	Acc@1 25.000000 (29.237288)
Epoch: [19][192/591]	Time  0.628 ( 0.648)	Data  0.530 ( 0.550)	Loss 8.2837e-01 (9.2958e-01)	Acc@1 37.500000 (28.983160)
Epoch: [19][208/591]	Time  0.637 ( 0.648)	Data  0.540 ( 0.550)	Loss 8.4846e-01 (9.3031e-01)	Acc@1 31.250000 (29.037081)
Epoch: [19][224/591]	Time  0.595 ( 0.648)	Data  0.497 ( 0.549)	Loss 9.9648e-01 (9.2903e-01)	Acc@1 37.500000 (29.250000)
Epoch: [19][240/591]	Time  0.608 ( 0.648)	Data  0.510 ( 0.549)	Loss 1.0124e+00 (9.3085e-01)	Acc@1 31.250000 (29.408714)
Epoch: [19][256/591]	Time  0.856 ( 0.651)	Data  0.758 ( 0.552)	Loss 8.2515e-01 (9.3326e-01)	Acc@1 12.500000 (29.280155)
Epoch: [19][272/591]	Time  0.643 ( 0.651)	Data  0.546 ( 0.553)	Loss 9.2021e-01 (9.3122e-01)	Acc@1 31.250000 (29.555861)
Epoch: [19][288/591]	Time  0.663 ( 0.650)	Data  0.565 ( 0.552)	Loss 1.0600e+00 (9.3339e-01)	Acc@1 31.250000 (29.779413)
Epoch: [19][304/591]	Time  0.632 ( 0.649)	Data  0.535 ( 0.551)	Loss 7.5924e-01 (9.2580e-01)	Acc@1 50.000000 (30.000000)
Epoch: [19][320/591]	Time  0.687 ( 0.649)	Data  0.590 ( 0.551)	Loss 1.1245e+00 (9.2831e-01)	Acc@1 37.500000 (30.023363)
Epoch: [19][336/591]	Time  0.652 ( 0.649)	Data  0.555 ( 0.550)	Loss 8.5382e-01 (9.2527e-01)	Acc@1 31.250000 (29.766321)
Epoch: [19][352/591]	Time  0.637 ( 0.651)	Data  0.539 ( 0.553)	Loss 1.1847e+00 (9.2500e-01)	Acc@1 37.500000 (29.638809)
Epoch: [19][368/591]	Time  0.646 ( 0.653)	Data  0.548 ( 0.555)	Loss 9.2598e-01 (9.2688e-01)	Acc@1 25.000000 (29.471546)
Epoch: [19][384/591]	Time  0.673 ( 0.654)	Data  0.575 ( 0.556)	Loss 1.1250e+00 (9.2497e-01)	Acc@1 37.500000 (29.448051)
Epoch: [19][400/591]	Time  0.636 ( 0.652)	Data  0.538 ( 0.554)	Loss 8.1837e-01 (9.2391e-01)	Acc@1 31.250000 (29.629053)
Epoch: [19][416/591]	Time  0.621 ( 0.651)	Data  0.523 ( 0.553)	Loss 8.3644e-01 (9.2412e-01)	Acc@1 43.750000 (29.841127)
Epoch: [19][432/591]	Time  0.671 ( 0.651)	Data  0.573 ( 0.553)	Loss 1.0375e+00 (9.2570e-01)	Acc@1 56.250000 (29.979792)
Epoch: [19][448/591]	Time  0.635 ( 0.654)	Data  0.537 ( 0.556)	Loss 1.0517e+00 (9.2713e-01)	Acc@1 6.250000 (29.844099)
Epoch: [19][464/591]	Time  0.613 ( 0.653)	Data  0.516 ( 0.554)	Loss 9.1996e-01 (9.2517e-01)	Acc@1 18.750000 (29.892473)
Epoch: [19][480/591]	Time  0.589 ( 0.652)	Data  0.491 ( 0.553)	Loss 1.0906e+00 (9.2540e-01)	Acc@1 18.750000 (29.729731)
Epoch: [19][496/591]	Time  0.668 ( 0.650)	Data  0.570 ( 0.552)	Loss 1.1791e+00 (9.2596e-01)	Acc@1 18.750000 (29.665491)
Epoch: [19][512/591]	Time  0.653 ( 0.650)	Data  0.555 ( 0.552)	Loss 1.0367e+00 (9.2723e-01)	Acc@1 18.750000 (29.556530)
Epoch: [19][528/591]	Time  0.649 ( 0.649)	Data  0.552 ( 0.551)	Loss 9.2997e-01 (9.2702e-01)	Acc@1 31.250000 (29.595936)
Epoch: [19][544/591]	Time  0.588 ( 0.650)	Data  0.491 ( 0.552)	Loss 8.1189e-01 (9.2697e-01)	Acc@1 37.500000 (29.564220)
Epoch: [19][560/591]	Time  0.593 ( 0.649)	Data  0.496 ( 0.551)	Loss 7.0634e-01 (9.2481e-01)	Acc@1 12.500000 (29.656862)
Epoch: [19][576/591]	Time  0.639 ( 0.650)	Data  0.541 ( 0.552)	Loss 1.0329e+00 (9.2499e-01)	Acc@1 18.750000 (29.625217)
##################################################
train_loss:  0.9243987896519062
train_acc:  tensor(29.6108, device='cuda:0')
##################################################
Epoch: [20][  0/591]	Time  0.627 ( 0.627)	Data  0.530 ( 0.530)	Loss 9.1087e-01 (9.1087e-01)	Acc@1 31.250000 (31.250000)
Epoch: [20][ 16/591]	Time  0.622 ( 0.646)	Data  0.525 ( 0.549)	Loss 9.3268e-01 (8.8352e-01)	Acc@1 31.250000 (27.205883)
Epoch: [20][ 32/591]	Time  1.056 ( 0.678)	Data  0.957 ( 0.580)	Loss 6.6657e-01 (8.8316e-01)	Acc@1 37.500000 (29.734850)
Epoch: [20][ 48/591]	Time  0.631 ( 0.657)	Data  0.534 ( 0.559)	Loss 9.5161e-01 (8.7278e-01)	Acc@1 37.500000 (29.591837)
Epoch: [20][ 64/591]	Time  0.596 ( 0.652)	Data  0.499 ( 0.555)	Loss 9.1655e-01 (8.8399e-01)	Acc@1 31.250000 (29.134615)
Epoch: [20][ 80/591]	Time  0.587 ( 0.653)	Data  0.490 ( 0.555)	Loss 7.8908e-01 (8.7511e-01)	Acc@1 25.000000 (28.703705)
Epoch: [20][ 96/591]	Time  0.633 ( 0.649)	Data  0.534 ( 0.551)	Loss 1.0075e+00 (8.9039e-01)	Acc@1 37.500000 (28.543814)
Epoch: [20][112/591]	Time  0.729 ( 0.651)	Data  0.632 ( 0.553)	Loss 1.0336e+00 (8.9210e-01)	Acc@1 25.000000 (28.373894)
Epoch: [20][128/591]	Time  0.656 ( 0.656)	Data  0.559 ( 0.558)	Loss 9.4415e-01 (8.9701e-01)	Acc@1 25.000000 (29.263565)
Epoch: [20][144/591]	Time  0.644 ( 0.657)	Data  0.547 ( 0.559)	Loss 8.5216e-01 (8.9797e-01)	Acc@1 31.250000 (29.482758)
Epoch: [20][160/591]	Time  0.601 ( 0.652)	Data  0.503 ( 0.555)	Loss 1.0013e+00 (8.9472e-01)	Acc@1 18.750000 (29.891304)
Epoch: [20][176/591]	Time  0.621 ( 0.649)	Data  0.523 ( 0.551)	Loss 6.6628e-01 (8.9797e-01)	Acc@1 25.000000 (30.190678)
Epoch: [20][192/591]	Time  0.602 ( 0.647)	Data  0.505 ( 0.549)	Loss 8.8881e-01 (8.9482e-01)	Acc@1 12.500000 (30.181347)
Epoch: [20][208/591]	Time  0.641 ( 0.647)	Data  0.544 ( 0.550)	Loss 8.8761e-01 (8.9724e-01)	Acc@1 25.000000 (30.352869)
Epoch: [20][224/591]	Time  0.642 ( 0.651)	Data  0.544 ( 0.553)	Loss 9.5305e-01 (8.9758e-01)	Acc@1 37.500000 (30.361113)
Epoch: [20][240/591]	Time  0.625 ( 0.652)	Data  0.527 ( 0.554)	Loss 1.0807e+00 (9.0018e-01)	Acc@1 18.750000 (30.134857)
Epoch: [20][256/591]	Time  0.615 ( 0.651)	Data  0.516 ( 0.553)	Loss 1.0433e+00 (9.0716e-01)	Acc@1 25.000000 (29.912451)
Epoch: [20][272/591]	Time  0.657 ( 0.651)	Data  0.560 ( 0.553)	Loss 8.8708e-01 (9.0898e-01)	Acc@1 25.000000 (29.784800)
Epoch: [20][288/591]	Time  0.571 ( 0.651)	Data  0.473 ( 0.553)	Loss 1.0700e+00 (9.1289e-01)	Acc@1 6.250000 (29.390139)
Epoch: [20][304/591]	Time  0.593 ( 0.649)	Data  0.496 ( 0.551)	Loss 8.7916e-01 (9.1453e-01)	Acc@1 37.500000 (29.323771)
Epoch: [20][320/591]	Time  0.651 ( 0.654)	Data  0.552 ( 0.556)	Loss 1.0110e+00 (9.1631e-01)	Acc@1 25.000000 (29.283487)
Epoch: [20][336/591]	Time  0.652 ( 0.653)	Data  0.555 ( 0.555)	Loss 9.7012e-01 (9.1594e-01)	Acc@1 37.500000 (29.543768)
Epoch: [20][352/591]	Time  0.724 ( 0.653)	Data  0.625 ( 0.555)	Loss 1.0133e+00 (9.1482e-01)	Acc@1 25.000000 (29.656515)
Epoch: [20][368/591]	Time  0.701 ( 0.654)	Data  0.602 ( 0.556)	Loss 9.3347e-01 (9.1341e-01)	Acc@1 37.500000 (29.725611)
Epoch: [20][384/591]	Time  0.693 ( 0.655)	Data  0.596 ( 0.557)	Loss 8.6117e-01 (9.1362e-01)	Acc@1 37.500000 (29.886364)
Epoch: [20][400/591]	Time  0.719 ( 0.659)	Data  0.621 ( 0.560)	Loss 1.1090e+00 (9.1404e-01)	Acc@1 18.750000 (30.236908)
Epoch: [20][416/591]	Time  0.609 ( 0.659)	Data  0.512 ( 0.560)	Loss 8.6556e-01 (9.1214e-01)	Acc@1 31.250000 (30.185852)
Epoch: [20][432/591]	Time  0.635 ( 0.658)	Data  0.538 ( 0.560)	Loss 8.0847e-01 (9.1112e-01)	Acc@1 6.250000 (29.907621)
Epoch: [20][448/591]	Time  0.611 ( 0.660)	Data  0.513 ( 0.561)	Loss 8.8093e-01 (9.1034e-01)	Acc@1 31.250000 (30.094656)
Epoch: [20][464/591]	Time  0.620 ( 0.659)	Data  0.522 ( 0.561)	Loss 8.8189e-01 (9.0992e-01)	Acc@1 6.250000 (30.013441)
Epoch: [20][480/591]	Time  0.654 ( 0.660)	Data  0.556 ( 0.561)	Loss 7.8431e-01 (9.0991e-01)	Acc@1 37.500000 (30.119543)
Epoch: [20][496/591]	Time  0.663 ( 0.663)	Data  0.565 ( 0.564)	Loss 5.8298e-01 (9.0957e-01)	Acc@1 37.500000 (30.055330)
Epoch: [20][512/591]	Time  0.633 ( 0.662)	Data  0.535 ( 0.564)	Loss 7.8024e-01 (9.0855e-01)	Acc@1 31.250000 (30.080410)
Epoch: [20][528/591]	Time  0.639 ( 0.661)	Data  0.541 ( 0.563)	Loss 7.6688e-01 (9.0767e-01)	Acc@1 43.750000 (30.127600)
Epoch: [20][544/591]	Time  0.660 ( 0.661)	Data  0.563 ( 0.562)	Loss 6.1580e-01 (9.0585e-01)	Acc@1 50.000000 (30.126146)
Epoch: [20][560/591]	Time  0.604 ( 0.661)	Data  0.506 ( 0.562)	Loss 9.1832e-01 (9.0581e-01)	Acc@1 12.500000 (30.046791)
Epoch: [20][576/591]	Time  0.939 ( 0.662)	Data  0.833 ( 0.564)	Loss 6.9983e-01 (9.0476e-01)	Acc@1 56.250000 (30.318457)
##################################################
train_loss:  0.904822593110467
train_acc:  tensor(30.3511, device='cuda:0')
##################################################
Best model was saved.
Epoch: [21][  0/591]	Time  0.625 ( 0.625)	Data  0.527 ( 0.527)	Loss 1.0601e+00 (1.0601e+00)	Acc@1 31.250000 (31.250000)
Epoch: [21][ 16/591]	Time  0.625 ( 0.634)	Data  0.527 ( 0.536)	Loss 9.2390e-01 (9.2272e-01)	Acc@1 31.250000 (34.191177)
Epoch: [21][ 32/591]	Time  0.589 ( 0.638)	Data  0.491 ( 0.540)	Loss 8.1816e-01 (8.9532e-01)	Acc@1 37.500000 (32.007576)
Epoch: [21][ 48/591]	Time  0.634 ( 0.636)	Data  0.536 ( 0.538)	Loss 8.4258e-01 (8.9405e-01)	Acc@1 43.750000 (31.122448)
Epoch: [21][ 64/591]	Time  0.631 ( 0.637)	Data  0.533 ( 0.539)	Loss 6.9567e-01 (8.9753e-01)	Acc@1 25.000000 (31.346153)
Epoch: [21][ 80/591]	Time  0.588 ( 0.653)	Data  0.490 ( 0.554)	Loss 7.7134e-01 (8.8340e-01)	Acc@1 18.750000 (29.938272)
Epoch: [21][ 96/591]	Time  0.648 ( 0.648)	Data  0.550 ( 0.550)	Loss 8.8335e-01 (8.8561e-01)	Acc@1 18.750000 (30.154638)
Epoch: [21][112/591]	Time  0.622 ( 0.647)	Data  0.524 ( 0.549)	Loss 9.8614e-01 (8.8518e-01)	Acc@1 18.750000 (31.028761)
Epoch: [21][128/591]	Time  0.660 ( 0.647)	Data  0.563 ( 0.549)	Loss 1.1420e+00 (8.9071e-01)	Acc@1 12.500000 (30.571705)
Epoch: [21][144/591]	Time  0.613 ( 0.646)	Data  0.515 ( 0.548)	Loss 9.1130e-01 (8.8988e-01)	Acc@1 25.000000 (30.603449)
Epoch: [21][160/591]	Time  0.683 ( 0.645)	Data  0.586 ( 0.547)	Loss 8.1004e-01 (8.9142e-01)	Acc@1 25.000000 (30.007765)
Epoch: [21][176/591]	Time  0.602 ( 0.652)	Data  0.504 ( 0.554)	Loss 7.4728e-01 (8.8935e-01)	Acc@1 37.500000 (30.155367)
Epoch: [21][192/591]	Time  0.596 ( 0.650)	Data  0.499 ( 0.552)	Loss 9.7292e-01 (8.8896e-01)	Acc@1 25.000000 (30.051813)
Epoch: [21][208/591]	Time  0.665 ( 0.651)	Data  0.567 ( 0.553)	Loss 9.5371e-01 (8.8656e-01)	Acc@1 12.500000 (29.964113)
Epoch: [21][224/591]	Time  0.661 ( 0.650)	Data  0.564 ( 0.552)	Loss 8.5954e-01 (8.9226e-01)	Acc@1 25.000000 (29.861113)
Epoch: [21][240/591]	Time  0.618 ( 0.651)	Data  0.519 ( 0.552)	Loss 6.3806e-01 (8.9319e-01)	Acc@1 37.500000 (29.849586)
Epoch: [21][256/591]	Time  0.899 ( 0.653)	Data  0.794 ( 0.555)	Loss 7.8417e-01 (8.9510e-01)	Acc@1 37.500000 (29.766537)
Epoch: [21][272/591]	Time  0.623 ( 0.656)	Data  0.525 ( 0.557)	Loss 7.3767e-01 (8.9116e-01)	Acc@1 43.750000 (29.876373)
Epoch: [21][288/591]	Time  0.629 ( 0.656)	Data  0.531 ( 0.558)	Loss 7.1519e-01 (8.9134e-01)	Acc@1 25.000000 (29.736160)
Epoch: [21][304/591]	Time  0.617 ( 0.655)	Data  0.520 ( 0.556)	Loss 8.7451e-01 (8.9349e-01)	Acc@1 50.000000 (29.897541)
Epoch: [21][320/591]	Time  0.617 ( 0.655)	Data  0.519 ( 0.556)	Loss 1.2498e+00 (8.9478e-01)	Acc@1 31.250000 (29.984423)
Epoch: [21][336/591]	Time  0.861 ( 0.654)	Data  0.764 ( 0.556)	Loss 1.0376e+00 (8.9524e-01)	Acc@1 43.750000 (29.840504)
Epoch: [21][352/591]	Time  0.624 ( 0.656)	Data  0.526 ( 0.558)	Loss 1.2025e+00 (8.9835e-01)	Acc@1 31.250000 (29.656515)
Epoch: [21][368/591]	Time  0.607 ( 0.655)	Data  0.509 ( 0.557)	Loss 6.3668e-01 (8.9808e-01)	Acc@1 37.500000 (29.759485)
Epoch: [21][384/591]	Time  0.639 ( 0.656)	Data  0.541 ( 0.557)	Loss 1.1212e+00 (8.9629e-01)	Acc@1 18.750000 (29.870129)
Epoch: [21][400/591]	Time  0.628 ( 0.654)	Data  0.530 ( 0.556)	Loss 8.1095e-01 (8.9526e-01)	Acc@1 18.750000 (29.706984)
Epoch: [21][416/591]	Time  0.608 ( 0.653)	Data  0.510 ( 0.555)	Loss 6.6845e-01 (8.9599e-01)	Acc@1 31.250000 (29.781176)
Epoch: [21][432/591]	Time  0.600 ( 0.652)	Data  0.502 ( 0.554)	Loss 7.0661e-01 (8.9684e-01)	Acc@1 25.000000 (29.792147)
Epoch: [21][448/591]	Time  0.694 ( 0.655)	Data  0.597 ( 0.557)	Loss 7.7533e-01 (8.9536e-01)	Acc@1 37.500000 (29.774500)
Epoch: [21][464/591]	Time  0.742 ( 0.654)	Data  0.644 ( 0.556)	Loss 1.0072e+00 (8.9489e-01)	Acc@1 18.750000 (29.717743)
Epoch: [21][480/591]	Time  0.753 ( 0.654)	Data  0.656 ( 0.556)	Loss 8.5617e-01 (8.9420e-01)	Acc@1 25.000000 (29.690748)
Epoch: [21][496/591]	Time  0.624 ( 0.654)	Data  0.526 ( 0.555)	Loss 8.0030e-01 (8.9334e-01)	Acc@1 31.250000 (29.778671)
Epoch: [21][512/591]	Time  0.649 ( 0.653)	Data  0.551 ( 0.555)	Loss 1.0094e+00 (8.9400e-01)	Acc@1 37.500000 (29.873295)
Epoch: [21][528/591]	Time  0.633 ( 0.653)	Data  0.536 ( 0.555)	Loss 7.7042e-01 (8.9492e-01)	Acc@1 18.750000 (29.903120)
Epoch: [21][544/591]	Time  0.640 ( 0.655)	Data  0.542 ( 0.557)	Loss 7.7441e-01 (8.9372e-01)	Acc@1 37.500000 (30.011469)
Epoch: [21][560/591]	Time  0.896 ( 0.655)	Data  0.798 ( 0.557)	Loss 7.1816e-01 (8.9307e-01)	Acc@1 43.750000 (30.113636)
Epoch: [21][576/591]	Time  0.597 ( 0.656)	Data  0.499 ( 0.558)	Loss 1.0630e+00 (8.9389e-01)	Acc@1 6.250000 (30.090988)
##################################################
train_loss:  0.8946721065669697
train_acc:  tensor(30.1079, device='cuda:0')
##################################################
Best model was saved.
Epoch: [22][  0/591]	Time  0.619 ( 0.619)	Data  0.521 ( 0.521)	Loss 8.8822e-01 (8.8822e-01)	Acc@1 6.250000 (6.250000)
Epoch: [22][ 16/591]	Time  0.674 ( 0.662)	Data  0.576 ( 0.563)	Loss 9.7571e-01 (9.3667e-01)	Acc@1 18.750000 (28.676470)
Epoch: [22][ 32/591]	Time  0.754 ( 0.693)	Data  0.655 ( 0.594)	Loss 1.0651e+00 (9.2853e-01)	Acc@1 18.750000 (29.545456)
Epoch: [22][ 48/591]	Time  0.610 ( 0.681)	Data  0.512 ( 0.582)	Loss 9.2822e-01 (8.8878e-01)	Acc@1 18.750000 (29.719387)
Epoch: [22][ 64/591]	Time  0.604 ( 0.675)	Data  0.506 ( 0.577)	Loss 8.7529e-01 (8.9975e-01)	Acc@1 50.000000 (30.576923)
Epoch: [22][ 80/591]	Time  0.654 ( 0.665)	Data  0.557 ( 0.567)	Loss 1.0668e+00 (9.1584e-01)	Acc@1 31.250000 (30.169754)
Epoch: [22][ 96/591]	Time  0.615 ( 0.664)	Data  0.517 ( 0.565)	Loss 7.3135e-01 (9.0769e-01)	Acc@1 12.500000 (30.283504)
Epoch: [22][112/591]	Time  0.684 ( 0.661)	Data  0.586 ( 0.563)	Loss 7.0987e-01 (9.0210e-01)	Acc@1 31.250000 (30.254425)
Epoch: [22][128/591]	Time  0.625 ( 0.666)	Data  0.527 ( 0.568)	Loss 9.8670e-01 (8.9823e-01)	Acc@1 18.750000 (30.329456)
Epoch: [22][144/591]	Time  0.637 ( 0.664)	Data  0.540 ( 0.565)	Loss 9.6611e-01 (8.9458e-01)	Acc@1 31.250000 (30.431034)
Epoch: [22][160/591]	Time  0.688 ( 0.662)	Data  0.590 ( 0.564)	Loss 8.9962e-01 (8.9657e-01)	Acc@1 31.250000 (30.357143)
Epoch: [22][176/591]	Time  1.074 ( 0.665)	Data  0.976 ( 0.567)	Loss 8.9824e-01 (8.9356e-01)	Acc@1 37.500000 (30.649717)
Epoch: [22][192/591]	Time  0.622 ( 0.663)	Data  0.524 ( 0.565)	Loss 8.1221e-01 (8.9577e-01)	Acc@1 18.750000 (30.634714)
Epoch: [22][208/591]	Time  0.817 ( 0.667)	Data  0.719 ( 0.568)	Loss 8.8125e-01 (8.9223e-01)	Acc@1 31.250000 (30.801434)
Epoch: [22][224/591]	Time  0.623 ( 0.664)	Data  0.526 ( 0.565)	Loss 9.5815e-01 (8.8913e-01)	Acc@1 25.000000 (30.916668)
Epoch: [22][240/591]	Time  0.678 ( 0.663)	Data  0.580 ( 0.564)	Loss 8.6322e-01 (8.9194e-01)	Acc@1 18.750000 (30.809130)
Epoch: [22][256/591]	Time  0.630 ( 0.661)	Data  0.532 ( 0.563)	Loss 1.0690e+00 (8.8738e-01)	Acc@1 18.750000 (30.812256)
Epoch: [22][272/591]	Time  0.659 ( 0.660)	Data  0.561 ( 0.562)	Loss 1.1026e+00 (8.8972e-01)	Acc@1 18.750000 (30.723444)
Epoch: [22][288/591]	Time  0.625 ( 0.661)	Data  0.528 ( 0.563)	Loss 1.0186e+00 (8.9176e-01)	Acc@1 31.250000 (30.795849)
Epoch: [22][304/591]	Time  0.589 ( 0.663)	Data  0.491 ( 0.565)	Loss 8.0336e-01 (8.9265e-01)	Acc@1 37.500000 (30.799181)
Epoch: [22][320/591]	Time  0.796 ( 0.663)	Data  0.698 ( 0.564)	Loss 1.0523e+00 (8.9327e-01)	Acc@1 43.750000 (30.957943)
Epoch: [22][336/591]	Time  0.655 ( 0.663)	Data  0.558 ( 0.565)	Loss 9.2527e-01 (8.9193e-01)	Acc@1 25.000000 (30.656528)
Epoch: [22][352/591]	Time  0.622 ( 0.662)	Data  0.524 ( 0.564)	Loss 7.5466e-01 (8.8935e-01)	Acc@1 43.750000 (30.612606)
Epoch: [22][368/591]	Time  0.612 ( 0.661)	Data  0.514 ( 0.562)	Loss 7.4187e-01 (8.8947e-01)	Acc@1 31.250000 (30.470867)
Epoch: [22][384/591]	Time  0.615 ( 0.659)	Data  0.517 ( 0.561)	Loss 1.0402e+00 (8.8833e-01)	Acc@1 37.500000 (30.616882)
Epoch: [22][400/591]	Time  0.636 ( 0.662)	Data  0.538 ( 0.564)	Loss 8.9991e-01 (8.9039e-01)	Acc@1 25.000000 (30.533043)
Epoch: [22][416/591]	Time  0.864 ( 0.663)	Data  0.767 ( 0.565)	Loss 1.0916e+00 (8.8946e-01)	Acc@1 18.750000 (30.395683)
Epoch: [22][432/591]	Time  0.880 ( 0.662)	Data  0.783 ( 0.564)	Loss 7.9611e-01 (8.8983e-01)	Acc@1 37.500000 (30.672632)
Epoch: [22][448/591]	Time  0.701 ( 0.662)	Data  0.603 ( 0.563)	Loss 7.7212e-01 (8.8926e-01)	Acc@1 25.000000 (30.637529)
Epoch: [22][464/591]	Time  0.746 ( 0.661)	Data  0.648 ( 0.563)	Loss 9.3157e-01 (8.8960e-01)	Acc@1 18.750000 (30.631721)
Epoch: [22][480/591]	Time  0.755 ( 0.664)	Data  0.657 ( 0.566)	Loss 7.5041e-01 (8.8909e-01)	Acc@1 50.000000 (30.613306)
Epoch: [22][496/591]	Time  0.619 ( 0.663)	Data  0.521 ( 0.565)	Loss 7.7767e-01 (8.8848e-01)	Acc@1 31.250000 (30.570925)
Epoch: [22][512/591]	Time  0.620 ( 0.662)	Data  0.522 ( 0.564)	Loss 1.0270e+00 (8.8827e-01)	Acc@1 37.500000 (30.543373)
Epoch: [22][528/591]	Time  0.623 ( 0.661)	Data  0.526 ( 0.563)	Loss 6.4920e-01 (8.8749e-01)	Acc@1 31.250000 (30.493856)
Epoch: [22][544/591]	Time  0.673 ( 0.661)	Data  0.576 ( 0.562)	Loss 1.2505e+00 (8.8723e-01)	Acc@1 31.250000 (30.481651)
Epoch: [22][560/591]	Time  0.634 ( 0.660)	Data  0.536 ( 0.562)	Loss 7.2171e-01 (8.8781e-01)	Acc@1 43.750000 (30.447861)
Epoch: [22][576/591]	Time  0.602 ( 0.661)	Data  0.503 ( 0.563)	Loss 9.6494e-01 (8.8736e-01)	Acc@1 25.000000 (30.502600)
##################################################
train_loss:  0.8874536324071803
train_acc:  tensor(30.6895, device='cuda:0')
##################################################
Best model was saved.
Epoch: [23][  0/591]	Time  0.593 ( 0.593)	Data  0.495 ( 0.495)	Loss 6.6388e-01 (6.6388e-01)	Acc@1 37.500000 (37.500000)
Epoch: [23][ 16/591]	Time  0.593 ( 0.619)	Data  0.498 ( 0.522)	Loss 1.0309e+00 (8.8143e-01)	Acc@1 50.000000 (34.558823)
Epoch: [23][ 32/591]	Time  0.597 ( 0.639)	Data  0.500 ( 0.541)	Loss 8.4084e-01 (9.1320e-01)	Acc@1 12.500000 (32.954548)
Epoch: [23][ 48/591]	Time  0.717 ( 0.646)	Data  0.619 ( 0.548)	Loss 9.2090e-01 (9.0505e-01)	Acc@1 37.500000 (31.887754)
Epoch: [23][ 64/591]	Time  0.605 ( 0.642)	Data  0.508 ( 0.545)	Loss 9.8715e-01 (8.9426e-01)	Acc@1 18.750000 (31.634615)
Epoch: [23][ 80/591]	Time  0.652 ( 0.652)	Data  0.554 ( 0.554)	Loss 4.8255e-01 (8.9091e-01)	Acc@1 31.250000 (31.018518)
Epoch: [23][ 96/591]	Time  0.593 ( 0.646)	Data  0.495 ( 0.548)	Loss 1.0713e+00 (9.0385e-01)	Acc@1 25.000000 (31.765463)
Epoch: [23][112/591]	Time  0.723 ( 0.644)	Data  0.625 ( 0.546)	Loss 8.1221e-01 (8.9710e-01)	Acc@1 31.250000 (31.803097)
Epoch: [23][128/591]	Time  0.589 ( 0.641)	Data  0.491 ( 0.543)	Loss 1.1360e+00 (8.9238e-01)	Acc@1 12.500000 (31.637596)
Epoch: [23][144/591]	Time  0.638 ( 0.640)	Data  0.541 ( 0.542)	Loss 9.5232e-01 (8.8998e-01)	Acc@1 25.000000 (31.206896)
Epoch: [23][160/591]	Time  0.597 ( 0.641)	Data  0.500 ( 0.543)	Loss 7.9449e-01 (8.8569e-01)	Acc@1 43.750000 (31.327641)
Epoch: [23][176/591]	Time  0.684 ( 0.650)	Data  0.587 ( 0.552)	Loss 1.0557e+00 (8.8326e-01)	Acc@1 31.250000 (31.426554)
Epoch: [23][192/591]	Time  0.645 ( 0.651)	Data  0.548 ( 0.553)	Loss 9.4964e-01 (8.8256e-01)	Acc@1 25.000000 (31.347149)
Epoch: [23][208/591]	Time  0.618 ( 0.650)	Data  0.520 ( 0.552)	Loss 7.6759e-01 (8.8600e-01)	Acc@1 25.000000 (31.309807)
Epoch: [23][224/591]	Time  0.557 ( 0.651)	Data  0.459 ( 0.553)	Loss 7.9632e-01 (8.8048e-01)	Acc@1 31.250000 (31.277779)
Epoch: [23][240/591]	Time  0.639 ( 0.650)	Data  0.540 ( 0.551)	Loss 1.0999e+00 (8.7973e-01)	Acc@1 25.000000 (31.457470)
Epoch: [23][256/591]	Time  0.624 ( 0.653)	Data  0.526 ( 0.555)	Loss 7.1409e-01 (8.8114e-01)	Acc@1 37.500000 (31.347277)
Epoch: [23][272/591]	Time  0.683 ( 0.652)	Data  0.585 ( 0.553)	Loss 8.1323e-01 (8.7992e-01)	Acc@1 12.500000 (31.272894)
Epoch: [23][288/591]	Time  1.171 ( 0.653)	Data  1.073 ( 0.555)	Loss 8.9652e-01 (8.8119e-01)	Acc@1 12.500000 (30.903980)
Epoch: [23][304/591]	Time  0.662 ( 0.653)	Data  0.565 ( 0.555)	Loss 7.6919e-01 (8.8116e-01)	Acc@1 37.500000 (31.086065)
Epoch: [23][320/591]	Time  0.619 ( 0.653)	Data  0.521 ( 0.555)	Loss 1.1491e+00 (8.8359e-01)	Acc@1 6.250000 (30.938473)
Epoch: [23][336/591]	Time  0.662 ( 0.655)	Data  0.565 ( 0.556)	Loss 1.1970e+00 (8.8243e-01)	Acc@1 31.250000 (31.212908)
Epoch: [23][352/591]	Time  0.673 ( 0.657)	Data  0.576 ( 0.559)	Loss 1.0649e+00 (8.8238e-01)	Acc@1 31.250000 (31.320822)
Epoch: [23][368/591]	Time  0.600 ( 0.657)	Data  0.502 ( 0.559)	Loss 1.0378e+00 (8.8257e-01)	Acc@1 31.250000 (31.385502)
Epoch: [23][384/591]	Time  0.725 ( 0.657)	Data  0.626 ( 0.558)	Loss 7.5108e-01 (8.8071e-01)	Acc@1 50.000000 (31.347403)
Epoch: [23][400/591]	Time  0.613 ( 0.656)	Data  0.514 ( 0.557)	Loss 7.0439e-01 (8.8005e-01)	Acc@1 43.750000 (31.359104)
Epoch: [23][416/591]	Time  0.606 ( 0.654)	Data  0.508 ( 0.556)	Loss 8.2915e-01 (8.8312e-01)	Acc@1 31.250000 (31.264988)
Epoch: [23][432/591]	Time  0.686 ( 0.655)	Data  0.572 ( 0.557)	Loss 7.8472e-01 (8.8478e-01)	Acc@1 31.250000 (31.062355)
Epoch: [23][448/591]	Time  0.619 ( 0.657)	Data  0.522 ( 0.559)	Loss 7.8142e-01 (8.8336e-01)	Acc@1 25.000000 (31.055124)
Epoch: [23][464/591]	Time  0.642 ( 0.657)	Data  0.544 ( 0.558)	Loss 7.1049e-01 (8.8222e-01)	Acc@1 12.500000 (31.129032)
Epoch: [23][480/591]	Time  0.614 ( 0.656)	Data  0.517 ( 0.558)	Loss 9.4950e-01 (8.8226e-01)	Acc@1 43.750000 (31.159044)
Epoch: [23][496/591]	Time  0.636 ( 0.655)	Data  0.538 ( 0.557)	Loss 9.9518e-01 (8.8127e-01)	Acc@1 6.250000 (31.061367)
Epoch: [23][512/591]	Time  0.658 ( 0.654)	Data  0.559 ( 0.556)	Loss 7.4723e-01 (8.8033e-01)	Acc@1 18.750000 (31.298733)
Epoch: [23][528/591]	Time  0.780 ( 0.656)	Data  0.682 ( 0.558)	Loss 8.0544e-01 (8.8116e-01)	Acc@1 31.250000 (31.214556)
Epoch: [23][544/591]	Time  0.659 ( 0.656)	Data  0.560 ( 0.558)	Loss 8.7268e-01 (8.8402e-01)	Acc@1 25.000000 (31.158257)
Epoch: [23][560/591]	Time  0.688 ( 0.656)	Data  0.590 ( 0.558)	Loss 8.2529e-01 (8.8428e-01)	Acc@1 50.000000 (31.205437)
Epoch: [23][576/591]	Time  0.611 ( 0.656)	Data  0.513 ( 0.558)	Loss 8.8575e-01 (8.8371e-01)	Acc@1 31.250000 (31.185009)
##################################################
train_loss:  0.8853265476206635
train_acc:  tensor(31.1654, device='cuda:0')
##################################################
Best model was saved.
Epoch: [24][  0/591]	Time  0.667 ( 0.667)	Data  0.569 ( 0.569)	Loss 5.9378e-01 (5.9378e-01)	Acc@1 31.250000 (31.250000)
Epoch: [24][ 16/591]	Time  0.589 ( 0.650)	Data  0.491 ( 0.551)	Loss 7.7788e-01 (8.2278e-01)	Acc@1 56.250000 (34.191177)
Epoch: [24][ 32/591]	Time  0.667 ( 0.675)	Data  0.569 ( 0.576)	Loss 7.8681e-01 (8.4981e-01)	Acc@1 31.250000 (34.659092)
Epoch: [24][ 48/591]	Time  0.699 ( 0.671)	Data  0.601 ( 0.573)	Loss 9.5319e-01 (8.6488e-01)	Acc@1 25.000000 (32.908161)
Epoch: [24][ 64/591]	Time  0.586 ( 0.665)	Data  0.486 ( 0.566)	Loss 1.1068e+00 (8.8267e-01)	Acc@1 43.750000 (31.923077)
Epoch: [24][ 80/591]	Time  0.652 ( 0.666)	Data  0.553 ( 0.567)	Loss 8.9729e-01 (8.6909e-01)	Acc@1 37.500000 (31.481482)
Epoch: [24][ 96/591]	Time  0.623 ( 0.657)	Data  0.525 ( 0.559)	Loss 7.9839e-01 (8.6336e-01)	Acc@1 43.750000 (31.378864)
Epoch: [24][112/591]	Time  0.611 ( 0.659)	Data  0.513 ( 0.561)	Loss 9.9371e-01 (8.7050e-01)	Acc@1 37.500000 (31.305309)
Epoch: [24][128/591]	Time  0.597 ( 0.665)	Data  0.500 ( 0.567)	Loss 9.5832e-01 (8.7301e-01)	Acc@1 25.000000 (31.104650)
Epoch: [24][144/591]	Time  0.631 ( 0.664)	Data  0.533 ( 0.566)	Loss 8.2184e-01 (8.7308e-01)	Acc@1 31.250000 (31.293104)
Epoch: [24][160/591]	Time  0.604 ( 0.665)	Data  0.506 ( 0.567)	Loss 1.0290e+00 (8.7238e-01)	Acc@1 25.000000 (31.405279)
Epoch: [24][176/591]	Time  0.658 ( 0.660)	Data  0.560 ( 0.562)	Loss 1.0092e+00 (8.7293e-01)	Acc@1 37.500000 (31.426554)
Epoch: [24][192/591]	Time  0.589 ( 0.659)	Data  0.491 ( 0.561)	Loss 8.2769e-01 (8.7246e-01)	Acc@1 37.500000 (31.573833)
Epoch: [24][208/591]	Time  0.590 ( 0.663)	Data  0.492 ( 0.565)	Loss 8.6446e-01 (8.7256e-01)	Acc@1 25.000000 (31.698563)
Epoch: [24][224/591]	Time  0.709 ( 0.662)	Data  0.611 ( 0.564)	Loss 1.1021e+00 (8.7545e-01)	Acc@1 12.500000 (31.583334)
Epoch: [24][240/591]	Time  0.635 ( 0.661)	Data  0.538 ( 0.563)	Loss 6.2220e-01 (8.7667e-01)	Acc@1 31.250000 (31.794607)
Epoch: [24][256/591]	Time  0.879 ( 0.662)	Data  0.780 ( 0.564)	Loss 7.7507e-01 (8.7211e-01)	Acc@1 18.750000 (31.906614)
Epoch: [24][272/591]	Time  0.647 ( 0.663)	Data  0.550 ( 0.565)	Loss 6.3396e-01 (8.7087e-01)	Acc@1 25.000000 (31.776556)
Epoch: [24][288/591]	Time  0.737 ( 0.662)	Data  0.639 ( 0.563)	Loss 8.8239e-01 (8.7117e-01)	Acc@1 12.500000 (32.071800)
Epoch: [24][304/591]	Time  0.668 ( 0.664)	Data  0.570 ( 0.566)	Loss 7.0737e-01 (8.7062e-01)	Acc@1 25.000000 (32.172131)
Epoch: [24][320/591]	Time  0.646 ( 0.662)	Data  0.548 ( 0.564)	Loss 9.9528e-01 (8.6901e-01)	Acc@1 31.250000 (32.223518)
Epoch: [24][336/591]	Time  0.680 ( 0.662)	Data  0.582 ( 0.563)	Loss 1.0311e+00 (8.7004e-01)	Acc@1 37.500000 (32.325668)
Epoch: [24][352/591]	Time  0.625 ( 0.660)	Data  0.527 ( 0.562)	Loss 7.2979e-01 (8.6605e-01)	Acc@1 25.000000 (32.294617)
Epoch: [24][368/591]	Time  0.610 ( 0.659)	Data  0.513 ( 0.561)	Loss 1.0898e+00 (8.6963e-01)	Acc@1 31.250000 (32.317074)
Epoch: [24][384/591]	Time  0.580 ( 0.659)	Data  0.483 ( 0.561)	Loss 7.3695e-01 (8.7033e-01)	Acc@1 50.000000 (32.451298)
Epoch: [24][400/591]	Time  0.606 ( 0.661)	Data  0.508 ( 0.563)	Loss 9.4408e-01 (8.7172e-01)	Acc@1 37.500000 (32.512470)
Epoch: [24][416/591]	Time  0.633 ( 0.659)	Data  0.536 ( 0.561)	Loss 8.1391e-01 (8.7220e-01)	Acc@1 31.250000 (32.673862)
Epoch: [24][432/591]	Time  0.603 ( 0.658)	Data  0.505 ( 0.560)	Loss 7.9672e-01 (8.7195e-01)	Acc@1 31.250000 (32.577946)
Epoch: [24][448/591]	Time  0.671 ( 0.658)	Data  0.574 ( 0.559)	Loss 9.8282e-01 (8.7041e-01)	Acc@1 43.750000 (32.683743)
Epoch: [24][464/591]	Time  0.626 ( 0.657)	Data  0.528 ( 0.558)	Loss 7.9678e-01 (8.7081e-01)	Acc@1 12.500000 (32.459679)
Epoch: [24][480/591]	Time  0.948 ( 0.658)	Data  0.845 ( 0.560)	Loss 1.0374e+00 (8.7149e-01)	Acc@1 50.000000 (32.575363)
Epoch: [24][496/591]	Time  0.581 ( 0.659)	Data  0.483 ( 0.560)	Loss 8.1614e-01 (8.7075e-01)	Acc@1 37.500000 (32.444668)
Epoch: [24][512/591]	Time  0.641 ( 0.658)	Data  0.543 ( 0.559)	Loss 9.8066e-01 (8.7186e-01)	Acc@1 37.500000 (32.407406)
Epoch: [24][528/591]	Time  0.678 ( 0.657)	Data  0.581 ( 0.559)	Loss 8.4240e-01 (8.7217e-01)	Acc@1 12.500000 (32.620510)
Epoch: [24][544/591]	Time  0.696 ( 0.657)	Data  0.590 ( 0.558)	Loss 6.6804e-01 (8.7285e-01)	Acc@1 18.750000 (32.350918)
Epoch: [24][560/591]	Time  0.653 ( 0.657)	Data  0.555 ( 0.559)	Loss 1.1383e+00 (8.7387e-01)	Acc@1 25.000000 (32.252674)
Epoch: [24][576/591]	Time  0.656 ( 0.659)	Data  0.559 ( 0.560)	Loss 7.2424e-01 (8.7364e-01)	Acc@1 43.750000 (32.289860)
##################################################
train_loss:  0.8730159761941978
train_acc:  tensor(32.3604, device='cuda:0')
##################################################
Best model was saved.
Milestone 25 model was saved.
Epoch: [25][  0/591]	Time  0.811 ( 0.811)	Data  0.713 ( 0.713)	Loss 8.7888e-01 (8.7888e-01)	Acc@1 25.000000 (25.000000)
Epoch: [25][ 16/591]	Time  0.599 ( 0.648)	Data  0.502 ( 0.550)	Loss 1.0530e+00 (8.6585e-01)	Acc@1 18.750000 (33.455883)
Epoch: [25][ 32/591]	Time  0.677 ( 0.641)	Data  0.580 ( 0.543)	Loss 9.2183e-01 (8.8634e-01)	Acc@1 37.500000 (30.113638)
Epoch: [25][ 48/591]	Time  0.653 ( 0.641)	Data  0.555 ( 0.543)	Loss 1.0134e+00 (8.8439e-01)	Acc@1 18.750000 (31.887754)
Epoch: [25][ 64/591]	Time  0.711 ( 0.639)	Data  0.614 ( 0.541)	Loss 1.0270e+00 (8.8246e-01)	Acc@1 31.250000 (31.634615)
Epoch: [25][ 80/591]	Time  0.621 ( 0.650)	Data  0.523 ( 0.552)	Loss 7.0504e-01 (8.7803e-01)	Acc@1 37.500000 (31.867285)
Epoch: [25][ 96/591]	Time  0.652 ( 0.651)	Data  0.555 ( 0.553)	Loss 6.2453e-01 (8.6851e-01)	Acc@1 37.500000 (32.409794)
Epoch: [25][112/591]	Time  0.644 ( 0.653)	Data  0.545 ( 0.555)	Loss 9.3452e-01 (8.7274e-01)	Acc@1 37.500000 (32.024338)
Epoch: [25][128/591]	Time  0.563 ( 0.650)	Data  0.466 ( 0.552)	Loss 7.4019e-01 (8.7079e-01)	Acc@1 43.750000 (31.589148)
Epoch: [25][144/591]	Time  0.648 ( 0.648)	Data  0.550 ( 0.550)	Loss 6.3855e-01 (8.6265e-01)	Acc@1 37.500000 (31.551723)
Epoch: [25][160/591]	Time  0.916 ( 0.653)	Data  0.812 ( 0.555)	Loss 7.8958e-01 (8.6437e-01)	Acc@1 43.750000 (31.754660)
Epoch: [25][176/591]	Time  0.559 ( 0.655)	Data  0.462 ( 0.556)	Loss 9.0785e-01 (8.6111e-01)	Acc@1 12.500000 (31.744350)
Epoch: [25][192/591]	Time  0.616 ( 0.653)	Data  0.518 ( 0.555)	Loss 7.8402e-01 (8.5784e-01)	Acc@1 37.500000 (31.800518)
Epoch: [25][208/591]	Time  0.604 ( 0.651)	Data  0.507 ( 0.553)	Loss 9.0629e-01 (8.6177e-01)	Acc@1 31.250000 (31.788277)
Epoch: [25][224/591]	Time  0.692 ( 0.651)	Data  0.593 ( 0.553)	Loss 6.5037e-01 (8.6323e-01)	Acc@1 37.500000 (31.805557)
Epoch: [25][240/591]	Time  0.634 ( 0.652)	Data  0.537 ( 0.554)	Loss 9.4992e-01 (8.6549e-01)	Acc@1 43.750000 (32.339214)
Epoch: [25][256/591]	Time  0.648 ( 0.656)	Data  0.550 ( 0.558)	Loss 9.2573e-01 (8.7111e-01)	Acc@1 25.000000 (32.222763)
Epoch: [25][272/591]	Time  0.622 ( 0.655)	Data  0.524 ( 0.557)	Loss 1.0048e+00 (8.7069e-01)	Acc@1 25.000000 (32.165752)
Epoch: [25][288/591]	Time  0.637 ( 0.654)	Data  0.539 ( 0.555)	Loss 6.4045e-01 (8.7390e-01)	Acc@1 6.250000 (32.071800)
Epoch: [25][304/591]	Time  0.653 ( 0.653)	Data  0.555 ( 0.555)	Loss 9.0505e-01 (8.7242e-01)	Acc@1 31.250000 (32.418034)
Epoch: [25][320/591]	Time  0.613 ( 0.653)	Data  0.514 ( 0.555)	Loss 1.0103e+00 (8.7053e-01)	Acc@1 25.000000 (32.398754)
Epoch: [25][336/591]	Time  0.606 ( 0.653)	Data  0.505 ( 0.555)	Loss 5.5798e-01 (8.7128e-01)	Acc@1 37.500000 (32.418396)
Epoch: [25][352/591]	Time  0.606 ( 0.656)	Data  0.509 ( 0.558)	Loss 8.0776e-01 (8.7135e-01)	Acc@1 18.750000 (32.276913)
Epoch: [25][368/591]	Time  0.618 ( 0.655)	Data  0.521 ( 0.557)	Loss 6.7701e-01 (8.7059e-01)	Acc@1 18.750000 (32.283199)
Epoch: [25][384/591]	Time  0.635 ( 0.655)	Data  0.538 ( 0.557)	Loss 9.7296e-01 (8.7112e-01)	Acc@1 31.250000 (32.272728)
Epoch: [25][400/591]	Time  0.607 ( 0.654)	Data  0.509 ( 0.556)	Loss 9.0807e-01 (8.6886e-01)	Acc@1 18.750000 (32.309853)
Epoch: [25][416/591]	Time  0.648 ( 0.653)	Data  0.550 ( 0.554)	Loss 1.1043e+00 (8.6794e-01)	Acc@1 37.500000 (32.508995)
Epoch: [25][432/591]	Time  0.653 ( 0.653)	Data  0.555 ( 0.555)	Loss 6.6246e-01 (8.6771e-01)	Acc@1 18.750000 (32.433601)
Epoch: [25][448/591]	Time  0.623 ( 0.656)	Data  0.526 ( 0.558)	Loss 9.6719e-01 (8.6599e-01)	Acc@1 43.750000 (32.461025)
Epoch: [25][464/591]	Time  0.593 ( 0.656)	Data  0.495 ( 0.558)	Loss 9.4572e-01 (8.6498e-01)	Acc@1 37.500000 (32.647850)
Epoch: [25][480/591]	Time  0.580 ( 0.657)	Data  0.483 ( 0.558)	Loss 1.0102e+00 (8.6394e-01)	Acc@1 31.250000 (32.549377)
Epoch: [25][496/591]	Time  0.613 ( 0.657)	Data  0.516 ( 0.559)	Loss 1.1179e+00 (8.6213e-01)	Acc@1 18.750000 (32.256035)
Epoch: [25][512/591]	Time  0.615 ( 0.656)	Data  0.517 ( 0.558)	Loss 8.6727e-01 (8.6322e-01)	Acc@1 6.250000 (32.261208)
Epoch: [25][528/591]	Time  0.619 ( 0.658)	Data  0.521 ( 0.560)	Loss 8.6500e-01 (8.6474e-01)	Acc@1 31.250000 (32.218811)
Epoch: [25][544/591]	Time  0.625 ( 0.658)	Data  0.527 ( 0.559)	Loss 1.0218e+00 (8.6456e-01)	Acc@1 37.500000 (32.259174)
Epoch: [25][560/591]	Time  0.641 ( 0.658)	Data  0.543 ( 0.560)	Loss 6.5247e-01 (8.6373e-01)	Acc@1 50.000000 (32.163548)
Epoch: [25][576/591]	Time  0.635 ( 0.658)	Data  0.538 ( 0.560)	Loss 1.0204e+00 (8.6407e-01)	Acc@1 18.750000 (32.159878)
##################################################
train_loss:  0.8633895606155525
train_acc:  tensor(32.1489, device='cuda:0')
##################################################
Best model was saved.
Epoch: [26][  0/591]	Time  0.639 ( 0.639)	Data  0.542 ( 0.542)	Loss 8.3157e-01 (8.3157e-01)	Acc@1 6.250000 (6.250000)
Epoch: [26][ 16/591]	Time  0.627 ( 0.627)	Data  0.529 ( 0.529)	Loss 9.7160e-01 (8.5059e-01)	Acc@1 43.750000 (33.088234)
Epoch: [26][ 32/591]	Time  0.635 ( 0.662)	Data  0.538 ( 0.563)	Loss 7.6345e-01 (8.7580e-01)	Acc@1 25.000000 (32.386364)
Epoch: [26][ 48/591]	Time  0.642 ( 0.654)	Data  0.545 ( 0.555)	Loss 1.0560e+00 (8.7711e-01)	Acc@1 37.500000 (33.035713)
Epoch: [26][ 64/591]	Time  0.598 ( 0.656)	Data  0.500 ( 0.557)	Loss 1.0192e+00 (8.7248e-01)	Acc@1 31.250000 (32.115383)
Epoch: [26][ 80/591]	Time  0.639 ( 0.653)	Data  0.541 ( 0.554)	Loss 1.0346e+00 (8.5020e-01)	Acc@1 25.000000 (32.561729)
Epoch: [26][ 96/591]	Time  0.684 ( 0.651)	Data  0.585 ( 0.553)	Loss 9.1907e-01 (8.5191e-01)	Acc@1 25.000000 (31.958761)
Epoch: [26][112/591]	Time  0.671 ( 0.650)	Data  0.566 ( 0.552)	Loss 8.3386e-01 (8.5579e-01)	Acc@1 37.500000 (32.466812)
Epoch: [26][128/591]	Time  0.616 ( 0.658)	Data  0.519 ( 0.559)	Loss 5.0589e-01 (8.5329e-01)	Acc@1 31.250000 (32.558140)
Epoch: [26][144/591]	Time  0.587 ( 0.655)	Data  0.490 ( 0.557)	Loss 1.1230e+00 (8.5237e-01)	Acc@1 50.000000 (32.715519)
Epoch: [26][160/591]	Time  0.597 ( 0.653)	Data  0.500 ( 0.555)	Loss 9.0819e-01 (8.5318e-01)	Acc@1 12.500000 (32.336956)
Epoch: [26][176/591]	Time  0.605 ( 0.654)	Data  0.507 ( 0.555)	Loss 8.7443e-01 (8.5277e-01)	Acc@1 31.250000 (32.662430)
Epoch: [26][192/591]	Time  0.667 ( 0.653)	Data  0.569 ( 0.555)	Loss 8.7858e-01 (8.5299e-01)	Acc@1 37.500000 (32.545338)
Epoch: [26][208/591]	Time  0.782 ( 0.655)	Data  0.685 ( 0.557)	Loss 9.7519e-01 (8.5967e-01)	Acc@1 12.500000 (32.595692)
Epoch: [26][224/591]	Time  0.542 ( 0.655)	Data  0.445 ( 0.557)	Loss 8.8215e-01 (8.6144e-01)	Acc@1 25.000000 (32.500000)
Epoch: [26][240/591]	Time  0.607 ( 0.655)	Data  0.509 ( 0.557)	Loss 8.4794e-01 (8.5645e-01)	Acc@1 25.000000 (32.961620)
Epoch: [26][256/591]	Time  0.619 ( 0.654)	Data  0.521 ( 0.556)	Loss 8.0561e-01 (8.5481e-01)	Acc@1 18.750000 (32.952335)
Epoch: [26][272/591]	Time  0.627 ( 0.653)	Data  0.529 ( 0.554)	Loss 7.7277e-01 (8.5153e-01)	Acc@1 43.750000 (33.012821)
Epoch: [26][288/591]	Time  0.604 ( 0.653)	Data  0.507 ( 0.555)	Loss 9.5794e-01 (8.5250e-01)	Acc@1 25.000000 (33.023357)
Epoch: [26][304/591]	Time  0.591 ( 0.655)	Data  0.493 ( 0.557)	Loss 5.9230e-01 (8.5354e-01)	Acc@1 31.250000 (33.073769)
Epoch: [26][320/591]	Time  0.585 ( 0.655)	Data  0.487 ( 0.557)	Loss 8.7597e-01 (8.5585e-01)	Acc@1 12.500000 (33.119160)
Epoch: [26][336/591]	Time  0.704 ( 0.655)	Data  0.606 ( 0.557)	Loss 6.7916e-01 (8.5580e-01)	Acc@1 12.500000 (33.067509)
Epoch: [26][352/591]	Time  0.615 ( 0.654)	Data  0.517 ( 0.556)	Loss 9.8368e-01 (8.5888e-01)	Acc@1 31.250000 (32.949715)
Epoch: [26][368/591]	Time  0.622 ( 0.654)	Data  0.524 ( 0.556)	Loss 5.3753e-01 (8.5823e-01)	Acc@1 18.750000 (32.791328)
Epoch: [26][384/591]	Time  0.611 ( 0.653)	Data  0.513 ( 0.555)	Loss 8.2186e-01 (8.5901e-01)	Acc@1 31.250000 (32.775974)
Epoch: [26][400/591]	Time  0.685 ( 0.656)	Data  0.587 ( 0.558)	Loss 1.0072e+00 (8.5682e-01)	Acc@1 37.500000 (32.824192)
Epoch: [26][416/591]	Time  0.586 ( 0.656)	Data  0.488 ( 0.558)	Loss 7.9120e-01 (8.5844e-01)	Acc@1 25.000000 (32.928658)
Epoch: [26][432/591]	Time  0.627 ( 0.656)	Data  0.530 ( 0.557)	Loss 8.1038e-01 (8.5707e-01)	Acc@1 37.500000 (32.881062)
Epoch: [26][448/591]	Time  0.600 ( 0.655)	Data  0.502 ( 0.556)	Loss 9.6014e-01 (8.5919e-01)	Acc@1 18.750000 (32.836861)
Epoch: [26][464/591]	Time  0.656 ( 0.656)	Data  0.558 ( 0.558)	Loss 8.7935e-01 (8.6015e-01)	Acc@1 31.250000 (32.782257)
Epoch: [26][480/591]	Time  1.168 ( 0.658)	Data  1.047 ( 0.560)	Loss 8.0501e-01 (8.5856e-01)	Acc@1 18.750000 (32.666321)
Epoch: [26][496/591]	Time  0.604 ( 0.658)	Data  0.506 ( 0.560)	Loss 8.1693e-01 (8.5921e-01)	Acc@1 25.000000 (32.620724)
Epoch: [26][512/591]	Time  0.591 ( 0.658)	Data  0.493 ( 0.560)	Loss 8.6751e-01 (8.5844e-01)	Acc@1 62.500000 (32.711990)
Epoch: [26][528/591]	Time  0.602 ( 0.658)	Data  0.504 ( 0.559)	Loss 8.3027e-01 (8.5741e-01)	Acc@1 62.500000 (32.833176)
Epoch: [26][544/591]	Time  0.641 ( 0.658)	Data  0.542 ( 0.559)	Loss 7.5977e-01 (8.5712e-01)	Acc@1 25.000000 (32.740826)
Epoch: [26][560/591]	Time  0.627 ( 0.658)	Data  0.530 ( 0.560)	Loss 6.8752e-01 (8.5841e-01)	Acc@1 31.250000 (32.765152)
Epoch: [26][576/591]	Time  0.845 ( 0.660)	Data  0.747 ( 0.562)	Loss 1.1405e+00 (8.6059e-01)	Acc@1 31.250000 (32.690639)
##################################################
train_loss:  0.8597540010252176
train_acc:  tensor(32.6036, device='cuda:0')
##################################################
Best model was saved.
Epoch: [27][  0/591]	Time  0.632 ( 0.632)	Data  0.534 ( 0.534)	Loss 6.6527e-01 (6.6527e-01)	Acc@1 37.500000 (37.500000)
Epoch: [27][ 16/591]	Time  0.618 ( 0.632)	Data  0.520 ( 0.534)	Loss 6.8740e-01 (8.5592e-01)	Acc@1 25.000000 (30.882353)
Epoch: [27][ 32/591]	Time  0.596 ( 0.630)	Data  0.498 ( 0.532)	Loss 7.5987e-01 (8.8278e-01)	Acc@1 43.750000 (30.303032)
Epoch: [27][ 48/591]	Time  0.760 ( 0.642)	Data  0.662 ( 0.544)	Loss 8.5820e-01 (8.8122e-01)	Acc@1 25.000000 (29.719387)
Epoch: [27][ 64/591]	Time  0.947 ( 0.652)	Data  0.841 ( 0.554)	Loss 1.1311e+00 (8.6948e-01)	Acc@1 18.750000 (31.442308)
Epoch: [27][ 80/591]	Time  0.599 ( 0.665)	Data  0.502 ( 0.567)	Loss 9.4658e-01 (8.6564e-01)	Acc@1 25.000000 (31.867285)
Epoch: [27][ 96/591]	Time  0.752 ( 0.662)	Data  0.654 ( 0.564)	Loss 7.5544e-01 (8.5600e-01)	Acc@1 37.500000 (32.345360)
Epoch: [27][112/591]	Time  0.666 ( 0.659)	Data  0.568 ( 0.561)	Loss 8.2282e-01 (8.6026e-01)	Acc@1 43.750000 (32.079647)
Epoch: [27][128/591]	Time  0.587 ( 0.655)	Data  0.489 ( 0.557)	Loss 5.4315e-01 (8.5662e-01)	Acc@1 25.000000 (31.734495)
Epoch: [27][144/591]	Time  0.613 ( 0.654)	Data  0.515 ( 0.556)	Loss 8.1700e-01 (8.5837e-01)	Acc@1 31.250000 (31.767241)
Epoch: [27][160/591]	Time  0.625 ( 0.660)	Data  0.527 ( 0.562)	Loss 9.5615e-01 (8.5857e-01)	Acc@1 12.500000 (31.599379)
Epoch: [27][176/591]	Time  0.584 ( 0.657)	Data  0.486 ( 0.559)	Loss 1.0619e+00 (8.6267e-01)	Acc@1 31.250000 (31.744350)
Epoch: [27][192/591]	Time  0.739 ( 0.656)	Data  0.641 ( 0.558)	Loss 6.9399e-01 (8.6192e-01)	Acc@1 18.750000 (31.930052)
Epoch: [27][208/591]	Time  0.627 ( 0.658)	Data  0.529 ( 0.559)	Loss 1.0445e+00 (8.6387e-01)	Acc@1 25.000000 (31.788277)
Epoch: [27][224/591]	Time  0.613 ( 0.656)	Data  0.515 ( 0.558)	Loss 8.6072e-01 (8.6091e-01)	Acc@1 37.500000 (31.972223)
Epoch: [27][240/591]	Time  0.593 ( 0.655)	Data  0.496 ( 0.557)	Loss 7.8493e-01 (8.6176e-01)	Acc@1 12.500000 (31.898342)
Epoch: [27][256/591]	Time  0.609 ( 0.658)	Data  0.511 ( 0.560)	Loss 7.4085e-01 (8.6071e-01)	Acc@1 62.500000 (31.882296)
Epoch: [27][272/591]	Time  0.623 ( 0.658)	Data  0.525 ( 0.560)	Loss 7.1371e-01 (8.6227e-01)	Acc@1 56.250000 (31.868132)
Epoch: [27][288/591]	Time  0.635 ( 0.660)	Data  0.537 ( 0.561)	Loss 9.7207e-01 (8.6251e-01)	Acc@1 18.750000 (31.833912)
Epoch: [27][304/591]	Time  0.646 ( 0.658)	Data  0.548 ( 0.560)	Loss 9.6072e-01 (8.6395e-01)	Acc@1 37.500000 (31.823771)
Epoch: [27][320/591]	Time  0.691 ( 0.657)	Data  0.594 ( 0.559)	Loss 9.4999e-01 (8.6625e-01)	Acc@1 31.250000 (31.561525)
Epoch: [27][336/591]	Time  0.638 ( 0.656)	Data  0.541 ( 0.558)	Loss 8.0390e-01 (8.6433e-01)	Acc@1 31.250000 (31.620920)
Epoch: [27][352/591]	Time  0.634 ( 0.657)	Data  0.537 ( 0.559)	Loss 8.6414e-01 (8.6172e-01)	Acc@1 31.250000 (31.781160)
Epoch: [27][368/591]	Time  0.606 ( 0.657)	Data  0.508 ( 0.559)	Loss 6.0927e-01 (8.6185e-01)	Acc@1 37.500000 (31.775068)
Epoch: [27][384/591]	Time  0.782 ( 0.657)	Data  0.684 ( 0.559)	Loss 7.6241e-01 (8.6161e-01)	Acc@1 43.750000 (31.834415)
Epoch: [27][400/591]	Time  0.611 ( 0.656)	Data  0.514 ( 0.558)	Loss 9.1633e-01 (8.6321e-01)	Acc@1 25.000000 (31.811098)
Epoch: [27][416/591]	Time  0.683 ( 0.656)	Data  0.585 ( 0.558)	Loss 5.1117e-01 (8.6279e-01)	Acc@1 43.750000 (31.879498)
Epoch: [27][432/591]	Time  0.863 ( 0.657)	Data  0.765 ( 0.559)	Loss 1.0752e+00 (8.6239e-01)	Acc@1 12.500000 (32.029446)
Epoch: [27][448/591]	Time  0.860 ( 0.658)	Data  0.762 ( 0.560)	Loss 1.2016e+00 (8.6038e-01)	Acc@1 37.500000 (32.140869)
Epoch: [27][464/591]	Time  0.620 ( 0.657)	Data  0.521 ( 0.559)	Loss 7.0572e-01 (8.5993e-01)	Acc@1 31.250000 (32.056454)
Epoch: [27][480/591]	Time  0.707 ( 0.657)	Data  0.609 ( 0.559)	Loss 8.2126e-01 (8.5920e-01)	Acc@1 37.500000 (32.211540)
Epoch: [27][496/591]	Time  0.648 ( 0.657)	Data  0.551 ( 0.559)	Loss 1.0738e+00 (8.5913e-01)	Acc@1 18.750000 (32.256035)
Epoch: [27][512/591]	Time  0.637 ( 0.658)	Data  0.538 ( 0.560)	Loss 8.3155e-01 (8.5912e-01)	Acc@1 37.500000 (32.200294)
Epoch: [27][528/591]	Time  0.656 ( 0.659)	Data  0.559 ( 0.561)	Loss 7.4859e-01 (8.5825e-01)	Acc@1 50.000000 (32.277885)
Epoch: [27][544/591]	Time  0.608 ( 0.659)	Data  0.510 ( 0.561)	Loss 8.8883e-01 (8.5866e-01)	Acc@1 43.750000 (32.201836)
Epoch: [27][560/591]	Time  0.608 ( 0.657)	Data  0.511 ( 0.559)	Loss 6.1260e-01 (8.5722e-01)	Acc@1 43.750000 (32.263813)
Epoch: [27][576/591]	Time  0.587 ( 0.658)	Data  0.490 ( 0.560)	Loss 6.1051e-01 (8.5832e-01)	Acc@1 43.750000 (32.430676)
##################################################
train_loss:  0.8567323147645457
train_acc:  tensor(32.5508, device='cuda:0')
##################################################
Best model was saved.
Epoch: [28][  0/591]	Time  0.811 ( 0.811)	Data  0.713 ( 0.713)	Loss 9.5236e-01 (9.5236e-01)	Acc@1 25.000000 (25.000000)
Epoch: [28][ 16/591]	Time  0.698 ( 0.664)	Data  0.589 ( 0.566)	Loss 1.0252e+00 (8.6238e-01)	Acc@1 31.250000 (30.882353)
Epoch: [28][ 32/591]	Time  0.662 ( 0.693)	Data  0.565 ( 0.594)	Loss 7.2376e-01 (8.6527e-01)	Acc@1 43.750000 (32.386364)
Epoch: [28][ 48/591]	Time  0.661 ( 0.679)	Data  0.564 ( 0.580)	Loss 5.9118e-01 (8.4289e-01)	Acc@1 43.750000 (30.484694)
Epoch: [28][ 64/591]	Time  0.632 ( 0.670)	Data  0.535 ( 0.572)	Loss 8.0168e-01 (8.3990e-01)	Acc@1 18.750000 (30.576923)
Epoch: [28][ 80/591]	Time  0.610 ( 0.663)	Data  0.512 ( 0.565)	Loss 6.8559e-01 (8.4429e-01)	Acc@1 43.750000 (30.709877)
Epoch: [28][ 96/591]	Time  0.875 ( 0.670)	Data  0.777 ( 0.571)	Loss 6.0591e-01 (8.4577e-01)	Acc@1 43.750000 (31.314432)
Epoch: [28][112/591]	Time  0.674 ( 0.678)	Data  0.576 ( 0.579)	Loss 9.4239e-01 (8.5174e-01)	Acc@1 56.250000 (31.913717)
Epoch: [28][128/591]	Time  0.638 ( 0.677)	Data  0.541 ( 0.578)	Loss 7.8733e-01 (8.5920e-01)	Acc@1 43.750000 (32.170544)
Epoch: [28][144/591]	Time  0.738 ( 0.674)	Data  0.640 ( 0.575)	Loss 7.3078e-01 (8.6158e-01)	Acc@1 25.000000 (32.370689)
Epoch: [28][160/591]	Time  0.691 ( 0.671)	Data  0.593 ( 0.572)	Loss 7.9526e-01 (8.5976e-01)	Acc@1 25.000000 (32.686337)
Epoch: [28][176/591]	Time  0.659 ( 0.670)	Data  0.562 ( 0.572)	Loss 6.7798e-01 (8.5378e-01)	Acc@1 18.750000 (32.591808)
Epoch: [28][192/591]	Time  0.684 ( 0.668)	Data  0.586 ( 0.570)	Loss 7.9949e-01 (8.5045e-01)	Acc@1 62.500000 (32.577721)
Epoch: [28][208/591]	Time  0.601 ( 0.671)	Data  0.504 ( 0.573)	Loss 6.5262e-01 (8.4919e-01)	Acc@1 25.000000 (32.864830)
Epoch: [28][224/591]	Time  0.625 ( 0.668)	Data  0.527 ( 0.569)	Loss 7.6275e-01 (8.4912e-01)	Acc@1 43.750000 (33.111111)
Epoch: [28][240/591]	Time  0.615 ( 0.665)	Data  0.517 ( 0.567)	Loss 8.6722e-01 (8.4938e-01)	Acc@1 25.000000 (33.117222)
Epoch: [28][256/591]	Time  0.613 ( 0.664)	Data  0.515 ( 0.566)	Loss 9.9463e-01 (8.4716e-01)	Acc@1 50.000000 (33.390079)
Epoch: [28][272/591]	Time  0.603 ( 0.662)	Data  0.506 ( 0.564)	Loss 7.5601e-01 (8.4770e-01)	Acc@1 37.500000 (33.424908)
Epoch: [28][288/591]	Time  1.055 ( 0.664)	Data  0.949 ( 0.566)	Loss 6.7744e-01 (8.4437e-01)	Acc@1 37.500000 (33.542389)
Epoch: [28][304/591]	Time  0.746 ( 0.666)	Data  0.649 ( 0.567)	Loss 7.6903e-01 (8.4425e-01)	Acc@1 18.750000 (33.524590)
Epoch: [28][320/591]	Time  0.612 ( 0.664)	Data  0.513 ( 0.565)	Loss 7.7585e-01 (8.4498e-01)	Acc@1 37.500000 (33.255451)
Epoch: [28][336/591]	Time  0.640 ( 0.662)	Data  0.540 ( 0.564)	Loss 7.2641e-01 (8.4197e-01)	Acc@1 12.500000 (33.271515)
Epoch: [28][352/591]	Time  0.650 ( 0.661)	Data  0.553 ( 0.563)	Loss 9.6368e-01 (8.4322e-01)	Acc@1 31.250000 (33.162182)
Epoch: [28][368/591]	Time  0.618 ( 0.661)	Data  0.521 ( 0.562)	Loss 6.3532e-01 (8.4190e-01)	Acc@1 43.750000 (33.384148)
Epoch: [28][384/591]	Time  0.593 ( 0.662)	Data  0.495 ( 0.564)	Loss 7.7250e-01 (8.3984e-01)	Acc@1 18.750000 (33.295452)
Epoch: [28][400/591]	Time  0.632 ( 0.662)	Data  0.534 ( 0.564)	Loss 7.7033e-01 (8.4027e-01)	Acc@1 25.000000 (33.291771)
Epoch: [28][416/591]	Time  0.630 ( 0.662)	Data  0.533 ( 0.564)	Loss 7.6561e-01 (8.4007e-01)	Acc@1 50.000000 (33.303356)
Epoch: [28][432/591]	Time  0.614 ( 0.662)	Data  0.517 ( 0.564)	Loss 9.5510e-01 (8.3952e-01)	Acc@1 50.000000 (33.487297)
Epoch: [28][448/591]	Time  0.602 ( 0.662)	Data  0.505 ( 0.564)	Loss 7.3978e-01 (8.4213e-01)	Acc@1 18.750000 (33.449333)
Epoch: [28][464/591]	Time  0.639 ( 0.661)	Data  0.541 ( 0.563)	Loss 9.7989e-01 (8.4315e-01)	Acc@1 25.000000 (33.481182)
Epoch: [28][480/591]	Time  0.852 ( 0.663)	Data  0.754 ( 0.565)	Loss 7.7922e-01 (8.4367e-01)	Acc@1 25.000000 (33.264034)
Epoch: [28][496/591]	Time  0.608 ( 0.662)	Data  0.510 ( 0.563)	Loss 8.6941e-01 (8.4322e-01)	Acc@1 31.250000 (33.186619)
Epoch: [28][512/591]	Time  0.593 ( 0.661)	Data  0.495 ( 0.563)	Loss 7.4959e-01 (8.4320e-01)	Acc@1 31.250000 (33.101852)
Epoch: [28][528/591]	Time  0.769 ( 0.661)	Data  0.672 ( 0.563)	Loss 8.8011e-01 (8.4405e-01)	Acc@1 31.250000 (33.128544)
Epoch: [28][544/591]	Time  0.654 ( 0.660)	Data  0.556 ( 0.562)	Loss 9.7555e-01 (8.4351e-01)	Acc@1 37.500000 (33.084862)
Epoch: [28][560/591]	Time  0.621 ( 0.660)	Data  0.523 ( 0.562)	Loss 8.6839e-01 (8.4436e-01)	Acc@1 31.250000 (33.065952)
Epoch: [28][576/591]	Time  0.829 ( 0.661)	Data  0.732 ( 0.563)	Loss 9.0343e-01 (8.4418e-01)	Acc@1 37.500000 (33.221405)
##################################################
train_loss:  0.8438855182196686
train_acc:  tensor(33.1430, device='cuda:0')
##################################################
Best model was saved.
Epoch: [29][  0/591]	Time  0.649 ( 0.649)	Data  0.552 ( 0.552)	Loss 8.4581e-01 (8.4581e-01)	Acc@1 25.000000 (25.000000)
Epoch: [29][ 16/591]	Time  0.929 ( 0.647)	Data  0.831 ( 0.549)	Loss 6.8631e-01 (8.2755e-01)	Acc@1 25.000000 (30.882353)
Epoch: [29][ 32/591]	Time  0.589 ( 0.640)	Data  0.492 ( 0.542)	Loss 7.3805e-01 (8.1181e-01)	Acc@1 43.750000 (30.681820)
Epoch: [29][ 48/591]	Time  0.846 ( 0.642)	Data  0.747 ( 0.544)	Loss 9.1850e-01 (8.0701e-01)	Acc@1 31.250000 (31.122448)
Epoch: [29][ 64/591]	Time  0.854 ( 0.663)	Data  0.757 ( 0.565)	Loss 8.0298e-01 (8.3008e-01)	Acc@1 37.500000 (32.211540)
Epoch: [29][ 80/591]	Time  0.632 ( 0.655)	Data  0.534 ( 0.557)	Loss 7.6641e-01 (8.2333e-01)	Acc@1 31.250000 (32.793209)
Epoch: [29][ 96/591]	Time  0.618 ( 0.659)	Data  0.520 ( 0.561)	Loss 7.6293e-01 (8.1851e-01)	Acc@1 18.750000 (32.731956)
Epoch: [29][112/591]	Time  0.803 ( 0.660)	Data  0.705 ( 0.562)	Loss 6.3309e-01 (8.1946e-01)	Acc@1 37.500000 (32.798672)
Epoch: [29][128/591]	Time  0.623 ( 0.660)	Data  0.525 ( 0.562)	Loss 9.1295e-01 (8.2170e-01)	Acc@1 18.750000 (32.364342)
Epoch: [29][144/591]	Time  0.653 ( 0.662)	Data  0.556 ( 0.564)	Loss 9.0782e-01 (8.2337e-01)	Acc@1 25.000000 (32.284481)
Epoch: [29][160/591]	Time  0.614 ( 0.667)	Data  0.516 ( 0.569)	Loss 8.6151e-01 (8.1979e-01)	Acc@1 25.000000 (32.531055)
Epoch: [29][176/591]	Time  0.613 ( 0.665)	Data  0.516 ( 0.567)	Loss 8.3442e-01 (8.2370e-01)	Acc@1 18.750000 (32.450565)
Epoch: [29][192/591]	Time  0.931 ( 0.664)	Data  0.833 ( 0.566)	Loss 9.3028e-01 (8.2518e-01)	Acc@1 31.250000 (32.480568)
Epoch: [29][208/591]	Time  0.618 ( 0.664)	Data  0.521 ( 0.566)	Loss 9.5714e-01 (8.2851e-01)	Acc@1 37.500000 (32.206936)
Epoch: [29][224/591]	Time  0.616 ( 0.664)	Data  0.518 ( 0.566)	Loss 8.6131e-01 (8.3151e-01)	Acc@1 25.000000 (32.222221)
Epoch: [29][240/591]	Time  1.294 ( 0.666)	Data  1.186 ( 0.568)	Loss 7.7315e-01 (8.3250e-01)	Acc@1 37.500000 (32.235477)
Epoch: [29][256/591]	Time  0.619 ( 0.667)	Data  0.521 ( 0.569)	Loss 7.8570e-01 (8.3021e-01)	Acc@1 18.750000 (32.490273)
Epoch: [29][272/591]	Time  0.645 ( 0.665)	Data  0.548 ( 0.567)	Loss 9.9604e-01 (8.2993e-01)	Acc@1 31.250000 (32.898354)
Epoch: [29][288/591]	Time  0.696 ( 0.663)	Data  0.597 ( 0.565)	Loss 9.1999e-01 (8.3134e-01)	Acc@1 37.500000 (32.590832)
Epoch: [29][304/591]	Time  0.673 ( 0.662)	Data  0.575 ( 0.564)	Loss 7.8384e-01 (8.3090e-01)	Acc@1 37.500000 (32.602459)
Epoch: [29][320/591]	Time  0.639 ( 0.660)	Data  0.542 ( 0.562)	Loss 1.0071e+00 (8.2952e-01)	Acc@1 37.500000 (32.671337)
Epoch: [29][336/591]	Time  0.615 ( 0.663)	Data  0.518 ( 0.564)	Loss 1.0223e+00 (8.3165e-01)	Acc@1 43.750000 (32.863503)
Epoch: [29][352/591]	Time  0.640 ( 0.662)	Data  0.542 ( 0.564)	Loss 6.1143e-01 (8.3050e-01)	Acc@1 37.500000 (32.808075)
Epoch: [29][368/591]	Time  0.619 ( 0.661)	Data  0.521 ( 0.563)	Loss 8.8504e-01 (8.3145e-01)	Acc@1 6.250000 (32.588078)
Epoch: [29][384/591]	Time  0.634 ( 0.661)	Data  0.536 ( 0.562)	Loss 8.4705e-01 (8.3378e-01)	Acc@1 25.000000 (32.532467)
Epoch: [29][400/591]	Time  0.683 ( 0.660)	Data  0.584 ( 0.562)	Loss 7.8728e-01 (8.3160e-01)	Acc@1 31.250000 (32.652744)
Epoch: [29][416/591]	Time  0.591 ( 0.658)	Data  0.494 ( 0.560)	Loss 7.6444e-01 (8.3182e-01)	Acc@1 43.750000 (32.628899)
Epoch: [29][432/591]	Time  0.685 ( 0.660)	Data  0.587 ( 0.562)	Loss 9.9463e-01 (8.3214e-01)	Acc@1 37.500000 (32.765587)
Epoch: [29][448/591]	Time  0.652 ( 0.659)	Data  0.555 ( 0.561)	Loss 9.3093e-01 (8.3205e-01)	Acc@1 6.250000 (32.809021)
Epoch: [29][464/591]	Time  0.626 ( 0.659)	Data  0.528 ( 0.561)	Loss 7.9765e-01 (8.3267e-01)	Acc@1 31.250000 (32.916668)
Epoch: [29][480/591]	Time  0.596 ( 0.660)	Data  0.498 ( 0.562)	Loss 7.6940e-01 (8.3399e-01)	Acc@1 56.250000 (32.861225)
Epoch: [29][496/591]	Time  0.673 ( 0.660)	Data  0.575 ( 0.561)	Loss 7.9907e-01 (8.3371e-01)	Acc@1 62.500000 (32.985413)
Epoch: [29][512/591]	Time  0.662 ( 0.659)	Data  0.565 ( 0.561)	Loss 7.8617e-01 (8.3182e-01)	Acc@1 18.750000 (33.016571)
Epoch: [29][528/591]	Time  0.634 ( 0.660)	Data  0.536 ( 0.562)	Loss 8.0022e-01 (8.3265e-01)	Acc@1 18.750000 (32.963139)
Epoch: [29][544/591]	Time  0.752 ( 0.661)	Data  0.655 ( 0.563)	Loss 6.6153e-01 (8.3159e-01)	Acc@1 50.000000 (33.073395)
Epoch: [29][560/591]	Time  0.601 ( 0.661)	Data  0.503 ( 0.562)	Loss 9.7819e-01 (8.3191e-01)	Acc@1 37.500000 (33.021389)
Epoch: [29][576/591]	Time  0.609 ( 0.660)	Data  0.511 ( 0.561)	Loss 6.7140e-01 (8.3178e-01)	Acc@1 31.250000 (33.004765)
##################################################
train_loss:  0.8338608919767357
train_acc:  tensor(33.2064, device='cuda:0')
##################################################
Best model was saved.
Epoch: [30][  0/591]	Time  0.635 ( 0.635)	Data  0.537 ( 0.537)	Loss 8.6714e-01 (8.6714e-01)	Acc@1 31.250000 (31.250000)
Epoch: [30][ 16/591]	Time  0.659 ( 0.695)	Data  0.561 ( 0.595)	Loss 7.5124e-01 (8.4191e-01)	Acc@1 37.500000 (30.514706)
Epoch: [30][ 32/591]	Time  0.624 ( 0.666)	Data  0.526 ( 0.567)	Loss 8.2043e-01 (8.3032e-01)	Acc@1 31.250000 (33.901516)
Epoch: [30][ 48/591]	Time  0.631 ( 0.655)	Data  0.534 ( 0.556)	Loss 7.6984e-01 (8.3782e-01)	Acc@1 62.500000 (35.076530)
Epoch: [30][ 64/591]	Time  0.738 ( 0.658)	Data  0.638 ( 0.560)	Loss 4.5535e-01 (8.3452e-01)	Acc@1 25.000000 (35.961540)
Epoch: [30][ 80/591]	Time  0.620 ( 0.676)	Data  0.519 ( 0.578)	Loss 5.8201e-01 (8.2695e-01)	Acc@1 12.500000 (36.111111)
Epoch: [30][ 96/591]	Time  0.602 ( 0.678)	Data  0.504 ( 0.580)	Loss 1.1647e+00 (8.2966e-01)	Acc@1 25.000000 (34.987114)
Epoch: [30][112/591]	Time  0.672 ( 0.691)	Data  0.575 ( 0.592)	Loss 7.6886e-01 (8.3723e-01)	Acc@1 43.750000 (34.734512)
Epoch: [30][128/591]	Time  0.669 ( 0.694)	Data  0.570 ( 0.595)	Loss 8.3553e-01 (8.3617e-01)	Acc@1 43.750000 (34.108528)
Epoch: [30][144/591]	Time  0.610 ( 0.688)	Data  0.512 ( 0.589)	Loss 8.5902e-01 (8.3989e-01)	Acc@1 31.250000 (33.836208)
Epoch: [30][160/591]	Time  0.590 ( 0.681)	Data  0.492 ( 0.582)	Loss 8.5979e-01 (8.4342e-01)	Acc@1 12.500000 (33.734474)
Epoch: [30][176/591]	Time  0.915 ( 0.680)	Data  0.817 ( 0.582)	Loss 8.2235e-01 (8.4019e-01)	Acc@1 18.750000 (33.827682)
Epoch: [30][192/591]	Time  0.646 ( 0.683)	Data  0.548 ( 0.584)	Loss 9.8888e-01 (8.4148e-01)	Acc@1 43.750000 (33.678757)
Epoch: [30][208/591]	Time  0.618 ( 0.680)	Data  0.520 ( 0.582)	Loss 8.5766e-01 (8.3600e-01)	Acc@1 31.250000 (34.061005)
Epoch: [30][224/591]	Time  0.594 ( 0.676)	Data  0.497 ( 0.577)	Loss 7.7667e-01 (8.2893e-01)	Acc@1 43.750000 (34.333336)
Epoch: [30][240/591]	Time  0.639 ( 0.676)	Data  0.541 ( 0.577)	Loss 7.8764e-01 (8.2626e-01)	Acc@1 37.500000 (34.465771)
Epoch: [30][256/591]	Time  0.587 ( 0.674)	Data  0.490 ( 0.576)	Loss 7.6944e-01 (8.2396e-01)	Acc@1 43.750000 (34.387161)
Epoch: [30][272/591]	Time  0.602 ( 0.671)	Data  0.504 ( 0.573)	Loss 9.0751e-01 (8.2612e-01)	Acc@1 56.250000 (34.340660)
Epoch: [30][288/591]	Time  0.625 ( 0.673)	Data  0.527 ( 0.574)	Loss 9.3434e-01 (8.2619e-01)	Acc@1 37.500000 (34.342560)
Epoch: [30][304/591]	Time  0.597 ( 0.671)	Data  0.499 ( 0.572)	Loss 1.1440e+00 (8.2679e-01)	Acc@1 37.500000 (34.426231)
Epoch: [30][320/591]	Time  0.621 ( 0.669)	Data  0.524 ( 0.570)	Loss 5.7931e-01 (8.2660e-01)	Acc@1 50.000000 (34.657318)
Epoch: [30][336/591]	Time  0.604 ( 0.667)	Data  0.506 ( 0.569)	Loss 1.0715e+00 (8.2717e-01)	Acc@1 25.000000 (34.810829)
Epoch: [30][352/591]	Time  0.631 ( 0.666)	Data  0.533 ( 0.568)	Loss 7.5879e-01 (8.2848e-01)	Acc@1 43.750000 (34.985836)
Epoch: [30][368/591]	Time  0.631 ( 0.666)	Data  0.529 ( 0.567)	Loss 8.5803e-01 (8.2775e-01)	Acc@1 50.000000 (34.993225)
Epoch: [30][384/591]	Time  0.610 ( 0.667)	Data  0.513 ( 0.568)	Loss 7.9826e-01 (8.2617e-01)	Acc@1 25.000000 (34.935062)
Epoch: [30][400/591]	Time  0.628 ( 0.666)	Data  0.530 ( 0.567)	Loss 6.2131e-01 (8.2645e-01)	Acc@1 31.250000 (34.788033)
Epoch: [30][416/591]	Time  0.588 ( 0.664)	Data  0.490 ( 0.565)	Loss 7.2469e-01 (8.2740e-01)	Acc@1 25.000000 (34.877098)
Epoch: [30][432/591]	Time  0.731 ( 0.664)	Data  0.633 ( 0.565)	Loss 8.2860e-01 (8.2826e-01)	Acc@1 50.000000 (34.916283)
Epoch: [30][448/591]	Time  0.600 ( 0.664)	Data  0.502 ( 0.565)	Loss 7.0483e-01 (8.2822e-01)	Acc@1 25.000000 (34.841316)
Epoch: [30][464/591]	Time  0.963 ( 0.664)	Data  0.858 ( 0.566)	Loss 7.7930e-01 (8.2898e-01)	Acc@1 31.250000 (34.583336)
Epoch: [30][480/591]	Time  0.638 ( 0.666)	Data  0.540 ( 0.567)	Loss 7.2867e-01 (8.2869e-01)	Acc@1 43.750000 (34.472454)
Epoch: [30][496/591]	Time  0.616 ( 0.665)	Data  0.518 ( 0.566)	Loss 8.4647e-01 (8.2886e-01)	Acc@1 18.750000 (34.456738)
Epoch: [30][512/591]	Time  0.628 ( 0.664)	Data  0.530 ( 0.566)	Loss 7.7017e-01 (8.2795e-01)	Acc@1 31.250000 (34.442009)
Epoch: [30][528/591]	Time  0.630 ( 0.664)	Data  0.532 ( 0.565)	Loss 7.2237e-01 (8.2740e-01)	Acc@1 6.250000 (34.380909)
Epoch: [30][544/591]	Time  0.632 ( 0.663)	Data  0.534 ( 0.564)	Loss 1.0684e+00 (8.2678e-01)	Acc@1 31.250000 (34.518349)
Epoch: [30][560/591]	Time  0.641 ( 0.665)	Data  0.543 ( 0.566)	Loss 7.7293e-01 (8.2666e-01)	Acc@1 37.500000 (34.569965)
Epoch: [30][576/591]	Time  0.620 ( 0.664)	Data  0.522 ( 0.566)	Loss 7.5051e-01 (8.2668e-01)	Acc@1 37.500000 (34.423744)
##################################################
train_loss:  0.8277046317376461
train_acc:  tensor(34.5495, device='cuda:0')
##################################################
Best model was saved.
Epoch: [31][  0/591]	Time  0.666 ( 0.666)	Data  0.568 ( 0.568)	Loss 1.0362e+00 (1.0362e+00)	Acc@1 31.250000 (31.250000)
Epoch: [31][ 16/591]	Time  0.639 ( 0.663)	Data  0.541 ( 0.565)	Loss 6.5488e-01 (8.4326e-01)	Acc@1 50.000000 (36.029411)
Epoch: [31][ 32/591]	Time  0.616 ( 0.654)	Data  0.518 ( 0.556)	Loss 8.3396e-01 (8.3279e-01)	Acc@1 56.250000 (38.446972)
Epoch: [31][ 48/591]	Time  0.636 ( 0.665)	Data  0.538 ( 0.567)	Loss 6.8930e-01 (8.2230e-01)	Acc@1 43.750000 (38.647957)
Epoch: [31][ 64/591]	Time  0.640 ( 0.678)	Data  0.542 ( 0.579)	Loss 7.0058e-01 (8.1672e-01)	Acc@1 12.500000 (36.634617)
Epoch: [31][ 80/591]	Time  0.627 ( 0.675)	Data  0.529 ( 0.577)	Loss 6.8829e-01 (8.1160e-01)	Acc@1 43.750000 (35.802471)
Epoch: [31][ 96/591]	Time  0.650 ( 0.669)	Data  0.552 ( 0.571)	Loss 8.3657e-01 (8.1462e-01)	Acc@1 31.250000 (35.244843)
Epoch: [31][112/591]	Time  0.610 ( 0.663)	Data  0.513 ( 0.565)	Loss 7.6811e-01 (8.2583e-01)	Acc@1 50.000000 (35.342918)
Epoch: [31][128/591]	Time  0.606 ( 0.658)	Data  0.509 ( 0.560)	Loss 1.1461e+00 (8.2479e-01)	Acc@1 12.500000 (35.222870)
Epoch: [31][144/591]	Time  0.931 ( 0.664)	Data  0.834 ( 0.565)	Loss 7.5087e-01 (8.2796e-01)	Acc@1 12.500000 (34.396553)
Epoch: [31][160/591]	Time  0.684 ( 0.662)	Data  0.586 ( 0.564)	Loss 1.0140e+00 (8.2575e-01)	Acc@1 12.500000 (34.006210)
Epoch: [31][176/591]	Time  0.597 ( 0.660)	Data  0.499 ( 0.562)	Loss 8.6418e-01 (8.2832e-01)	Acc@1 25.000000 (34.463276)
Epoch: [31][192/591]	Time  0.843 ( 0.658)	Data  0.746 ( 0.560)	Loss 8.2947e-01 (8.2980e-01)	Acc@1 50.000000 (34.650257)
Epoch: [31][208/591]	Time  0.692 ( 0.657)	Data  0.594 ( 0.558)	Loss 7.9332e-01 (8.3044e-01)	Acc@1 50.000000 (34.599281)
Epoch: [31][224/591]	Time  0.649 ( 0.657)	Data  0.552 ( 0.558)	Loss 8.4623e-01 (8.2944e-01)	Acc@1 37.500000 (34.611111)
Epoch: [31][240/591]	Time  0.606 ( 0.660)	Data  0.508 ( 0.562)	Loss 5.9330e-01 (8.2714e-01)	Acc@1 25.000000 (34.673237)
Epoch: [31][256/591]	Time  0.656 ( 0.660)	Data  0.557 ( 0.561)	Loss 7.7741e-01 (8.2479e-01)	Acc@1 62.500000 (35.019455)
Epoch: [31][272/591]	Time  0.641 ( 0.658)	Data  0.544 ( 0.560)	Loss 9.9141e-01 (8.2360e-01)	Acc@1 18.750000 (35.187729)
Epoch: [31][288/591]	Time  0.744 ( 0.659)	Data  0.646 ( 0.561)	Loss 8.1618e-01 (8.2333e-01)	Acc@1 37.500000 (35.380623)
Epoch: [31][304/591]	Time  0.681 ( 0.658)	Data  0.583 ( 0.560)	Loss 5.0799e-01 (8.2360e-01)	Acc@1 25.000000 (35.245903)
Epoch: [31][320/591]	Time  0.719 ( 0.658)	Data  0.622 ( 0.560)	Loss 6.5770e-01 (8.2395e-01)	Acc@1 43.750000 (35.221962)
Epoch: [31][336/591]	Time  0.706 ( 0.662)	Data  0.608 ( 0.563)	Loss 1.0532e+00 (8.2367e-01)	Acc@1 31.250000 (35.404301)
Epoch: [31][352/591]	Time  0.581 ( 0.661)	Data  0.482 ( 0.563)	Loss 1.0382e+00 (8.2469e-01)	Acc@1 37.500000 (35.481586)
Epoch: [31][368/591]	Time  0.682 ( 0.661)	Data  0.584 ( 0.563)	Loss 1.0737e+00 (8.2528e-01)	Acc@1 31.250000 (35.602982)
Epoch: [31][384/591]	Time  0.663 ( 0.660)	Data  0.565 ( 0.562)	Loss 7.9977e-01 (8.2494e-01)	Acc@1 31.250000 (35.487011)
Epoch: [31][400/591]	Time  0.673 ( 0.660)	Data  0.575 ( 0.562)	Loss 5.0337e-01 (8.2382e-01)	Acc@1 18.750000 (35.520576)
Epoch: [31][416/591]	Time  0.895 ( 0.663)	Data  0.783 ( 0.565)	Loss 1.2060e+00 (8.2499e-01)	Acc@1 12.500000 (35.311752)
Epoch: [31][432/591]	Time  0.782 ( 0.663)	Data  0.685 ( 0.565)	Loss 8.6739e-01 (8.2551e-01)	Acc@1 25.000000 (35.219398)
Epoch: [31][448/591]	Time  0.601 ( 0.664)	Data  0.503 ( 0.566)	Loss 8.8519e-01 (8.2423e-01)	Acc@1 37.500000 (35.175392)
Epoch: [31][464/591]	Time  0.628 ( 0.664)	Data  0.531 ( 0.566)	Loss 8.3046e-01 (8.2279e-01)	Acc@1 31.250000 (35.040325)
Epoch: [31][480/591]	Time  0.581 ( 0.664)	Data  0.483 ( 0.565)	Loss 7.9851e-01 (8.2403e-01)	Acc@1 50.000000 (34.849274)
Epoch: [31][496/591]	Time  0.687 ( 0.663)	Data  0.589 ( 0.564)	Loss 6.6358e-01 (8.2324e-01)	Acc@1 43.750000 (34.859154)
Epoch: [31][512/591]	Time  0.651 ( 0.664)	Data  0.553 ( 0.566)	Loss 7.0232e-01 (8.2190e-01)	Acc@1 31.250000 (34.831871)
Epoch: [31][528/591]	Time  0.809 ( 0.665)	Data  0.708 ( 0.566)	Loss 8.8500e-01 (8.2272e-01)	Acc@1 31.250000 (34.782608)
Epoch: [31][544/591]	Time  0.644 ( 0.664)	Data  0.547 ( 0.566)	Loss 6.1858e-01 (8.2337e-01)	Acc@1 50.000000 (34.690369)
Epoch: [31][560/591]	Time  0.608 ( 0.663)	Data  0.510 ( 0.565)	Loss 5.6619e-01 (8.2415e-01)	Acc@1 37.500000 (34.725937)
Epoch: [31][576/591]	Time  0.702 ( 0.663)	Data  0.604 ( 0.565)	Loss 7.5997e-01 (8.2378e-01)	Acc@1 50.000000 (34.770363)
##################################################
train_loss:  0.8232621003427683
train_acc:  tensor(34.8244, device='cuda:0')
##################################################
Best model was saved.
Epoch: [32][  0/591]	Time  0.991 ( 0.991)	Data  0.866 ( 0.866)	Loss 5.6153e-01 (5.6153e-01)	Acc@1 37.500000 (37.500000)
Epoch: [32][ 16/591]	Time  0.606 ( 0.683)	Data  0.508 ( 0.582)	Loss 1.0726e+00 (8.2496e-01)	Acc@1 31.250000 (35.661766)
Epoch: [32][ 32/591]	Time  0.611 ( 0.657)	Data  0.514 ( 0.558)	Loss 8.8358e-01 (8.3434e-01)	Acc@1 37.500000 (35.227272)
Epoch: [32][ 48/591]	Time  0.644 ( 0.650)	Data  0.547 ( 0.552)	Loss 1.0030e+00 (8.4142e-01)	Acc@1 12.500000 (33.545918)
Epoch: [32][ 64/591]	Time  0.707 ( 0.648)	Data  0.610 ( 0.550)	Loss 7.3542e-01 (8.2581e-01)	Acc@1 31.250000 (33.557693)
Epoch: [32][ 80/591]	Time  0.624 ( 0.645)	Data  0.526 ( 0.547)	Loss 6.4883e-01 (8.3556e-01)	Acc@1 43.750000 (34.182098)
Epoch: [32][ 96/591]	Time  0.644 ( 0.660)	Data  0.546 ( 0.562)	Loss 6.9581e-01 (8.3349e-01)	Acc@1 37.500000 (34.471649)
Epoch: [32][112/591]	Time  0.635 ( 0.659)	Data  0.538 ( 0.561)	Loss 8.7437e-01 (8.3392e-01)	Acc@1 37.500000 (33.683628)
Epoch: [32][128/591]	Time  0.593 ( 0.658)	Data  0.496 ( 0.560)	Loss 7.9695e-01 (8.3124e-01)	Acc@1 37.500000 (33.430233)
Epoch: [32][144/591]	Time  0.704 ( 0.657)	Data  0.607 ( 0.558)	Loss 7.5450e-01 (8.3152e-01)	Acc@1 25.000000 (33.362068)
Epoch: [32][160/591]	Time  0.647 ( 0.652)	Data  0.550 ( 0.554)	Loss 9.3179e-01 (8.2487e-01)	Acc@1 37.500000 (33.695652)
Epoch: [32][176/591]	Time  0.741 ( 0.652)	Data  0.643 ( 0.554)	Loss 8.8038e-01 (8.2679e-01)	Acc@1 12.500000 (33.686440)
Epoch: [32][192/591]	Time  0.670 ( 0.658)	Data  0.573 ( 0.560)	Loss 9.1312e-01 (8.2307e-01)	Acc@1 12.500000 (33.711140)
Epoch: [32][208/591]	Time  0.651 ( 0.656)	Data  0.553 ( 0.558)	Loss 7.9180e-01 (8.1933e-01)	Acc@1 43.750000 (33.971291)
Epoch: [32][224/591]	Time  0.631 ( 0.655)	Data  0.534 ( 0.557)	Loss 7.6637e-01 (8.1839e-01)	Acc@1 37.500000 (34.305557)
Epoch: [32][240/591]	Time  0.747 ( 0.655)	Data  0.648 ( 0.556)	Loss 7.4044e-01 (8.1798e-01)	Acc@1 37.500000 (34.517635)
Epoch: [32][256/591]	Time  0.649 ( 0.654)	Data  0.551 ( 0.556)	Loss 7.4133e-01 (8.1791e-01)	Acc@1 37.500000 (34.606030)
Epoch: [32][272/591]	Time  0.627 ( 0.653)	Data  0.530 ( 0.555)	Loss 7.7248e-01 (8.1776e-01)	Acc@1 18.750000 (34.478024)
Epoch: [32][288/591]	Time  0.672 ( 0.655)	Data  0.574 ( 0.557)	Loss 6.7235e-01 (8.1525e-01)	Acc@1 25.000000 (34.558826)
Epoch: [32][304/591]	Time  0.682 ( 0.655)	Data  0.584 ( 0.556)	Loss 7.1923e-01 (8.1600e-01)	Acc@1 25.000000 (34.385246)
Epoch: [32][320/591]	Time  0.659 ( 0.655)	Data  0.561 ( 0.557)	Loss 9.2582e-01 (8.1538e-01)	Acc@1 25.000000 (34.482086)
Epoch: [32][336/591]	Time  0.637 ( 0.654)	Data  0.539 ( 0.556)	Loss 8.8592e-01 (8.1509e-01)	Acc@1 31.250000 (34.458458)
Epoch: [32][352/591]	Time  0.591 ( 0.653)	Data  0.493 ( 0.555)	Loss 6.9427e-01 (8.1679e-01)	Acc@1 31.250000 (34.313030)
Epoch: [32][368/591]	Time  0.913 ( 0.655)	Data  0.808 ( 0.557)	Loss 9.9628e-01 (8.1724e-01)	Acc@1 50.000000 (34.518970)
Epoch: [32][384/591]	Time  0.653 ( 0.656)	Data  0.555 ( 0.558)	Loss 7.6253e-01 (8.1694e-01)	Acc@1 37.500000 (34.431816)
Epoch: [32][400/591]	Time  0.689 ( 0.655)	Data  0.592 ( 0.557)	Loss 7.6575e-01 (8.1973e-01)	Acc@1 37.500000 (34.180176)
Epoch: [32][416/591]	Time  0.823 ( 0.656)	Data  0.726 ( 0.557)	Loss 7.0633e-01 (8.2036e-01)	Acc@1 25.000000 (33.992805)
Epoch: [32][432/591]	Time  0.932 ( 0.655)	Data  0.834 ( 0.557)	Loss 7.1472e-01 (8.1807e-01)	Acc@1 31.250000 (33.877022)
Epoch: [32][448/591]	Time  0.653 ( 0.655)	Data  0.556 ( 0.557)	Loss 1.0772e+00 (8.1958e-01)	Acc@1 31.250000 (33.950447)
Epoch: [32][464/591]	Time  0.622 ( 0.658)	Data  0.525 ( 0.559)	Loss 5.9414e-01 (8.2081e-01)	Acc@1 31.250000 (33.978497)
Epoch: [32][480/591]	Time  0.669 ( 0.656)	Data  0.572 ( 0.558)	Loss 9.2763e-01 (8.2110e-01)	Acc@1 12.500000 (33.913723)
Epoch: [32][496/591]	Time  0.665 ( 0.656)	Data  0.567 ( 0.558)	Loss 6.2873e-01 (8.2114e-01)	Acc@1 43.750000 (33.853119)
Epoch: [32][512/591]	Time  0.601 ( 0.655)	Data  0.503 ( 0.557)	Loss 8.7607e-01 (8.2030e-01)	Acc@1 31.250000 (33.808479)
Epoch: [32][528/591]	Time  0.613 ( 0.655)	Data  0.515 ( 0.557)	Loss 7.2235e-01 (8.1829e-01)	Acc@1 31.250000 (33.778355)
Epoch: [32][544/591]	Time  0.909 ( 0.655)	Data  0.812 ( 0.557)	Loss 1.1522e+00 (8.1832e-01)	Acc@1 37.500000 (33.841743)
Epoch: [32][560/591]	Time  0.641 ( 0.657)	Data  0.543 ( 0.558)	Loss 9.1687e-01 (8.1754e-01)	Acc@1 18.750000 (33.756683)
Epoch: [32][576/591]	Time  0.634 ( 0.656)	Data  0.537 ( 0.558)	Loss 9.5726e-01 (8.1732e-01)	Acc@1 12.500000 (33.752167)
##################################################
train_loss:  0.8158749395921548
train_acc:  tensor(33.9150, device='cuda:0')
##################################################
Best model was saved.
Epoch: [33][  0/591]	Time  0.639 ( 0.639)	Data  0.535 ( 0.535)	Loss 7.9808e-01 (7.9808e-01)	Acc@1 18.750000 (18.750000)
Epoch: [33][ 16/591]	Time  0.587 ( 0.658)	Data  0.490 ( 0.560)	Loss 6.7694e-01 (7.9678e-01)	Acc@1 37.500000 (33.823528)
Epoch: [33][ 32/591]	Time  0.582 ( 0.655)	Data  0.485 ( 0.557)	Loss 8.3501e-01 (7.9613e-01)	Acc@1 37.500000 (36.553032)
Epoch: [33][ 48/591]	Time  0.724 ( 0.652)	Data  0.619 ( 0.554)	Loss 7.3881e-01 (7.9353e-01)	Acc@1 43.750000 (37.882652)
Epoch: [33][ 64/591]	Time  0.621 ( 0.662)	Data  0.524 ( 0.564)	Loss 9.5414e-01 (8.0265e-01)	Acc@1 31.250000 (38.942307)
Epoch: [33][ 80/591]	Time  0.639 ( 0.667)	Data  0.541 ( 0.569)	Loss 6.7388e-01 (8.0974e-01)	Acc@1 43.750000 (37.962963)
Epoch: [33][ 96/591]	Time  0.595 ( 0.662)	Data  0.498 ( 0.563)	Loss 7.5172e-01 (8.0669e-01)	Acc@1 43.750000 (37.822163)
Epoch: [33][112/591]	Time  0.610 ( 0.659)	Data  0.513 ( 0.561)	Loss 1.0293e+00 (8.0971e-01)	Acc@1 43.750000 (38.053097)
Epoch: [33][128/591]	Time  0.670 ( 0.660)	Data  0.573 ( 0.562)	Loss 8.2734e-01 (8.1374e-01)	Acc@1 37.500000 (37.403099)
Epoch: [33][144/591]	Time  0.628 ( 0.666)	Data  0.530 ( 0.568)	Loss 7.3998e-01 (8.1789e-01)	Acc@1 37.500000 (37.155170)
Epoch: [33][160/591]	Time  0.629 ( 0.662)	Data  0.532 ( 0.564)	Loss 7.7331e-01 (8.1895e-01)	Acc@1 31.250000 (36.684784)
Epoch: [33][176/591]	Time  0.602 ( 0.659)	Data  0.505 ( 0.561)	Loss 6.7444e-01 (8.1686e-01)	Acc@1 37.500000 (36.935028)
Epoch: [33][192/591]	Time  0.641 ( 0.657)	Data  0.544 ( 0.559)	Loss 9.1164e-01 (8.1450e-01)	Acc@1 37.500000 (37.014248)
Epoch: [33][208/591]	Time  0.599 ( 0.654)	Data  0.502 ( 0.556)	Loss 8.4397e-01 (8.1078e-01)	Acc@1 50.000000 (37.320572)
Epoch: [33][224/591]	Time  0.582 ( 0.653)	Data  0.485 ( 0.555)	Loss 5.3759e-01 (8.1270e-01)	Acc@1 31.250000 (37.472221)
Epoch: [33][240/591]	Time  0.583 ( 0.656)	Data  0.486 ( 0.558)	Loss 6.6740e-01 (8.0958e-01)	Acc@1 37.500000 (37.655605)
Epoch: [33][256/591]	Time  0.622 ( 0.654)	Data  0.524 ( 0.556)	Loss 6.7088e-01 (8.0816e-01)	Acc@1 43.750000 (37.524319)
Epoch: [33][272/591]	Time  0.633 ( 0.655)	Data  0.535 ( 0.557)	Loss 7.1899e-01 (8.0807e-01)	Acc@1 43.750000 (37.660255)
Epoch: [33][288/591]	Time  0.617 ( 0.653)	Data  0.519 ( 0.555)	Loss 1.0371e+00 (8.1025e-01)	Acc@1 25.000000 (37.348618)
Epoch: [33][304/591]	Time  0.732 ( 0.653)	Data  0.635 ( 0.555)	Loss 5.8971e-01 (8.0843e-01)	Acc@1 37.500000 (37.684425)
Epoch: [33][320/591]	Time  0.683 ( 0.651)	Data  0.586 ( 0.553)	Loss 7.3081e-01 (8.0700e-01)	Acc@1 43.750000 (37.655762)
Epoch: [33][336/591]	Time  0.667 ( 0.654)	Data  0.569 ( 0.556)	Loss 6.4274e-01 (8.0727e-01)	Acc@1 37.500000 (37.370178)
Epoch: [33][352/591]	Time  0.593 ( 0.653)	Data  0.495 ( 0.555)	Loss 6.4150e-01 (8.0751e-01)	Acc@1 31.250000 (37.145893)
Epoch: [33][368/591]	Time  0.584 ( 0.652)	Data  0.486 ( 0.554)	Loss 7.4226e-01 (8.0544e-01)	Acc@1 37.500000 (37.212059)
Epoch: [33][384/591]	Time  0.624 ( 0.651)	Data  0.527 ( 0.553)	Loss 7.6248e-01 (8.0527e-01)	Acc@1 43.750000 (37.142857)
Epoch: [33][400/591]	Time  0.627 ( 0.650)	Data  0.530 ( 0.552)	Loss 8.0442e-01 (8.0712e-01)	Acc@1 0.000000 (37.157108)
Epoch: [33][416/591]	Time  0.649 ( 0.649)	Data  0.551 ( 0.551)	Loss 8.2899e-01 (8.0567e-01)	Acc@1 31.250000 (37.080338)
Epoch: [33][432/591]	Time  0.612 ( 0.651)	Data  0.514 ( 0.553)	Loss 7.9699e-01 (8.0645e-01)	Acc@1 31.250000 (37.009239)
Epoch: [33][448/591]	Time  0.727 ( 0.651)	Data  0.629 ( 0.552)	Loss 5.7376e-01 (8.0450e-01)	Acc@1 50.000000 (36.901447)
Epoch: [33][464/591]	Time  0.640 ( 0.650)	Data  0.542 ( 0.552)	Loss 9.2892e-01 (8.0508e-01)	Acc@1 37.500000 (36.881721)
Epoch: [33][480/591]	Time  0.631 ( 0.650)	Data  0.534 ( 0.552)	Loss 7.2678e-01 (8.0463e-01)	Acc@1 18.750000 (36.590435)
Epoch: [33][496/591]	Time  0.621 ( 0.650)	Data  0.524 ( 0.552)	Loss 7.3337e-01 (8.0644e-01)	Acc@1 18.750000 (36.657444)
Epoch: [33][512/591]	Time  0.591 ( 0.654)	Data  0.487 ( 0.555)	Loss 8.5112e-01 (8.0642e-01)	Acc@1 37.500000 (36.549709)
Epoch: [33][528/591]	Time  0.603 ( 0.653)	Data  0.505 ( 0.555)	Loss 9.2420e-01 (8.0605e-01)	Acc@1 25.000000 (36.566635)
Epoch: [33][544/591]	Time  0.691 ( 0.653)	Data  0.592 ( 0.555)	Loss 7.1546e-01 (8.0583e-01)	Acc@1 43.750000 (36.490826)
Epoch: [33][560/591]	Time  0.908 ( 0.653)	Data  0.811 ( 0.555)	Loss 7.5546e-01 (8.0732e-01)	Acc@1 25.000000 (36.296791)
Epoch: [33][576/591]	Time  0.610 ( 0.653)	Data  0.512 ( 0.555)	Loss 9.6175e-01 (8.0805e-01)	Acc@1 37.500000 (36.319324)
##################################################
train_loss:  0.8068912774576552
train_acc:  tensor(36.2415, device='cuda:0')
##################################################
Best model was saved.
Epoch: [34][  0/591]	Time  0.647 ( 0.647)	Data  0.550 ( 0.550)	Loss 7.5415e-01 (7.5415e-01)	Acc@1 43.750000 (43.750000)
Epoch: [34][ 16/591]	Time  0.720 ( 0.698)	Data  0.621 ( 0.595)	Loss 9.1965e-01 (8.5502e-01)	Acc@1 25.000000 (31.985294)
Epoch: [34][ 32/591]	Time  0.587 ( 0.663)	Data  0.489 ( 0.563)	Loss 1.0132e+00 (8.6133e-01)	Acc@1 31.250000 (32.007576)
Epoch: [34][ 48/591]	Time  0.671 ( 0.656)	Data  0.573 ( 0.556)	Loss 5.9969e-01 (8.4541e-01)	Acc@1 50.000000 (32.908161)
Epoch: [34][ 64/591]	Time  0.646 ( 0.651)	Data  0.549 ( 0.552)	Loss 8.7767e-01 (8.3117e-01)	Acc@1 43.750000 (34.903847)
Epoch: [34][ 80/591]	Time  0.628 ( 0.648)	Data  0.531 ( 0.549)	Loss 6.0768e-01 (8.2745e-01)	Acc@1 37.500000 (35.262344)
Epoch: [34][ 96/591]	Time  0.551 ( 0.645)	Data  0.453 ( 0.547)	Loss 7.7657e-01 (8.2932e-01)	Acc@1 50.000000 (35.373711)
Epoch: [34][112/591]	Time  0.654 ( 0.652)	Data  0.557 ( 0.553)	Loss 5.4813e-01 (8.2500e-01)	Acc@1 37.500000 (35.619469)
Epoch: [34][128/591]	Time  0.630 ( 0.655)	Data  0.532 ( 0.556)	Loss 7.7711e-01 (8.2281e-01)	Acc@1 43.750000 (35.852715)
Epoch: [34][144/591]	Time  0.711 ( 0.654)	Data  0.607 ( 0.555)	Loss 8.5349e-01 (8.1818e-01)	Acc@1 43.750000 (35.517242)
Epoch: [34][160/591]	Time  0.862 ( 0.653)	Data  0.765 ( 0.555)	Loss 6.8056e-01 (8.1855e-01)	Acc@1 50.000000 (35.830746)
Epoch: [34][176/591]	Time  0.662 ( 0.654)	Data  0.565 ( 0.555)	Loss 8.4415e-01 (8.2202e-01)	Acc@1 50.000000 (35.628532)
Epoch: [34][192/591]	Time  0.841 ( 0.660)	Data  0.743 ( 0.561)	Loss 9.3016e-01 (8.2274e-01)	Acc@1 43.750000 (35.136009)
Epoch: [34][208/591]	Time  0.634 ( 0.658)	Data  0.536 ( 0.559)	Loss 1.1233e+00 (8.2494e-01)	Acc@1 18.750000 (34.958134)
Epoch: [34][224/591]	Time  0.607 ( 0.656)	Data  0.510 ( 0.558)	Loss 7.5006e-01 (8.2332e-01)	Acc@1 31.250000 (34.805557)
Epoch: [34][240/591]	Time  0.611 ( 0.654)	Data  0.513 ( 0.555)	Loss 6.1998e-01 (8.1955e-01)	Acc@1 43.750000 (35.088177)
Epoch: [34][256/591]	Time  0.635 ( 0.654)	Data  0.537 ( 0.555)	Loss 6.6842e-01 (8.1712e-01)	Acc@1 31.250000 (35.165371)
Epoch: [34][272/591]	Time  0.598 ( 0.653)	Data  0.501 ( 0.555)	Loss 9.4081e-01 (8.1419e-01)	Acc@1 50.000000 (35.187729)
Epoch: [34][288/591]	Time  0.668 ( 0.656)	Data  0.570 ( 0.558)	Loss 6.2925e-01 (8.1301e-01)	Acc@1 43.750000 (35.229240)
Epoch: [34][304/591]	Time  0.580 ( 0.657)	Data  0.482 ( 0.559)	Loss 8.1314e-01 (8.1384e-01)	Acc@1 37.500000 (35.184425)
Epoch: [34][320/591]	Time  0.600 ( 0.657)	Data  0.502 ( 0.558)	Loss 8.7983e-01 (8.1338e-01)	Acc@1 31.250000 (35.416664)
Epoch: [34][336/591]	Time  0.592 ( 0.656)	Data  0.495 ( 0.557)	Loss 8.6852e-01 (8.1453e-01)	Acc@1 50.000000 (35.552670)
Epoch: [34][352/591]	Time  0.596 ( 0.657)	Data  0.498 ( 0.558)	Loss 7.8231e-01 (8.1578e-01)	Acc@1 37.500000 (35.357647)
Epoch: [34][368/591]	Time  0.619 ( 0.655)	Data  0.521 ( 0.557)	Loss 5.3369e-01 (8.1440e-01)	Acc@1 43.750000 (35.230354)
Epoch: [34][384/591]	Time  0.613 ( 0.658)	Data  0.515 ( 0.560)	Loss 7.4033e-01 (8.1517e-01)	Acc@1 31.250000 (35.097401)
Epoch: [34][400/591]	Time  0.649 ( 0.657)	Data  0.552 ( 0.559)	Loss 7.3539e-01 (8.1344e-01)	Acc@1 50.000000 (35.380299)
Epoch: [34][416/591]	Time  0.662 ( 0.656)	Data  0.564 ( 0.558)	Loss 6.0081e-01 (8.0876e-01)	Acc@1 25.000000 (35.356716)
Epoch: [34][432/591]	Time  0.661 ( 0.656)	Data  0.562 ( 0.557)	Loss 1.0210e+00 (8.0788e-01)	Acc@1 25.000000 (35.262703)
Epoch: [34][448/591]	Time  0.683 ( 0.655)	Data  0.585 ( 0.557)	Loss 5.6326e-01 (8.0839e-01)	Acc@1 68.750000 (35.342430)
Epoch: [34][464/591]	Time  0.987 ( 0.657)	Data  0.883 ( 0.558)	Loss 6.7300e-01 (8.0609e-01)	Acc@1 37.500000 (35.215054)
Epoch: [34][480/591]	Time  0.614 ( 0.657)	Data  0.517 ( 0.559)	Loss 7.5361e-01 (8.0643e-01)	Acc@1 25.000000 (35.031185)
Epoch: [34][496/591]	Time  0.656 ( 0.656)	Data  0.558 ( 0.558)	Loss 6.1718e-01 (8.0183e-01)	Acc@1 12.500000 (34.959759)
Epoch: [34][512/591]	Time  0.663 ( 0.656)	Data  0.565 ( 0.558)	Loss 7.4365e-01 (8.0029e-01)	Acc@1 37.500000 (35.197369)
Epoch: [34][528/591]	Time  0.636 ( 0.656)	Data  0.539 ( 0.557)	Loss 9.9470e-01 (8.0167e-01)	Acc@1 56.250000 (35.160683)
Epoch: [34][544/591]	Time  0.646 ( 0.656)	Data  0.547 ( 0.558)	Loss 6.5728e-01 (7.9909e-01)	Acc@1 62.500000 (35.229359)
Epoch: [34][560/591]	Time  0.599 ( 0.657)	Data  0.502 ( 0.559)	Loss 8.4763e-01 (7.9832e-01)	Acc@1 25.000000 (35.305256)
Epoch: [34][576/591]	Time  0.722 ( 0.657)	Data  0.624 ( 0.558)	Loss 1.0251e+00 (7.9912e-01)	Acc@1 31.250000 (35.333622)
##################################################
train_loss:  0.7988521560597944
train_acc:  tensor(35.3321, device='cuda:0')
##################################################
Best model was saved.
Epoch: [35][  0/591]	Time  0.645 ( 0.645)	Data  0.547 ( 0.547)	Loss 5.8256e-01 (5.8256e-01)	Acc@1 43.750000 (43.750000)
Epoch: [35][ 16/591]	Time  0.609 ( 0.634)	Data  0.510 ( 0.536)	Loss 1.0589e+00 (7.9889e-01)	Acc@1 43.750000 (40.808823)
Epoch: [35][ 32/591]	Time  0.637 ( 0.636)	Data  0.540 ( 0.538)	Loss 9.8962e-01 (7.9591e-01)	Acc@1 25.000000 (38.068184)
Epoch: [35][ 48/591]	Time  0.596 ( 0.639)	Data  0.498 ( 0.542)	Loss 7.3944e-01 (7.9887e-01)	Acc@1 50.000000 (38.520409)
Epoch: [35][ 64/591]	Time  0.661 ( 0.657)	Data  0.564 ( 0.559)	Loss 8.5057e-01 (7.9772e-01)	Acc@1 18.750000 (38.076923)
Epoch: [35][ 80/591]	Time  0.609 ( 0.655)	Data  0.511 ( 0.556)	Loss 8.6641e-01 (7.9905e-01)	Acc@1 37.500000 (38.194447)
Epoch: [35][ 96/591]	Time  0.624 ( 0.655)	Data  0.526 ( 0.557)	Loss 1.1813e+00 (8.0883e-01)	Acc@1 43.750000 (37.886597)
Epoch: [35][112/591]	Time  0.625 ( 0.656)	Data  0.528 ( 0.558)	Loss 7.8572e-01 (8.1322e-01)	Acc@1 37.500000 (37.665928)
Epoch: [35][128/591]	Time  0.614 ( 0.653)	Data  0.517 ( 0.555)	Loss 8.8676e-01 (8.1811e-01)	Acc@1 37.500000 (37.354652)
Epoch: [35][144/591]	Time  0.940 ( 0.656)	Data  0.834 ( 0.558)	Loss 6.4500e-01 (8.1229e-01)	Acc@1 25.000000 (37.198277)
Epoch: [35][160/591]	Time  0.593 ( 0.661)	Data  0.496 ( 0.563)	Loss 6.6534e-01 (8.0782e-01)	Acc@1 25.000000 (37.034161)
Epoch: [35][176/591]	Time  0.664 ( 0.657)	Data  0.565 ( 0.559)	Loss 8.9032e-01 (8.0857e-01)	Acc@1 25.000000 (36.935028)
Epoch: [35][192/591]	Time  0.651 ( 0.657)	Data  0.554 ( 0.558)	Loss 7.1241e-01 (8.0727e-01)	Acc@1 31.250000 (36.852329)
Epoch: [35][208/591]	Time  0.635 ( 0.655)	Data  0.538 ( 0.557)	Loss 8.4359e-01 (8.0659e-01)	Acc@1 43.750000 (36.692581)
Epoch: [35][224/591]	Time  0.582 ( 0.654)	Data  0.485 ( 0.556)	Loss 8.5323e-01 (8.0728e-01)	Acc@1 43.750000 (36.611111)
Epoch: [35][240/591]	Time  0.677 ( 0.657)	Data  0.579 ( 0.559)	Loss 8.3498e-01 (8.0865e-01)	Acc@1 25.000000 (36.229256)
Epoch: [35][256/591]	Time  0.604 ( 0.655)	Data  0.506 ( 0.557)	Loss 8.2367e-01 (8.0845e-01)	Acc@1 37.500000 (36.186771)
Epoch: [35][272/591]	Time  0.630 ( 0.654)	Data  0.532 ( 0.556)	Loss 8.7781e-01 (8.0972e-01)	Acc@1 18.750000 (35.943222)
Epoch: [35][288/591]	Time  0.603 ( 0.652)	Data  0.505 ( 0.554)	Loss 7.4300e-01 (8.0531e-01)	Acc@1 37.500000 (36.137543)
Epoch: [35][304/591]	Time  0.634 ( 0.653)	Data  0.536 ( 0.555)	Loss 7.9205e-01 (8.0174e-01)	Acc@1 31.250000 (36.209015)
Epoch: [35][320/591]	Time  0.598 ( 0.652)	Data  0.500 ( 0.554)	Loss 6.3958e-01 (8.0308e-01)	Acc@1 56.250000 (36.273365)
Epoch: [35][336/591]	Time  0.619 ( 0.657)	Data  0.521 ( 0.559)	Loss 7.1095e-01 (8.0512e-01)	Acc@1 43.750000 (36.238873)
Epoch: [35][352/591]	Time  0.633 ( 0.655)	Data  0.536 ( 0.557)	Loss 9.9065e-01 (8.0248e-01)	Acc@1 25.000000 (36.225212)
Epoch: [35][368/591]	Time  0.652 ( 0.655)	Data  0.555 ( 0.557)	Loss 6.7726e-01 (7.9936e-01)	Acc@1 25.000000 (36.128048)
Epoch: [35][384/591]	Time  0.582 ( 0.655)	Data  0.485 ( 0.557)	Loss 6.5841e-01 (7.9919e-01)	Acc@1 18.750000 (35.844154)
Epoch: [35][400/591]	Time  0.717 ( 0.654)	Data  0.619 ( 0.556)	Loss 7.4110e-01 (7.9866e-01)	Acc@1 37.500000 (35.769951)
Epoch: [35][416/591]	Time  0.616 ( 0.654)	Data  0.519 ( 0.556)	Loss 1.0123e+00 (8.0142e-01)	Acc@1 25.000000 (35.746403)
Epoch: [35][432/591]	Time  0.605 ( 0.656)	Data  0.508 ( 0.558)	Loss 6.9668e-01 (8.0167e-01)	Acc@1 50.000000 (35.854504)
Epoch: [35][448/591]	Time  0.612 ( 0.656)	Data  0.507 ( 0.558)	Loss 7.8649e-01 (8.0288e-01)	Acc@1 56.250000 (35.829624)
Epoch: [35][464/591]	Time  0.638 ( 0.655)	Data  0.541 ( 0.557)	Loss 7.5194e-01 (8.0263e-01)	Acc@1 43.750000 (35.913979)
Epoch: [35][480/591]	Time  0.620 ( 0.655)	Data  0.522 ( 0.556)	Loss 5.9485e-01 (7.9985e-01)	Acc@1 31.250000 (35.771832)
Epoch: [35][496/591]	Time  0.628 ( 0.654)	Data  0.530 ( 0.556)	Loss 8.9001e-01 (7.9835e-01)	Acc@1 31.250000 (35.651405)
Epoch: [35][512/591]	Time  1.138 ( 0.656)	Data  1.025 ( 0.558)	Loss 8.0636e-01 (7.9933e-01)	Acc@1 50.000000 (35.648148)
Epoch: [35][528/591]	Time  0.601 ( 0.656)	Data  0.504 ( 0.557)	Loss 7.4924e-01 (7.9878e-01)	Acc@1 37.500000 (35.834122)
Epoch: [35][544/591]	Time  0.627 ( 0.656)	Data  0.530 ( 0.558)	Loss 6.8790e-01 (7.9745e-01)	Acc@1 43.750000 (36.100918)
Epoch: [35][560/591]	Time  0.636 ( 0.656)	Data  0.538 ( 0.558)	Loss 7.9971e-01 (7.9589e-01)	Acc@1 37.500000 (36.174240)
Epoch: [35][576/591]	Time  0.682 ( 0.656)	Data  0.584 ( 0.558)	Loss 8.2665e-01 (7.9501e-01)	Acc@1 37.500000 (36.232670)
##################################################
train_loss:  0.7946133331195554
train_acc:  tensor(36.1464, device='cuda:0')
##################################################
Best model was saved.
Epoch: [36][  0/591]	Time  0.658 ( 0.658)	Data  0.560 ( 0.560)	Loss 8.1861e-01 (8.1861e-01)	Acc@1 43.750000 (43.750000)
Epoch: [36][ 16/591]	Time  0.626 ( 0.731)	Data  0.529 ( 0.631)	Loss 8.5259e-01 (7.9879e-01)	Acc@1 43.750000 (42.279411)
Epoch: [36][ 32/591]	Time  0.593 ( 0.686)	Data  0.495 ( 0.587)	Loss 7.9108e-01 (7.8895e-01)	Acc@1 37.500000 (37.500000)
Epoch: [36][ 48/591]	Time  0.613 ( 0.670)	Data  0.516 ( 0.571)	Loss 9.5960e-01 (7.7638e-01)	Acc@1 31.250000 (37.500000)
Epoch: [36][ 64/591]	Time  0.784 ( 0.661)	Data  0.686 ( 0.562)	Loss 5.7155e-01 (7.8826e-01)	Acc@1 31.250000 (37.019230)
Epoch: [36][ 80/591]	Time  0.595 ( 0.664)	Data  0.498 ( 0.566)	Loss 5.4680e-01 (7.8726e-01)	Acc@1 50.000000 (37.345680)
Epoch: [36][ 96/591]	Time  0.657 ( 0.660)	Data  0.559 ( 0.561)	Loss 7.5531e-01 (7.8137e-01)	Acc@1 56.250000 (37.564430)
Epoch: [36][112/591]	Time  0.766 ( 0.669)	Data  0.667 ( 0.570)	Loss 8.2656e-01 (7.7938e-01)	Acc@1 25.000000 (38.274338)
Epoch: [36][128/591]	Time  0.646 ( 0.666)	Data  0.548 ( 0.567)	Loss 6.2424e-01 (7.7756e-01)	Acc@1 25.000000 (38.323643)
Epoch: [36][144/591]	Time  0.639 ( 0.661)	Data  0.541 ( 0.562)	Loss 8.8063e-01 (7.8277e-01)	Acc@1 37.500000 (37.974136)
Epoch: [36][160/591]	Time  0.699 ( 0.660)	Data  0.597 ( 0.562)	Loss 8.1810e-01 (7.8657e-01)	Acc@1 6.250000 (37.888199)
Epoch: [36][176/591]	Time  0.659 ( 0.660)	Data  0.561 ( 0.561)	Loss 1.1631e+00 (7.8713e-01)	Acc@1 31.250000 (38.276836)
Epoch: [36][192/591]	Time  0.659 ( 0.665)	Data  0.560 ( 0.566)	Loss 7.1928e-01 (7.8930e-01)	Acc@1 25.000000 (38.050518)
Epoch: [36][208/591]	Time  0.632 ( 0.663)	Data  0.534 ( 0.565)	Loss 7.1008e-01 (7.8782e-01)	Acc@1 25.000000 (38.157894)
Epoch: [36][224/591]	Time  0.594 ( 0.661)	Data  0.497 ( 0.563)	Loss 7.5292e-01 (7.8778e-01)	Acc@1 50.000000 (38.250000)
Epoch: [36][240/591]	Time  0.632 ( 0.659)	Data  0.535 ( 0.561)	Loss 8.6523e-01 (7.9074e-01)	Acc@1 25.000000 (37.889008)
Epoch: [36][256/591]	Time  0.653 ( 0.658)	Data  0.555 ( 0.560)	Loss 6.5973e-01 (7.9370e-01)	Acc@1 37.500000 (37.718872)
Epoch: [36][272/591]	Time  0.631 ( 0.656)	Data  0.533 ( 0.557)	Loss 8.8501e-01 (7.9039e-01)	Acc@1 6.250000 (37.225273)
Epoch: [36][288/591]	Time  0.614 ( 0.658)	Data  0.516 ( 0.560)	Loss 7.9588e-01 (7.8786e-01)	Acc@1 31.250000 (37.348618)
Epoch: [36][304/591]	Time  0.638 ( 0.658)	Data  0.540 ( 0.560)	Loss 7.0758e-01 (7.8923e-01)	Acc@1 37.500000 (37.336067)
Epoch: [36][320/591]	Time  0.630 ( 0.658)	Data  0.533 ( 0.560)	Loss 1.0341e+00 (7.8864e-01)	Acc@1 12.500000 (37.441589)
Epoch: [36][336/591]	Time  0.644 ( 0.657)	Data  0.547 ( 0.558)	Loss 5.1224e-01 (7.8820e-01)	Acc@1 31.250000 (37.555637)
Epoch: [36][352/591]	Time  0.877 ( 0.657)	Data  0.780 ( 0.558)	Loss 1.1476e+00 (7.9009e-01)	Acc@1 25.000000 (37.553116)
Epoch: [36][368/591]	Time  0.644 ( 0.657)	Data  0.546 ( 0.559)	Loss 7.0406e-01 (7.9232e-01)	Acc@1 37.500000 (37.533875)
Epoch: [36][384/591]	Time  0.672 ( 0.660)	Data  0.574 ( 0.562)	Loss 8.0679e-01 (7.9237e-01)	Acc@1 43.750000 (37.435062)
Epoch: [36][400/591]	Time  0.602 ( 0.659)	Data  0.504 ( 0.561)	Loss 9.9821e-01 (7.9262e-01)	Acc@1 12.500000 (37.250626)
Epoch: [36][416/591]	Time  0.629 ( 0.659)	Data  0.531 ( 0.561)	Loss 7.3671e-01 (7.9258e-01)	Acc@1 25.000000 (37.275181)
Epoch: [36][432/591]	Time  0.627 ( 0.659)	Data  0.529 ( 0.561)	Loss 8.7769e-01 (7.9408e-01)	Acc@1 31.250000 (37.139145)
Epoch: [36][448/591]	Time  0.620 ( 0.660)	Data  0.522 ( 0.561)	Loss 7.7432e-01 (7.9363e-01)	Acc@1 43.750000 (37.165924)
Epoch: [36][464/591]	Time  0.953 ( 0.661)	Data  0.848 ( 0.562)	Loss 8.4433e-01 (7.9421e-01)	Acc@1 12.500000 (37.137096)
Epoch: [36][480/591]	Time  0.631 ( 0.661)	Data  0.534 ( 0.562)	Loss 5.3808e-01 (7.9246e-01)	Acc@1 31.250000 (37.175156)
Epoch: [36][496/591]	Time  0.638 ( 0.661)	Data  0.540 ( 0.562)	Loss 7.6980e-01 (7.9325e-01)	Acc@1 31.250000 (37.173038)
Epoch: [36][512/591]	Time  0.874 ( 0.661)	Data  0.776 ( 0.563)	Loss 1.0241e+00 (7.9477e-01)	Acc@1 12.500000 (37.000488)
Epoch: [36][528/591]	Time  0.631 ( 0.662)	Data  0.533 ( 0.563)	Loss 7.3152e-01 (7.9260e-01)	Acc@1 68.750000 (37.169189)
Epoch: [36][544/591]	Time  0.622 ( 0.661)	Data  0.524 ( 0.563)	Loss 9.0574e-01 (7.9314e-01)	Acc@1 37.500000 (36.983944)
Epoch: [36][560/591]	Time  0.639 ( 0.663)	Data  0.541 ( 0.564)	Loss 8.9109e-01 (7.9288e-01)	Acc@1 31.250000 (37.087788)
Epoch: [36][576/591]	Time  0.617 ( 0.663)	Data  0.519 ( 0.565)	Loss 9.3935e-01 (7.9220e-01)	Acc@1 25.000000 (37.045059)
##################################################
train_loss:  0.791147635118207
train_acc:  tensor(37.0664, device='cuda:0')
##################################################
Best model was saved.
Epoch: [37][  0/591]	Time  0.659 ( 0.659)	Data  0.561 ( 0.561)	Loss 7.3347e-01 (7.3347e-01)	Acc@1 37.500000 (37.500000)
Epoch: [37][ 16/591]	Time  0.591 ( 0.669)	Data  0.493 ( 0.571)	Loss 8.1192e-01 (7.7927e-01)	Acc@1 12.500000 (38.970589)
Epoch: [37][ 32/591]	Time  0.644 ( 0.681)	Data  0.546 ( 0.583)	Loss 7.9327e-01 (7.6658e-01)	Acc@1 62.500000 (39.204548)
Epoch: [37][ 48/591]	Time  0.758 ( 0.695)	Data  0.660 ( 0.596)	Loss 6.5535e-01 (7.5473e-01)	Acc@1 43.750000 (39.540817)
Epoch: [37][ 64/591]	Time  0.678 ( 0.684)	Data  0.580 ( 0.585)	Loss 6.2763e-01 (7.5836e-01)	Acc@1 25.000000 (38.076923)
Epoch: [37][ 80/591]	Time  0.635 ( 0.674)	Data  0.537 ( 0.575)	Loss 5.6475e-01 (7.5484e-01)	Acc@1 37.500000 (38.117283)
Epoch: [37][ 96/591]	Time  0.795 ( 0.669)	Data  0.697 ( 0.570)	Loss 9.9399e-01 (7.5867e-01)	Acc@1 18.750000 (37.371132)
Epoch: [37][112/591]	Time  0.611 ( 0.669)	Data  0.513 ( 0.570)	Loss 9.3775e-01 (7.6083e-01)	Acc@1 37.500000 (36.836285)
Epoch: [37][128/591]	Time  0.713 ( 0.668)	Data  0.615 ( 0.570)	Loss 7.6425e-01 (7.5494e-01)	Acc@1 43.750000 (37.257751)
Epoch: [37][144/591]	Time  0.686 ( 0.675)	Data  0.588 ( 0.577)	Loss 7.5191e-01 (7.5955e-01)	Acc@1 43.750000 (37.801723)
Epoch: [37][160/591]	Time  0.639 ( 0.672)	Data  0.541 ( 0.574)	Loss 7.3018e-01 (7.5834e-01)	Acc@1 62.500000 (37.927021)
Epoch: [37][176/591]	Time  0.613 ( 0.669)	Data  0.516 ( 0.571)	Loss 6.5066e-01 (7.5502e-01)	Acc@1 18.750000 (38.170902)
Epoch: [37][192/591]	Time  0.634 ( 0.668)	Data  0.535 ( 0.569)	Loss 8.3366e-01 (7.5102e-01)	Acc@1 37.500000 (38.568653)
Epoch: [37][208/591]	Time  0.611 ( 0.665)	Data  0.513 ( 0.567)	Loss 7.1924e-01 (7.5515e-01)	Acc@1 43.750000 (38.427032)
Epoch: [37][224/591]	Time  0.664 ( 0.663)	Data  0.566 ( 0.565)	Loss 9.7659e-01 (7.5789e-01)	Acc@1 37.500000 (38.194447)
Epoch: [37][240/591]	Time  0.637 ( 0.667)	Data  0.540 ( 0.568)	Loss 7.1440e-01 (7.5763e-01)	Acc@1 43.750000 (38.226143)
Epoch: [37][256/591]	Time  0.599 ( 0.665)	Data  0.501 ( 0.567)	Loss 6.5841e-01 (7.6091e-01)	Acc@1 37.500000 (38.205254)
Epoch: [37][272/591]	Time  0.624 ( 0.663)	Data  0.527 ( 0.565)	Loss 7.9627e-01 (7.6064e-01)	Acc@1 50.000000 (37.934982)
Epoch: [37][288/591]	Time  0.646 ( 0.661)	Data  0.548 ( 0.563)	Loss 7.8624e-01 (7.6214e-01)	Acc@1 25.000000 (37.651386)
Epoch: [37][304/591]	Time  0.798 ( 0.661)	Data  0.701 ( 0.563)	Loss 9.0419e-01 (7.6024e-01)	Acc@1 56.250000 (37.745903)
Epoch: [37][320/591]	Time  0.919 ( 0.663)	Data  0.814 ( 0.565)	Loss 4.7962e-01 (7.6030e-01)	Acc@1 50.000000 (37.480530)
Epoch: [37][336/591]	Time  0.780 ( 0.662)	Data  0.683 ( 0.564)	Loss 8.0433e-01 (7.6230e-01)	Acc@1 31.250000 (37.444363)
Epoch: [37][352/591]	Time  0.627 ( 0.662)	Data  0.529 ( 0.564)	Loss 7.8258e-01 (7.6406e-01)	Acc@1 43.750000 (37.464588)
Epoch: [37][368/591]	Time  0.649 ( 0.662)	Data  0.552 ( 0.563)	Loss 8.1137e-01 (7.6324e-01)	Acc@1 62.500000 (37.432251)
Epoch: [37][384/591]	Time  0.706 ( 0.661)	Data  0.608 ( 0.562)	Loss 6.9720e-01 (7.6492e-01)	Acc@1 43.750000 (37.500000)
Epoch: [37][400/591]	Time  0.626 ( 0.660)	Data  0.528 ( 0.561)	Loss 7.9636e-01 (7.6628e-01)	Acc@1 18.750000 (37.141521)
Epoch: [37][416/591]	Time  0.677 ( 0.661)	Data  0.580 ( 0.563)	Loss 7.1464e-01 (7.6631e-01)	Acc@1 37.500000 (37.320145)
Epoch: [37][432/591]	Time  0.594 ( 0.661)	Data  0.495 ( 0.563)	Loss 7.0611e-01 (7.6708e-01)	Acc@1 50.000000 (37.456696)
Epoch: [37][448/591]	Time  0.701 ( 0.660)	Data  0.604 ( 0.562)	Loss 7.3708e-01 (7.6885e-01)	Acc@1 56.250000 (37.235523)
Epoch: [37][464/591]	Time  0.642 ( 0.659)	Data  0.544 ( 0.561)	Loss 7.9575e-01 (7.6963e-01)	Acc@1 31.250000 (37.137096)
Epoch: [37][480/591]	Time  0.614 ( 0.659)	Data  0.517 ( 0.561)	Loss 9.9240e-01 (7.7192e-01)	Acc@1 31.250000 (37.097195)
Epoch: [37][496/591]	Time  0.656 ( 0.658)	Data  0.558 ( 0.560)	Loss 7.7478e-01 (7.7222e-01)	Acc@1 50.000000 (37.059856)
Epoch: [37][512/591]	Time  0.609 ( 0.660)	Data  0.512 ( 0.562)	Loss 7.0639e-01 (7.7076e-01)	Acc@1 25.000000 (37.134502)
Epoch: [37][528/591]	Time  0.600 ( 0.660)	Data  0.502 ( 0.562)	Loss 5.0318e-01 (7.7131e-01)	Acc@1 50.000000 (37.098301)
Epoch: [37][544/591]	Time  0.608 ( 0.660)	Data  0.511 ( 0.561)	Loss 7.0891e-01 (7.7179e-01)	Acc@1 43.750000 (37.155964)
Epoch: [37][560/591]	Time  0.622 ( 0.658)	Data  0.523 ( 0.560)	Loss 7.3365e-01 (7.7174e-01)	Acc@1 31.250000 (37.121212)
Epoch: [37][576/591]	Time  0.633 ( 0.658)	Data  0.535 ( 0.560)	Loss 8.8251e-01 (7.6954e-01)	Acc@1 25.000000 (37.153381)
##################################################
train_loss:  0.769199038721785
train_acc:  tensor(37.0347, device='cuda:0')
##################################################
Best model was saved.
Epoch: [38][  0/591]	Time  0.664 ( 0.664)	Data  0.560 ( 0.560)	Loss 8.4605e-01 (8.4605e-01)	Acc@1 43.750000 (43.750000)
Epoch: [38][ 16/591]	Time  0.661 ( 0.733)	Data  0.563 ( 0.634)	Loss 6.3379e-01 (7.4943e-01)	Acc@1 50.000000 (37.132355)
Epoch: [38][ 32/591]	Time  0.611 ( 0.676)	Data  0.513 ( 0.577)	Loss 5.5290e-01 (7.1885e-01)	Acc@1 43.750000 (39.583336)
Epoch: [38][ 48/591]	Time  0.623 ( 0.657)	Data  0.525 ( 0.559)	Loss 8.5395e-01 (7.2584e-01)	Acc@1 43.750000 (38.647957)
Epoch: [38][ 64/591]	Time  0.669 ( 0.656)	Data  0.571 ( 0.558)	Loss 7.2791e-01 (7.2802e-01)	Acc@1 31.250000 (38.846153)
Epoch: [38][ 80/591]	Time  0.847 ( 0.655)	Data  0.749 ( 0.557)	Loss 5.2848e-01 (7.2905e-01)	Acc@1 25.000000 (38.734570)
Epoch: [38][ 96/591]	Time  0.622 ( 0.665)	Data  0.524 ( 0.567)	Loss 8.8818e-01 (7.3669e-01)	Acc@1 31.250000 (39.175255)
Epoch: [38][112/591]	Time  0.655 ( 0.663)	Data  0.557 ( 0.565)	Loss 7.0684e-01 (7.3112e-01)	Acc@1 31.250000 (39.103981)
Epoch: [38][128/591]	Time  0.669 ( 0.666)	Data  0.571 ( 0.568)	Loss 8.1883e-01 (7.3712e-01)	Acc@1 37.500000 (38.905037)
Epoch: [38][144/591]	Time  0.735 ( 0.665)	Data  0.638 ( 0.567)	Loss 8.9586e-01 (7.4266e-01)	Acc@1 37.500000 (38.577587)
Epoch: [38][160/591]	Time  0.566 ( 0.660)	Data  0.468 ( 0.562)	Loss 6.1622e-01 (7.4125e-01)	Acc@1 50.000000 (38.198757)
Epoch: [38][176/591]	Time  0.612 ( 0.658)	Data  0.515 ( 0.560)	Loss 5.9155e-01 (7.4311e-01)	Acc@1 43.750000 (38.206215)
Epoch: [38][192/591]	Time  0.579 ( 0.662)	Data  0.481 ( 0.564)	Loss 7.8079e-01 (7.4612e-01)	Acc@1 31.250000 (38.147667)
Epoch: [38][208/591]	Time  0.620 ( 0.660)	Data  0.522 ( 0.562)	Loss 9.4653e-01 (7.4954e-01)	Acc@1 37.500000 (38.038277)
Epoch: [38][224/591]	Time  0.639 ( 0.659)	Data  0.540 ( 0.561)	Loss 7.9826e-01 (7.4710e-01)	Acc@1 37.500000 (37.916668)
Epoch: [38][240/591]	Time  0.627 ( 0.657)	Data  0.529 ( 0.559)	Loss 8.5066e-01 (7.4617e-01)	Acc@1 25.000000 (38.148342)
Epoch: [38][256/591]	Time  0.630 ( 0.657)	Data  0.533 ( 0.559)	Loss 5.1443e-01 (7.4667e-01)	Acc@1 50.000000 (37.986382)
Epoch: [38][272/591]	Time  0.630 ( 0.655)	Data  0.532 ( 0.557)	Loss 6.7591e-01 (7.4892e-01)	Acc@1 43.750000 (37.889194)
Epoch: [38][288/591]	Time  0.624 ( 0.657)	Data  0.526 ( 0.558)	Loss 5.4258e-01 (7.5099e-01)	Acc@1 31.250000 (37.889275)
Epoch: [38][304/591]	Time  0.683 ( 0.655)	Data  0.585 ( 0.557)	Loss 8.0152e-01 (7.5150e-01)	Acc@1 18.750000 (37.889343)
Epoch: [38][320/591]	Time  0.631 ( 0.654)	Data  0.534 ( 0.556)	Loss 9.7030e-01 (7.5063e-01)	Acc@1 18.750000 (38.006229)
Epoch: [38][336/591]	Time  0.645 ( 0.653)	Data  0.547 ( 0.555)	Loss 6.3669e-01 (7.5023e-01)	Acc@1 12.500000 (37.796734)
Epoch: [38][352/591]	Time  0.553 ( 0.653)	Data  0.456 ( 0.555)	Loss 7.7508e-01 (7.5485e-01)	Acc@1 31.250000 (37.677052)
Epoch: [38][368/591]	Time  0.955 ( 0.653)	Data  0.833 ( 0.555)	Loss 7.4310e-01 (7.5541e-01)	Acc@1 31.250000 (37.466125)
Epoch: [38][384/591]	Time  0.625 ( 0.656)	Data  0.528 ( 0.558)	Loss 8.6446e-01 (7.5635e-01)	Acc@1 37.500000 (37.435062)
Epoch: [38][400/591]	Time  0.657 ( 0.655)	Data  0.559 ( 0.557)	Loss 5.2105e-01 (7.5762e-01)	Acc@1 43.750000 (37.266212)
Epoch: [38][416/591]	Time  0.588 ( 0.654)	Data  0.490 ( 0.556)	Loss 7.3479e-01 (7.6028e-01)	Acc@1 43.750000 (37.140289)
Epoch: [38][432/591]	Time  0.719 ( 0.654)	Data  0.622 ( 0.555)	Loss 7.5555e-01 (7.5858e-01)	Acc@1 56.250000 (37.269054)
Epoch: [38][448/591]	Time  0.685 ( 0.653)	Data  0.587 ( 0.555)	Loss 9.3243e-01 (7.6006e-01)	Acc@1 25.000000 (37.165924)
Epoch: [38][464/591]	Time  0.852 ( 0.656)	Data  0.755 ( 0.557)	Loss 6.4864e-01 (7.6289e-01)	Acc@1 56.250000 (37.016129)
Epoch: [38][480/591]	Time  0.607 ( 0.656)	Data  0.509 ( 0.557)	Loss 6.8033e-01 (7.6177e-01)	Acc@1 43.750000 (37.019230)
Epoch: [38][496/591]	Time  0.596 ( 0.655)	Data  0.498 ( 0.557)	Loss 7.4630e-01 (7.6075e-01)	Acc@1 25.000000 (37.047283)
Epoch: [38][512/591]	Time  0.571 ( 0.655)	Data  0.474 ( 0.557)	Loss 9.4031e-01 (7.6186e-01)	Acc@1 43.750000 (36.976120)
Epoch: [38][528/591]	Time  0.648 ( 0.654)	Data  0.550 ( 0.556)	Loss 8.2258e-01 (7.6146e-01)	Acc@1 37.500000 (37.145557)
Epoch: [38][544/591]	Time  0.616 ( 0.653)	Data  0.518 ( 0.555)	Loss 5.7282e-01 (7.6288e-01)	Acc@1 31.250000 (37.041286)
Epoch: [38][560/591]	Time  0.674 ( 0.655)	Data  0.577 ( 0.557)	Loss 9.8364e-01 (7.6354e-01)	Acc@1 12.500000 (37.065506)
Epoch: [38][576/591]	Time  0.725 ( 0.655)	Data  0.628 ( 0.557)	Loss 7.3236e-01 (7.6381e-01)	Acc@1 43.750000 (37.045059)
##################################################
train_loss:  0.763272910352084
train_acc:  tensor(37.0770, device='cuda:0')
##################################################
Best model was saved.
Epoch: [39][  0/591]	Time  0.676 ( 0.676)	Data  0.579 ( 0.579)	Loss 8.1358e-01 (8.1358e-01)	Acc@1 37.500000 (37.500000)
Epoch: [39][ 16/591]	Time  0.614 ( 0.644)	Data  0.517 ( 0.546)	Loss 9.6327e-01 (7.9504e-01)	Acc@1 43.750000 (37.132355)
Epoch: [39][ 32/591]	Time  0.647 ( 0.654)	Data  0.550 ( 0.556)	Loss 7.0776e-01 (7.8656e-01)	Acc@1 56.250000 (38.446972)
Epoch: [39][ 48/591]	Time  0.692 ( 0.654)	Data  0.571 ( 0.556)	Loss 7.9191e-01 (7.5468e-01)	Acc@1 56.250000 (38.647957)
Epoch: [39][ 64/591]	Time  0.583 ( 0.668)	Data  0.486 ( 0.570)	Loss 8.9217e-01 (7.5980e-01)	Acc@1 56.250000 (38.750000)
Epoch: [39][ 80/591]	Time  0.679 ( 0.663)	Data  0.581 ( 0.564)	Loss 6.5847e-01 (7.4803e-01)	Acc@1 50.000000 (38.580246)
Epoch: [39][ 96/591]	Time  0.594 ( 0.659)	Data  0.496 ( 0.560)	Loss 5.6733e-01 (7.5189e-01)	Acc@1 50.000000 (39.239689)
Epoch: [39][112/591]	Time  0.620 ( 0.661)	Data  0.523 ( 0.563)	Loss 8.4736e-01 (7.5836e-01)	Acc@1 43.750000 (39.823009)
Epoch: [39][128/591]	Time  0.599 ( 0.659)	Data  0.500 ( 0.560)	Loss 6.7227e-01 (7.6217e-01)	Acc@1 56.250000 (40.164730)
Epoch: [39][144/591]	Time  0.592 ( 0.661)	Data  0.495 ( 0.563)	Loss 1.0912e+00 (7.6689e-01)	Acc@1 37.500000 (40.086208)
Epoch: [39][160/591]	Time  0.623 ( 0.662)	Data  0.525 ( 0.564)	Loss 8.3889e-01 (7.6782e-01)	Acc@1 37.500000 (39.945652)
Epoch: [39][176/591]	Time  0.654 ( 0.662)	Data  0.556 ( 0.563)	Loss 7.2775e-01 (7.6883e-01)	Acc@1 31.250000 (39.689266)
Epoch: [39][192/591]	Time  0.641 ( 0.659)	Data  0.543 ( 0.561)	Loss 7.4509e-01 (7.7143e-01)	Acc@1 81.250000 (39.799221)
Epoch: [39][208/591]	Time  0.628 ( 0.657)	Data  0.531 ( 0.559)	Loss 4.7617e-01 (7.7079e-01)	Acc@1 56.250000 (40.251194)
Epoch: [39][224/591]	Time  0.608 ( 0.655)	Data  0.510 ( 0.556)	Loss 6.7896e-01 (7.7127e-01)	Acc@1 37.500000 (40.000000)
Epoch: [39][240/591]	Time  0.613 ( 0.657)	Data  0.516 ( 0.559)	Loss 5.9057e-01 (7.7193e-01)	Acc@1 43.750000 (39.989628)
Epoch: [39][256/591]	Time  0.604 ( 0.655)	Data  0.506 ( 0.557)	Loss 7.6322e-01 (7.6817e-01)	Acc@1 12.500000 (39.567120)
Epoch: [39][272/591]	Time  0.617 ( 0.655)	Data  0.520 ( 0.557)	Loss 7.7751e-01 (7.6517e-01)	Acc@1 25.000000 (39.423077)
Epoch: [39][288/591]	Time  0.672 ( 0.655)	Data  0.574 ( 0.557)	Loss 7.2493e-01 (7.6212e-01)	Acc@1 37.500000 (39.208477)
Epoch: [39][304/591]	Time  0.633 ( 0.654)	Data  0.535 ( 0.556)	Loss 5.3135e-01 (7.5871e-01)	Acc@1 43.750000 (39.057377)
Epoch: [39][320/591]	Time  0.676 ( 0.654)	Data  0.578 ( 0.556)	Loss 1.1004e+00 (7.5847e-01)	Acc@1 25.000000 (39.096573)
Epoch: [39][336/591]	Time  0.693 ( 0.656)	Data  0.596 ( 0.558)	Loss 8.4323e-01 (7.5682e-01)	Acc@1 43.750000 (39.113503)
Epoch: [39][352/591]	Time  0.657 ( 0.656)	Data  0.559 ( 0.558)	Loss 6.7257e-01 (7.5662e-01)	Acc@1 18.750000 (38.987251)
Epoch: [39][368/591]	Time  0.642 ( 0.656)	Data  0.545 ( 0.558)	Loss 5.3134e-01 (7.5673e-01)	Acc@1 31.250000 (38.804203)
Epoch: [39][384/591]	Time  0.623 ( 0.655)	Data  0.525 ( 0.557)	Loss 8.4206e-01 (7.5600e-01)	Acc@1 31.250000 (38.538960)
Epoch: [39][400/591]	Time  0.597 ( 0.654)	Data  0.500 ( 0.556)	Loss 6.9694e-01 (7.5541e-01)	Acc@1 50.000000 (38.513092)
Epoch: [39][416/591]	Time  0.942 ( 0.655)	Data  0.838 ( 0.557)	Loss 7.5828e-01 (7.5512e-01)	Acc@1 56.250000 (38.489208)
Epoch: [39][432/591]	Time  0.602 ( 0.655)	Data  0.505 ( 0.557)	Loss 6.5765e-01 (7.5424e-01)	Acc@1 56.250000 (38.265011)
Epoch: [39][448/591]	Time  0.633 ( 0.654)	Data  0.536 ( 0.556)	Loss 7.1370e-01 (7.5441e-01)	Acc@1 37.500000 (38.168152)
Epoch: [39][464/591]	Time  0.620 ( 0.654)	Data  0.523 ( 0.556)	Loss 6.9887e-01 (7.5283e-01)	Acc@1 31.250000 (38.145161)
Epoch: [39][480/591]	Time  0.613 ( 0.653)	Data  0.516 ( 0.555)	Loss 5.5748e-01 (7.5202e-01)	Acc@1 37.500000 (38.305614)
Epoch: [39][496/591]	Time  0.580 ( 0.653)	Data  0.482 ( 0.555)	Loss 5.7171e-01 (7.5292e-01)	Acc@1 31.250000 (38.392857)
Epoch: [39][512/591]	Time  0.623 ( 0.656)	Data  0.525 ( 0.558)	Loss 8.7303e-01 (7.5435e-01)	Acc@1 31.250000 (38.438110)
Epoch: [39][528/591]	Time  0.637 ( 0.656)	Data  0.539 ( 0.557)	Loss 6.8037e-01 (7.5499e-01)	Acc@1 50.000000 (38.468811)
Epoch: [39][544/591]	Time  0.629 ( 0.655)	Data  0.532 ( 0.557)	Loss 6.2206e-01 (7.5708e-01)	Acc@1 25.000000 (38.314220)
Epoch: [39][560/591]	Time  0.611 ( 0.655)	Data  0.514 ( 0.557)	Loss 6.4201e-01 (7.5662e-01)	Acc@1 31.250000 (38.268715)
Epoch: [39][576/591]	Time  0.634 ( 0.654)	Data  0.536 ( 0.556)	Loss 5.2674e-01 (7.5520e-01)	Acc@1 56.250000 (38.323223)
##################################################
train_loss:  0.7549272742872513
train_acc:  tensor(38.3672, device='cuda:0')
##################################################
Best model was saved.
Epoch: [40][  0/591]	Time  0.616 ( 0.616)	Data  0.512 ( 0.512)	Loss 5.7182e-01 (5.7182e-01)	Acc@1 18.750000 (18.750000)
Epoch: [40][ 16/591]	Time  0.756 ( 0.712)	Data  0.659 ( 0.611)	Loss 8.0529e-01 (7.4970e-01)	Acc@1 43.750000 (33.455883)
Epoch: [40][ 32/591]	Time  0.668 ( 0.668)	Data  0.570 ( 0.569)	Loss 7.4412e-01 (7.7558e-01)	Acc@1 31.250000 (36.174244)
Epoch: [40][ 48/591]	Time  0.610 ( 0.658)	Data  0.511 ( 0.559)	Loss 8.0036e-01 (7.6986e-01)	Acc@1 62.500000 (37.882652)
Epoch: [40][ 64/591]	Time  0.605 ( 0.654)	Data  0.508 ( 0.556)	Loss 7.0630e-01 (7.6901e-01)	Acc@1 56.250000 (37.115383)
Epoch: [40][ 80/591]	Time  0.652 ( 0.659)	Data  0.555 ( 0.561)	Loss 7.8748e-01 (7.6894e-01)	Acc@1 25.000000 (38.194447)
Epoch: [40][ 96/591]	Time  0.614 ( 0.654)	Data  0.517 ( 0.556)	Loss 8.1072e-01 (7.7291e-01)	Acc@1 43.750000 (38.659794)
Epoch: [40][112/591]	Time  0.619 ( 0.661)	Data  0.521 ( 0.563)	Loss 9.0330e-01 (7.6889e-01)	Acc@1 37.500000 (38.993362)
Epoch: [40][128/591]	Time  0.639 ( 0.658)	Data  0.542 ( 0.559)	Loss 5.4958e-01 (7.6572e-01)	Acc@1 43.750000 (39.098839)
Epoch: [40][144/591]	Time  0.599 ( 0.654)	Data  0.501 ( 0.556)	Loss 9.1075e-01 (7.5723e-01)	Acc@1 43.750000 (39.655170)
Epoch: [40][160/591]	Time  0.600 ( 0.653)	Data  0.503 ( 0.554)	Loss 6.4967e-01 (7.5345e-01)	Acc@1 43.750000 (39.673912)
Epoch: [40][176/591]	Time  0.624 ( 0.652)	Data  0.527 ( 0.554)	Loss 5.6076e-01 (7.5104e-01)	Acc@1 37.500000 (39.336159)
Epoch: [40][192/591]	Time  0.666 ( 0.659)	Data  0.569 ( 0.560)	Loss 4.1238e-01 (7.4494e-01)	Acc@1 62.500000 (39.734455)
Epoch: [40][208/591]	Time  0.603 ( 0.659)	Data  0.506 ( 0.560)	Loss 9.2981e-01 (7.5000e-01)	Acc@1 43.750000 (39.982056)
Epoch: [40][224/591]	Time  0.595 ( 0.656)	Data  0.497 ( 0.558)	Loss 7.8981e-01 (7.4911e-01)	Acc@1 18.750000 (39.527779)
Epoch: [40][240/591]	Time  0.608 ( 0.654)	Data  0.511 ( 0.556)	Loss 7.3392e-01 (7.5114e-01)	Acc@1 37.500000 (39.730293)
Epoch: [40][256/591]	Time  0.557 ( 0.652)	Data  0.460 ( 0.554)	Loss 5.6676e-01 (7.5225e-01)	Acc@1 50.000000 (39.640079)
Epoch: [40][272/591]	Time  0.620 ( 0.651)	Data  0.523 ( 0.553)	Loss 9.8637e-01 (7.5287e-01)	Acc@1 25.000000 (39.629120)
Epoch: [40][288/591]	Time  0.627 ( 0.657)	Data  0.530 ( 0.559)	Loss 6.6330e-01 (7.5433e-01)	Acc@1 37.500000 (39.251732)
Epoch: [40][304/591]	Time  0.661 ( 0.657)	Data  0.562 ( 0.559)	Loss 6.8100e-01 (7.5538e-01)	Acc@1 12.500000 (39.118851)
Epoch: [40][320/591]	Time  0.641 ( 0.656)	Data  0.544 ( 0.558)	Loss 1.1791e+00 (7.5838e-01)	Acc@1 6.250000 (38.882397)
Epoch: [40][336/591]	Time  0.593 ( 0.656)	Data  0.495 ( 0.558)	Loss 5.2066e-01 (7.5665e-01)	Acc@1 62.500000 (38.983681)
Epoch: [40][352/591]	Time  0.627 ( 0.654)	Data  0.529 ( 0.556)	Loss 9.0975e-01 (7.5843e-01)	Acc@1 37.500000 (38.686260)
Epoch: [40][368/591]	Time  0.637 ( 0.654)	Data  0.539 ( 0.556)	Loss 1.0954e+00 (7.6037e-01)	Acc@1 31.250000 (38.584011)
Epoch: [40][384/591]	Time  0.588 ( 0.656)	Data  0.491 ( 0.558)	Loss 1.0287e+00 (7.5876e-01)	Acc@1 25.000000 (38.571426)
Epoch: [40][400/591]	Time  0.626 ( 0.656)	Data  0.528 ( 0.558)	Loss 1.1133e+00 (7.5808e-01)	Acc@1 31.250000 (38.731297)
Epoch: [40][416/591]	Time  0.623 ( 0.656)	Data  0.525 ( 0.558)	Loss 8.1745e-01 (7.5806e-01)	Acc@1 37.500000 (38.714031)
Epoch: [40][432/591]	Time  0.636 ( 0.654)	Data  0.538 ( 0.556)	Loss 8.8829e-01 (7.5790e-01)	Acc@1 43.750000 (38.770206)
Epoch: [40][448/591]	Time  0.660 ( 0.654)	Data  0.563 ( 0.556)	Loss 7.7257e-01 (7.5789e-01)	Acc@1 50.000000 (38.808464)
Epoch: [40][464/591]	Time  0.791 ( 0.654)	Data  0.686 ( 0.556)	Loss 7.5034e-01 (7.5827e-01)	Acc@1 31.250000 (38.750000)
Epoch: [40][480/591]	Time  0.618 ( 0.655)	Data  0.520 ( 0.557)	Loss 6.9669e-01 (7.5765e-01)	Acc@1 12.500000 (38.682434)
Epoch: [40][496/591]	Time  0.645 ( 0.654)	Data  0.548 ( 0.556)	Loss 6.1735e-01 (7.5572e-01)	Acc@1 18.750000 (38.644363)
Epoch: [40][512/591]	Time  0.610 ( 0.654)	Data  0.512 ( 0.556)	Loss 8.9963e-01 (7.5387e-01)	Acc@1 37.500000 (38.608673)
Epoch: [40][528/591]	Time  0.630 ( 0.653)	Data  0.532 ( 0.555)	Loss 7.4904e-01 (7.5258e-01)	Acc@1 56.250000 (38.787807)
Epoch: [40][544/591]	Time  0.656 ( 0.652)	Data  0.556 ( 0.554)	Loss 5.0066e-01 (7.5235e-01)	Acc@1 37.500000 (38.715595)
Epoch: [40][560/591]	Time  1.075 ( 0.654)	Data  0.961 ( 0.556)	Loss 6.4149e-01 (7.5043e-01)	Acc@1 37.500000 (38.836899)
Epoch: [40][576/591]	Time  0.632 ( 0.654)	Data  0.535 ( 0.556)	Loss 6.2035e-01 (7.5025e-01)	Acc@1 56.250000 (38.951473)
##################################################
train_loss:  0.7487313710594339
train_acc:  tensor(38.8959, device='cuda:0')
##################################################
Best model was saved.
Epoch: [41][  0/591]	Time  0.615 ( 0.615)	Data  0.517 ( 0.517)	Loss 7.1493e-01 (7.1493e-01)	Acc@1 62.500000 (62.500000)
Epoch: [41][ 16/591]	Time  0.807 ( 0.683)	Data  0.710 ( 0.585)	Loss 7.5324e-01 (6.8813e-01)	Acc@1 50.000000 (40.073528)
Epoch: [41][ 32/591]	Time  0.625 ( 0.652)	Data  0.527 ( 0.555)	Loss 5.0980e-01 (6.8878e-01)	Acc@1 50.000000 (41.856060)
Epoch: [41][ 48/591]	Time  0.677 ( 0.657)	Data  0.580 ( 0.560)	Loss 7.2308e-01 (7.1106e-01)	Acc@1 43.750000 (40.178570)
Epoch: [41][ 64/591]	Time  0.675 ( 0.669)	Data  0.577 ( 0.572)	Loss 5.8394e-01 (7.4336e-01)	Acc@1 37.500000 (41.250000)
Epoch: [41][ 80/591]	Time  0.626 ( 0.661)	Data  0.527 ( 0.563)	Loss 7.4302e-01 (7.4758e-01)	Acc@1 50.000000 (39.814816)
Epoch: [41][ 96/591]	Time  0.601 ( 0.658)	Data  0.503 ( 0.560)	Loss 5.9209e-01 (7.5231e-01)	Acc@1 25.000000 (40.077320)
Epoch: [41][112/591]	Time  0.681 ( 0.652)	Data  0.583 ( 0.555)	Loss 4.9521e-01 (7.4871e-01)	Acc@1 43.750000 (40.542034)
Epoch: [41][128/591]	Time  0.694 ( 0.650)	Data  0.596 ( 0.552)	Loss 1.0219e+00 (7.5286e-01)	Acc@1 56.250000 (40.358528)
Epoch: [41][144/591]	Time  0.641 ( 0.646)	Data  0.544 ( 0.549)	Loss 5.9334e-01 (7.5231e-01)	Acc@1 25.000000 (39.913792)
Epoch: [41][160/591]	Time  0.616 ( 0.654)	Data  0.519 ( 0.556)	Loss 6.7900e-01 (7.5916e-01)	Acc@1 37.500000 (39.596275)
Epoch: [41][176/591]	Time  0.644 ( 0.651)	Data  0.546 ( 0.553)	Loss 6.8181e-01 (7.5557e-01)	Acc@1 43.750000 (39.194916)
Epoch: [41][192/591]	Time  0.635 ( 0.652)	Data  0.537 ( 0.554)	Loss 7.1979e-01 (7.5487e-01)	Acc@1 43.750000 (39.216320)
Epoch: [41][208/591]	Time  0.616 ( 0.649)	Data  0.518 ( 0.552)	Loss 7.2820e-01 (7.5575e-01)	Acc@1 56.250000 (39.503586)
Epoch: [41][224/591]	Time  0.650 ( 0.648)	Data  0.552 ( 0.551)	Loss 1.0152e+00 (7.5821e-01)	Acc@1 43.750000 (39.666668)
Epoch: [41][240/591]	Time  0.850 ( 0.648)	Data  0.745 ( 0.550)	Loss 6.4724e-01 (7.5954e-01)	Acc@1 37.500000 (39.782158)
Epoch: [41][256/591]	Time  0.586 ( 0.651)	Data  0.488 ( 0.553)	Loss 5.7861e-01 (7.5696e-01)	Acc@1 37.500000 (39.907589)
Epoch: [41][272/591]	Time  0.643 ( 0.650)	Data  0.546 ( 0.552)	Loss 8.0609e-01 (7.5700e-01)	Acc@1 31.250000 (39.835163)
Epoch: [41][288/591]	Time  0.627 ( 0.649)	Data  0.530 ( 0.552)	Loss 5.5638e-01 (7.5551e-01)	Acc@1 43.750000 (39.749138)
Epoch: [41][304/591]	Time  0.589 ( 0.650)	Data  0.491 ( 0.552)	Loss 7.0802e-01 (7.5549e-01)	Acc@1 56.250000 (39.815575)
Epoch: [41][320/591]	Time  0.657 ( 0.651)	Data  0.560 ( 0.553)	Loss 8.1800e-01 (7.5801e-01)	Acc@1 12.500000 (39.583332)
Epoch: [41][336/591]	Time  0.612 ( 0.653)	Data  0.514 ( 0.555)	Loss 8.2509e-01 (7.5488e-01)	Acc@1 25.000000 (39.558605)
Epoch: [41][352/591]	Time  0.613 ( 0.653)	Data  0.516 ( 0.555)	Loss 5.1896e-01 (7.5118e-01)	Acc@1 25.000000 (39.270538)
Epoch: [41][368/591]	Time  0.601 ( 0.653)	Data  0.504 ( 0.555)	Loss 4.8792e-01 (7.5155e-01)	Acc@1 43.750000 (39.430897)
Epoch: [41][384/591]	Time  0.626 ( 0.652)	Data  0.529 ( 0.554)	Loss 7.6238e-01 (7.5320e-01)	Acc@1 31.250000 (39.188313)
Epoch: [41][400/591]	Time  0.613 ( 0.652)	Data  0.516 ( 0.554)	Loss 7.1193e-01 (7.5350e-01)	Acc@1 31.250000 (39.276810)
Epoch: [41][416/591]	Time  0.637 ( 0.652)	Data  0.539 ( 0.555)	Loss 9.1308e-01 (7.5443e-01)	Acc@1 31.250000 (39.103718)
Epoch: [41][432/591]	Time  0.618 ( 0.654)	Data  0.520 ( 0.556)	Loss 8.7825e-01 (7.5328e-01)	Acc@1 18.750000 (39.030022)
Epoch: [41][448/591]	Time  0.658 ( 0.653)	Data  0.561 ( 0.555)	Loss 8.8433e-01 (7.5398e-01)	Acc@1 25.000000 (38.919823)
Epoch: [41][464/591]	Time  0.616 ( 0.652)	Data  0.519 ( 0.554)	Loss 9.3945e-01 (7.5473e-01)	Acc@1 37.500000 (38.844086)
Epoch: [41][480/591]	Time  0.657 ( 0.652)	Data  0.559 ( 0.554)	Loss 5.0715e-01 (7.5145e-01)	Acc@1 62.500000 (38.968296)
Epoch: [41][496/591]	Time  0.639 ( 0.652)	Data  0.542 ( 0.554)	Loss 5.8690e-01 (7.5229e-01)	Acc@1 43.750000 (38.795269)
Epoch: [41][512/591]	Time  0.605 ( 0.651)	Data  0.508 ( 0.553)	Loss 9.8118e-01 (7.5281e-01)	Acc@1 31.250000 (38.840157)
Epoch: [41][528/591]	Time  0.682 ( 0.652)	Data  0.584 ( 0.555)	Loss 5.0647e-01 (7.5254e-01)	Acc@1 43.750000 (38.858696)
Epoch: [41][544/591]	Time  0.626 ( 0.652)	Data  0.528 ( 0.554)	Loss 5.6878e-01 (7.4964e-01)	Acc@1 37.500000 (38.979359)
Epoch: [41][560/591]	Time  0.608 ( 0.651)	Data  0.511 ( 0.553)	Loss 8.8416e-01 (7.5073e-01)	Acc@1 31.250000 (38.937164)
Epoch: [41][576/591]	Time  0.611 ( 0.650)	Data  0.513 ( 0.552)	Loss 8.6641e-01 (7.5132e-01)	Acc@1 25.000000 (38.973137)
##################################################
train_loss:  0.7523501170972479
train_acc:  tensor(39.0440, device='cuda:0')
##################################################
Epoch: [42][  0/591]	Time  0.735 ( 0.735)	Data  0.638 ( 0.638)	Loss 7.4778e-01 (7.4778e-01)	Acc@1 37.500000 (37.500000)
Epoch: [42][ 16/591]	Time  0.976 ( 0.666)	Data  0.870 ( 0.566)	Loss 7.6433e-01 (7.2518e-01)	Acc@1 31.250000 (35.661766)
Epoch: [42][ 32/591]	Time  0.629 ( 0.686)	Data  0.532 ( 0.587)	Loss 7.0371e-01 (6.9370e-01)	Acc@1 43.750000 (37.500000)
Epoch: [42][ 48/591]	Time  0.613 ( 0.677)	Data  0.515 ( 0.578)	Loss 9.1456e-01 (7.0291e-01)	Acc@1 31.250000 (39.795918)
Epoch: [42][ 64/591]	Time  0.638 ( 0.663)	Data  0.541 ( 0.564)	Loss 9.0614e-01 (7.1774e-01)	Acc@1 31.250000 (40.769230)
Epoch: [42][ 80/591]	Time  0.622 ( 0.658)	Data  0.524 ( 0.559)	Loss 6.3938e-01 (7.3042e-01)	Acc@1 31.250000 (39.891975)
Epoch: [42][ 96/591]	Time  0.623 ( 0.658)	Data  0.525 ( 0.560)	Loss 6.5489e-01 (7.3220e-01)	Acc@1 31.250000 (39.690720)
Epoch: [42][112/591]	Time  0.584 ( 0.664)	Data  0.486 ( 0.566)	Loss 6.7764e-01 (7.3666e-01)	Acc@1 25.000000 (39.380531)
Epoch: [42][128/591]	Time  0.659 ( 0.661)	Data  0.561 ( 0.563)	Loss 9.9865e-01 (7.3669e-01)	Acc@1 50.000000 (39.050388)
Epoch: [42][144/591]	Time  0.578 ( 0.657)	Data  0.480 ( 0.558)	Loss 7.7481e-01 (7.4427e-01)	Acc@1 43.750000 (38.922413)
Epoch: [42][160/591]	Time  0.678 ( 0.655)	Data  0.580 ( 0.557)	Loss 9.9863e-01 (7.4226e-01)	Acc@1 50.000000 (39.363354)
Epoch: [42][176/591]	Time  0.653 ( 0.654)	Data  0.556 ( 0.555)	Loss 1.2361e+00 (7.4552e-01)	Acc@1 25.000000 (39.371468)
Epoch: [42][192/591]	Time  0.608 ( 0.653)	Data  0.511 ( 0.555)	Loss 7.0835e-01 (7.4290e-01)	Acc@1 43.750000 (39.540154)
Epoch: [42][208/591]	Time  0.587 ( 0.658)	Data  0.490 ( 0.560)	Loss 5.2821e-01 (7.4390e-01)	Acc@1 43.750000 (39.623203)
Epoch: [42][224/591]	Time  0.687 ( 0.657)	Data  0.590 ( 0.559)	Loss 7.9145e-01 (7.4694e-01)	Acc@1 50.000000 (39.944447)
Epoch: [42][240/591]	Time  0.687 ( 0.656)	Data  0.589 ( 0.558)	Loss 5.6106e-01 (7.4709e-01)	Acc@1 37.500000 (40.197098)
Epoch: [42][256/591]	Time  0.651 ( 0.655)	Data  0.553 ( 0.556)	Loss 8.4716e-01 (7.4898e-01)	Acc@1 31.250000 (39.956226)
Epoch: [42][272/591]	Time  0.742 ( 0.654)	Data  0.645 ( 0.556)	Loss 6.3899e-01 (7.4700e-01)	Acc@1 43.750000 (39.880951)
Epoch: [42][288/591]	Time  0.640 ( 0.654)	Data  0.542 ( 0.556)	Loss 9.0915e-01 (7.4873e-01)	Acc@1 37.500000 (39.943771)
Epoch: [42][304/591]	Time  0.652 ( 0.657)	Data  0.554 ( 0.559)	Loss 9.0674e-01 (7.4751e-01)	Acc@1 18.750000 (39.938526)
Epoch: [42][320/591]	Time  0.623 ( 0.656)	Data  0.526 ( 0.558)	Loss 6.1906e-01 (7.4669e-01)	Acc@1 56.250000 (39.875389)
Epoch: [42][336/591]	Time  0.605 ( 0.655)	Data  0.507 ( 0.557)	Loss 6.6489e-01 (7.4518e-01)	Acc@1 50.000000 (39.855343)
Epoch: [42][352/591]	Time  0.616 ( 0.655)	Data  0.518 ( 0.557)	Loss 7.5469e-01 (7.4732e-01)	Acc@1 31.250000 (39.660057)
Epoch: [42][368/591]	Time  0.638 ( 0.655)	Data  0.540 ( 0.557)	Loss 9.3629e-01 (7.4570e-01)	Acc@1 37.500000 (39.617210)
Epoch: [42][384/591]	Time  0.971 ( 0.656)	Data  0.866 ( 0.558)	Loss 8.4169e-01 (7.4542e-01)	Acc@1 31.250000 (39.642857)
Epoch: [42][400/591]	Time  0.627 ( 0.657)	Data  0.528 ( 0.559)	Loss 9.6819e-01 (7.4460e-01)	Acc@1 31.250000 (39.541771)
Epoch: [42][416/591]	Time  0.586 ( 0.657)	Data  0.488 ( 0.558)	Loss 7.9991e-01 (7.4300e-01)	Acc@1 25.000000 (39.433453)
Epoch: [42][432/591]	Time  0.738 ( 0.656)	Data  0.639 ( 0.558)	Loss 9.5384e-01 (7.4262e-01)	Acc@1 18.750000 (39.578522)
Epoch: [42][448/591]	Time  0.617 ( 0.656)	Data  0.519 ( 0.558)	Loss 8.5174e-01 (7.4176e-01)	Acc@1 31.250000 (39.560135)
Epoch: [42][464/591]	Time  0.627 ( 0.656)	Data  0.529 ( 0.558)	Loss 6.3046e-01 (7.3997e-01)	Acc@1 31.250000 (39.569893)
Epoch: [42][480/591]	Time  0.643 ( 0.658)	Data  0.545 ( 0.560)	Loss 7.3265e-01 (7.4064e-01)	Acc@1 31.250000 (39.449066)
Epoch: [42][496/591]	Time  0.731 ( 0.658)	Data  0.633 ( 0.560)	Loss 8.2113e-01 (7.4081e-01)	Acc@1 43.750000 (39.398891)
Epoch: [42][512/591]	Time  0.681 ( 0.658)	Data  0.583 ( 0.559)	Loss 6.6555e-01 (7.3857e-01)	Acc@1 18.750000 (39.364037)
Epoch: [42][528/591]	Time  0.679 ( 0.657)	Data  0.581 ( 0.559)	Loss 8.3266e-01 (7.3662e-01)	Acc@1 62.500000 (39.532139)
Epoch: [42][544/591]	Time  0.629 ( 0.656)	Data  0.531 ( 0.558)	Loss 8.0565e-01 (7.3585e-01)	Acc@1 31.250000 (39.587154)
Epoch: [42][560/591]	Time  0.612 ( 0.656)	Data  0.515 ( 0.558)	Loss 7.4199e-01 (7.3596e-01)	Acc@1 37.500000 (39.505348)
Epoch: [42][576/591]	Time  0.649 ( 0.658)	Data  0.551 ( 0.560)	Loss 5.4124e-01 (7.3611e-01)	Acc@1 43.750000 (39.352253)
##################################################
train_loss:  0.7369603956411332
train_acc:  tensor(39.2555, device='cuda:0')
##################################################
Best model was saved.
Epoch: [43][  0/591]	Time  1.039 ( 1.039)	Data  0.938 ( 0.938)	Loss 8.6972e-01 (8.6972e-01)	Acc@1 18.750000 (18.750000)
Epoch: [43][ 16/591]	Time  0.645 ( 0.654)	Data  0.547 ( 0.556)	Loss 6.5283e-01 (7.0901e-01)	Acc@1 37.500000 (37.500000)
Epoch: [43][ 32/591]	Time  0.641 ( 0.665)	Data  0.543 ( 0.567)	Loss 4.7851e-01 (7.3444e-01)	Acc@1 43.750000 (38.636364)
Epoch: [43][ 48/591]	Time  0.596 ( 0.655)	Data  0.499 ( 0.557)	Loss 7.3816e-01 (7.3946e-01)	Acc@1 43.750000 (39.413265)
Epoch: [43][ 64/591]	Time  0.955 ( 0.665)	Data  0.843 ( 0.567)	Loss 4.0604e-01 (7.3606e-01)	Acc@1 43.750000 (39.230770)
Epoch: [43][ 80/591]	Time  0.641 ( 0.660)	Data  0.544 ( 0.562)	Loss 6.0833e-01 (7.2721e-01)	Acc@1 31.250000 (39.274693)
Epoch: [43][ 96/591]	Time  0.697 ( 0.657)	Data  0.599 ( 0.558)	Loss 7.4395e-01 (7.2085e-01)	Acc@1 25.000000 (39.304123)
Epoch: [43][112/591]	Time  0.623 ( 0.654)	Data  0.525 ( 0.556)	Loss 6.7558e-01 (7.1701e-01)	Acc@1 31.250000 (39.380531)
Epoch: [43][128/591]	Time  0.591 ( 0.652)	Data  0.494 ( 0.554)	Loss 8.1919e-01 (7.1849e-01)	Acc@1 50.000000 (39.341084)
Epoch: [43][144/591]	Time  0.706 ( 0.649)	Data  0.608 ( 0.551)	Loss 9.8043e-01 (7.1921e-01)	Acc@1 18.750000 (39.396553)
Epoch: [43][160/591]	Time  0.632 ( 0.654)	Data  0.535 ( 0.556)	Loss 6.3439e-01 (7.1795e-01)	Acc@1 37.500000 (39.091614)
Epoch: [43][176/591]	Time  0.600 ( 0.654)	Data  0.502 ( 0.556)	Loss 6.2235e-01 (7.1676e-01)	Acc@1 31.250000 (38.947739)
Epoch: [43][192/591]	Time  0.590 ( 0.651)	Data  0.493 ( 0.553)	Loss 6.6049e-01 (7.1353e-01)	Acc@1 43.750000 (39.345856)
Epoch: [43][208/591]	Time  0.654 ( 0.650)	Data  0.556 ( 0.552)	Loss 7.3998e-01 (7.1218e-01)	Acc@1 50.000000 (38.875595)
Epoch: [43][224/591]	Time  0.594 ( 0.648)	Data  0.497 ( 0.550)	Loss 6.3074e-01 (7.1430e-01)	Acc@1 31.250000 (38.611111)
Epoch: [43][240/591]	Time  0.634 ( 0.648)	Data  0.537 ( 0.550)	Loss 7.0965e-01 (7.1432e-01)	Acc@1 37.500000 (38.433613)
Epoch: [43][256/591]	Time  0.591 ( 0.650)	Data  0.494 ( 0.552)	Loss 4.3124e-01 (7.1863e-01)	Acc@1 62.500000 (38.448444)
Epoch: [43][272/591]	Time  0.633 ( 0.649)	Data  0.536 ( 0.551)	Loss 5.7646e-01 (7.1772e-01)	Acc@1 50.000000 (38.438644)
Epoch: [43][288/591]	Time  0.607 ( 0.650)	Data  0.509 ( 0.552)	Loss 7.4118e-01 (7.1628e-01)	Acc@1 25.000000 (38.451557)
Epoch: [43][304/591]	Time  0.636 ( 0.649)	Data  0.539 ( 0.551)	Loss 6.0070e-01 (7.1646e-01)	Acc@1 37.500000 (38.381149)
Epoch: [43][320/591]	Time  0.577 ( 0.648)	Data  0.480 ( 0.550)	Loss 5.8073e-01 (7.1924e-01)	Acc@1 43.750000 (38.551399)
Epoch: [43][336/591]	Time  0.607 ( 0.648)	Data  0.510 ( 0.550)	Loss 7.0232e-01 (7.1857e-01)	Acc@1 31.250000 (38.594212)
Epoch: [43][352/591]	Time  0.576 ( 0.649)	Data  0.476 ( 0.551)	Loss 6.5472e-01 (7.1700e-01)	Acc@1 50.000000 (38.544617)
Epoch: [43][368/591]	Time  0.713 ( 0.650)	Data  0.615 ( 0.552)	Loss 6.3627e-01 (7.1637e-01)	Acc@1 56.250000 (38.668701)
Epoch: [43][384/591]	Time  0.639 ( 0.650)	Data  0.542 ( 0.552)	Loss 9.7319e-01 (7.1766e-01)	Acc@1 31.250000 (38.652596)
Epoch: [43][400/591]	Time  0.570 ( 0.650)	Data  0.473 ( 0.552)	Loss 1.0307e+00 (7.1882e-01)	Acc@1 50.000000 (38.996262)
Epoch: [43][416/591]	Time  0.575 ( 0.649)	Data  0.477 ( 0.551)	Loss 7.1511e-01 (7.2027e-01)	Acc@1 31.250000 (38.773983)
Epoch: [43][432/591]	Time  0.946 ( 0.649)	Data  0.841 ( 0.551)	Loss 7.4268e-01 (7.1859e-01)	Acc@1 37.500000 (38.784641)
Epoch: [43][448/591]	Time  0.618 ( 0.651)	Data  0.521 ( 0.553)	Loss 8.8790e-01 (7.1733e-01)	Acc@1 50.000000 (38.711025)
Epoch: [43][464/591]	Time  0.588 ( 0.650)	Data  0.491 ( 0.552)	Loss 1.4151e+00 (7.1858e-01)	Acc@1 25.000000 (38.776882)
Epoch: [43][480/591]	Time  0.684 ( 0.650)	Data  0.587 ( 0.552)	Loss 7.2698e-01 (7.1908e-01)	Acc@1 62.500000 (38.825363)
Epoch: [43][496/591]	Time  0.651 ( 0.650)	Data  0.553 ( 0.552)	Loss 8.4209e-01 (7.1895e-01)	Acc@1 18.750000 (38.757545)
Epoch: [43][512/591]	Time  0.651 ( 0.649)	Data  0.553 ( 0.551)	Loss 9.1721e-01 (7.1979e-01)	Acc@1 50.000000 (38.754875)
Epoch: [43][528/591]	Time  0.628 ( 0.651)	Data  0.530 ( 0.553)	Loss 7.6119e-01 (7.1980e-01)	Acc@1 31.250000 (38.811436)
Epoch: [43][544/591]	Time  0.597 ( 0.651)	Data  0.500 ( 0.553)	Loss 9.4569e-01 (7.1988e-01)	Acc@1 43.750000 (38.841743)
Epoch: [43][560/591]	Time  0.618 ( 0.650)	Data  0.521 ( 0.552)	Loss 7.7431e-01 (7.1992e-01)	Acc@1 68.750000 (38.970589)
Epoch: [43][576/591]	Time  0.652 ( 0.650)	Data  0.554 ( 0.552)	Loss 7.4243e-01 (7.2238e-01)	Acc@1 18.750000 (38.843155)
##################################################
train_loss:  0.7230007548622673
train_acc:  tensor(38.8113, device='cuda:0')
##################################################
Best model was saved.
Epoch: [44][  0/591]	Time  0.614 ( 0.614)	Data  0.517 ( 0.517)	Loss 9.0054e-01 (9.0054e-01)	Acc@1 31.250000 (31.250000)
Epoch: [44][ 16/591]	Time  0.598 ( 0.659)	Data  0.500 ( 0.561)	Loss 6.0165e-01 (7.3249e-01)	Acc@1 31.250000 (39.705883)
Epoch: [44][ 32/591]	Time  0.688 ( 0.688)	Data  0.591 ( 0.589)	Loss 6.9888e-01 (7.2284e-01)	Acc@1 18.750000 (39.015152)
Epoch: [44][ 48/591]	Time  0.598 ( 0.671)	Data  0.500 ( 0.573)	Loss 8.3370e-01 (7.2000e-01)	Acc@1 25.000000 (38.520409)
Epoch: [44][ 64/591]	Time  0.663 ( 0.665)	Data  0.566 ( 0.567)	Loss 7.0059e-01 (7.0695e-01)	Acc@1 43.750000 (39.423077)
Epoch: [44][ 80/591]	Time  0.644 ( 0.661)	Data  0.546 ( 0.563)	Loss 8.7855e-01 (7.2506e-01)	Acc@1 50.000000 (38.348766)
Epoch: [44][ 96/591]	Time  0.650 ( 0.660)	Data  0.553 ( 0.562)	Loss 9.0831e-01 (7.3193e-01)	Acc@1 31.250000 (39.368557)
Epoch: [44][112/591]	Time  0.948 ( 0.661)	Data  0.830 ( 0.563)	Loss 7.5907e-01 (7.3214e-01)	Acc@1 43.750000 (38.827435)
Epoch: [44][128/591]	Time  0.623 ( 0.664)	Data  0.525 ( 0.566)	Loss 9.7671e-01 (7.3397e-01)	Acc@1 37.500000 (39.244186)
Epoch: [44][144/591]	Time  0.589 ( 0.659)	Data  0.491 ( 0.561)	Loss 6.6666e-01 (7.2934e-01)	Acc@1 37.500000 (39.137932)
Epoch: [44][160/591]	Time  0.736 ( 0.659)	Data  0.638 ( 0.561)	Loss 8.9754e-01 (7.2806e-01)	Acc@1 37.500000 (39.130436)
Epoch: [44][176/591]	Time  0.703 ( 0.658)	Data  0.605 ( 0.560)	Loss 4.8633e-01 (7.2216e-01)	Acc@1 50.000000 (39.548023)
Epoch: [44][192/591]	Time  0.657 ( 0.655)	Data  0.560 ( 0.557)	Loss 5.4921e-01 (7.2100e-01)	Acc@1 25.000000 (39.572536)
Epoch: [44][208/591]	Time  0.585 ( 0.657)	Data  0.488 ( 0.559)	Loss 5.5338e-01 (7.1895e-01)	Acc@1 62.500000 (39.563396)
Epoch: [44][224/591]	Time  0.627 ( 0.655)	Data  0.529 ( 0.557)	Loss 7.5131e-01 (7.1736e-01)	Acc@1 37.500000 (39.500000)
Epoch: [44][240/591]	Time  0.602 ( 0.653)	Data  0.505 ( 0.555)	Loss 7.0967e-01 (7.1986e-01)	Acc@1 31.250000 (39.419090)
Epoch: [44][256/591]	Time  0.857 ( 0.652)	Data  0.760 ( 0.554)	Loss 6.6604e-01 (7.2252e-01)	Acc@1 31.250000 (39.250973)
Epoch: [44][272/591]	Time  0.636 ( 0.652)	Data  0.538 ( 0.554)	Loss 8.7077e-01 (7.2319e-01)	Acc@1 37.500000 (39.400185)
Epoch: [44][288/591]	Time  0.713 ( 0.653)	Data  0.616 ( 0.555)	Loss 4.5612e-01 (7.2223e-01)	Acc@1 43.750000 (39.294983)
Epoch: [44][304/591]	Time  0.647 ( 0.657)	Data  0.550 ( 0.558)	Loss 1.1007e+00 (7.2221e-01)	Acc@1 43.750000 (39.426231)
Epoch: [44][320/591]	Time  0.576 ( 0.655)	Data  0.479 ( 0.557)	Loss 9.7620e-01 (7.2388e-01)	Acc@1 50.000000 (39.408100)
Epoch: [44][336/591]	Time  0.598 ( 0.654)	Data  0.500 ( 0.556)	Loss 9.5809e-01 (7.2233e-01)	Acc@1 31.250000 (39.502968)
Epoch: [44][352/591]	Time  0.656 ( 0.654)	Data  0.558 ( 0.555)	Loss 6.0158e-01 (7.2272e-01)	Acc@1 50.000000 (39.624645)
Epoch: [44][368/591]	Time  0.679 ( 0.653)	Data  0.582 ( 0.555)	Loss 5.9115e-01 (7.2270e-01)	Acc@1 50.000000 (39.549458)
Epoch: [44][384/591]	Time  0.635 ( 0.652)	Data  0.537 ( 0.554)	Loss 7.7064e-01 (7.2409e-01)	Acc@1 50.000000 (39.480518)
Epoch: [44][400/591]	Time  0.618 ( 0.654)	Data  0.521 ( 0.556)	Loss 9.4172e-01 (7.2406e-01)	Acc@1 50.000000 (39.463840)
Epoch: [44][416/591]	Time  0.605 ( 0.653)	Data  0.508 ( 0.555)	Loss 8.9122e-01 (7.2691e-01)	Acc@1 37.500000 (39.358513)
Epoch: [44][432/591]	Time  0.722 ( 0.653)	Data  0.624 ( 0.554)	Loss 8.7659e-01 (7.2591e-01)	Acc@1 43.750000 (39.318707)
Epoch: [44][448/591]	Time  0.619 ( 0.653)	Data  0.521 ( 0.555)	Loss 7.2724e-01 (7.2648e-01)	Acc@1 37.500000 (39.462696)
Epoch: [44][464/591]	Time  0.659 ( 0.653)	Data  0.561 ( 0.555)	Loss 6.9385e-01 (7.2862e-01)	Acc@1 50.000000 (39.408604)
Epoch: [44][480/591]	Time  0.708 ( 0.653)	Data  0.611 ( 0.554)	Loss 1.1978e+00 (7.2947e-01)	Acc@1 37.500000 (39.436069)
Epoch: [44][496/591]	Time  0.616 ( 0.655)	Data  0.519 ( 0.556)	Loss 9.9175e-01 (7.2924e-01)	Acc@1 31.250000 (39.486919)
Epoch: [44][512/591]	Time  0.564 ( 0.654)	Data  0.467 ( 0.556)	Loss 7.9462e-01 (7.2845e-01)	Acc@1 37.500000 (39.315304)
Epoch: [44][528/591]	Time  0.572 ( 0.653)	Data  0.474 ( 0.555)	Loss 6.9347e-01 (7.2786e-01)	Acc@1 12.500000 (39.272213)
Epoch: [44][544/591]	Time  0.704 ( 0.653)	Data  0.606 ( 0.555)	Loss 7.0918e-01 (7.2744e-01)	Acc@1 25.000000 (39.036697)
Epoch: [44][560/591]	Time  0.660 ( 0.653)	Data  0.561 ( 0.555)	Loss 6.3273e-01 (7.2528e-01)	Acc@1 31.250000 (39.037434)
Epoch: [44][576/591]	Time  0.601 ( 0.654)	Data  0.504 ( 0.556)	Loss 9.0247e-01 (7.2404e-01)	Acc@1 43.750000 (39.038128)
##################################################
train_loss:  0.7236500154493626
train_acc:  tensor(39.0546, device='cuda:0')
##################################################
Epoch: [45][  0/591]	Time  0.612 ( 0.612)	Data  0.513 ( 0.513)	Loss 6.3751e-01 (6.3751e-01)	Acc@1 25.000000 (25.000000)
Epoch: [45][ 16/591]	Time  0.594 ( 0.634)	Data  0.496 ( 0.536)	Loss 6.7441e-01 (7.1219e-01)	Acc@1 68.750000 (39.705883)
Epoch: [45][ 32/591]	Time  0.625 ( 0.630)	Data  0.527 ( 0.532)	Loss 8.0324e-01 (7.2353e-01)	Acc@1 37.500000 (40.151516)
Epoch: [45][ 48/591]	Time  0.649 ( 0.632)	Data  0.549 ( 0.534)	Loss 6.5869e-01 (7.2209e-01)	Acc@1 56.250000 (40.943878)
Epoch: [45][ 64/591]	Time  0.676 ( 0.636)	Data  0.579 ( 0.538)	Loss 5.6355e-01 (7.2066e-01)	Acc@1 56.250000 (39.519230)
Epoch: [45][ 80/591]	Time  0.637 ( 0.652)	Data  0.539 ( 0.554)	Loss 6.9993e-01 (7.1669e-01)	Acc@1 31.250000 (39.043209)
Epoch: [45][ 96/591]	Time  0.618 ( 0.649)	Data  0.520 ( 0.551)	Loss 5.6983e-01 (7.1481e-01)	Acc@1 37.500000 (39.239689)
Epoch: [45][112/591]	Time  0.591 ( 0.645)	Data  0.494 ( 0.547)	Loss 6.8415e-01 (7.1932e-01)	Acc@1 37.500000 (38.274338)
Epoch: [45][128/591]	Time  0.615 ( 0.644)	Data  0.517 ( 0.546)	Loss 7.2163e-01 (7.2208e-01)	Acc@1 25.000000 (38.372093)
Epoch: [45][144/591]	Time  0.564 ( 0.644)	Data  0.467 ( 0.546)	Loss 5.8993e-01 (7.1925e-01)	Acc@1 43.750000 (38.491379)
Epoch: [45][160/591]	Time  0.618 ( 0.642)	Data  0.521 ( 0.544)	Loss 5.5152e-01 (7.1246e-01)	Acc@1 31.250000 (38.392857)
Epoch: [45][176/591]	Time  0.641 ( 0.646)	Data  0.544 ( 0.548)	Loss 6.3828e-01 (7.0538e-01)	Acc@1 43.750000 (38.559322)
Epoch: [45][192/591]	Time  0.617 ( 0.647)	Data  0.519 ( 0.549)	Loss 9.4138e-01 (7.0525e-01)	Acc@1 37.500000 (38.406734)
Epoch: [45][208/591]	Time  0.579 ( 0.646)	Data  0.482 ( 0.548)	Loss 6.4521e-01 (7.0653e-01)	Acc@1 56.250000 (38.576553)
Epoch: [45][224/591]	Time  0.583 ( 0.646)	Data  0.485 ( 0.548)	Loss 6.9647e-01 (7.0494e-01)	Acc@1 31.250000 (38.611111)
Epoch: [45][240/591]	Time  0.644 ( 0.648)	Data  0.546 ( 0.550)	Loss 6.6280e-01 (7.0593e-01)	Acc@1 50.000000 (38.822617)
Epoch: [45][256/591]	Time  0.673 ( 0.647)	Data  0.576 ( 0.549)	Loss 5.6126e-01 (7.0614e-01)	Acc@1 37.500000 (38.886189)
Epoch: [45][272/591]	Time  0.642 ( 0.653)	Data  0.545 ( 0.555)	Loss 6.7886e-01 (7.0553e-01)	Acc@1 43.750000 (38.759159)
Epoch: [45][288/591]	Time  0.621 ( 0.653)	Data  0.523 ( 0.555)	Loss 6.8602e-01 (7.0730e-01)	Acc@1 31.250000 (38.711075)
Epoch: [45][304/591]	Time  0.602 ( 0.653)	Data  0.505 ( 0.555)	Loss 7.0411e-01 (7.1014e-01)	Acc@1 25.000000 (38.463116)
Epoch: [45][320/591]	Time  0.642 ( 0.653)	Data  0.544 ( 0.555)	Loss 6.6115e-01 (7.0972e-01)	Acc@1 43.750000 (38.668224)
Epoch: [45][336/591]	Time  0.593 ( 0.653)	Data  0.496 ( 0.555)	Loss 5.9789e-01 (7.0641e-01)	Acc@1 31.250000 (38.668396)
Epoch: [45][352/591]	Time  0.636 ( 0.656)	Data  0.538 ( 0.558)	Loss 7.6573e-01 (7.1031e-01)	Acc@1 43.750000 (38.650848)
Epoch: [45][368/591]	Time  0.647 ( 0.655)	Data  0.549 ( 0.557)	Loss 1.0362e+00 (7.1235e-01)	Acc@1 43.750000 (38.533199)
Epoch: [45][384/591]	Time  0.584 ( 0.654)	Data  0.486 ( 0.556)	Loss 7.9428e-01 (7.1091e-01)	Acc@1 31.250000 (38.620129)
Epoch: [45][400/591]	Time  0.620 ( 0.654)	Data  0.522 ( 0.556)	Loss 8.6910e-01 (7.1271e-01)	Acc@1 31.250000 (38.575439)
Epoch: [45][416/591]	Time  0.612 ( 0.653)	Data  0.514 ( 0.555)	Loss 5.9518e-01 (7.1214e-01)	Acc@1 50.000000 (38.639091)
Epoch: [45][432/591]	Time  0.616 ( 0.654)	Data  0.519 ( 0.556)	Loss 6.8547e-01 (7.1194e-01)	Acc@1 50.000000 (38.698036)
Epoch: [45][448/591]	Time  0.604 ( 0.656)	Data  0.506 ( 0.558)	Loss 6.9654e-01 (7.1237e-01)	Acc@1 18.750000 (38.599667)
Epoch: [45][464/591]	Time  0.630 ( 0.655)	Data  0.533 ( 0.557)	Loss 8.3857e-01 (7.1301e-01)	Acc@1 43.750000 (38.669357)
Epoch: [45][480/591]	Time  0.645 ( 0.654)	Data  0.548 ( 0.556)	Loss 9.0578e-01 (7.1391e-01)	Acc@1 25.000000 (38.929314)
Epoch: [45][496/591]	Time  0.629 ( 0.653)	Data  0.531 ( 0.555)	Loss 5.7468e-01 (7.1203e-01)	Acc@1 37.500000 (38.958752)
Epoch: [45][512/591]	Time  0.629 ( 0.652)	Data  0.532 ( 0.554)	Loss 4.8517e-01 (7.1016e-01)	Acc@1 31.250000 (38.974171)
Epoch: [45][528/591]	Time  0.611 ( 0.651)	Data  0.512 ( 0.553)	Loss 7.3364e-01 (7.1120e-01)	Acc@1 37.500000 (38.976845)
Epoch: [45][544/591]	Time  0.614 ( 0.653)	Data  0.516 ( 0.555)	Loss 7.0478e-01 (7.1097e-01)	Acc@1 37.500000 (39.036697)
Epoch: [45][560/591]	Time  0.779 ( 0.653)	Data  0.681 ( 0.555)	Loss 3.8823e-01 (7.1064e-01)	Acc@1 43.750000 (39.070854)
Epoch: [45][576/591]	Time  0.617 ( 0.654)	Data  0.518 ( 0.555)	Loss 7.3104e-01 (7.1117e-01)	Acc@1 43.750000 (39.113953)
##################################################
train_loss:  0.7128152242166742
train_acc:  tensor(39.0228, device='cuda:0')
##################################################
Best model was saved.
Epoch: [46][  0/591]	Time  0.606 ( 0.606)	Data  0.508 ( 0.508)	Loss 8.8178e-01 (8.8178e-01)	Acc@1 12.500000 (12.500000)
Epoch: [46][ 16/591]	Time  0.639 ( 0.660)	Data  0.541 ( 0.562)	Loss 8.1775e-01 (7.4565e-01)	Acc@1 31.250000 (37.132355)
Epoch: [46][ 32/591]	Time  0.628 ( 0.683)	Data  0.529 ( 0.584)	Loss 6.7950e-01 (7.3451e-01)	Acc@1 18.750000 (36.742424)
Epoch: [46][ 48/591]	Time  0.661 ( 0.680)	Data  0.563 ( 0.581)	Loss 6.1363e-01 (7.3003e-01)	Acc@1 56.250000 (37.755100)
Epoch: [46][ 64/591]	Time  0.660 ( 0.671)	Data  0.563 ( 0.572)	Loss 7.3920e-01 (7.2383e-01)	Acc@1 31.250000 (38.653847)
Epoch: [46][ 80/591]	Time  0.636 ( 0.667)	Data  0.538 ( 0.568)	Loss 9.9841e-01 (7.2044e-01)	Acc@1 50.000000 (38.811729)
Epoch: [46][ 96/591]	Time  0.813 ( 0.663)	Data  0.715 ( 0.564)	Loss 5.9827e-01 (7.1817e-01)	Acc@1 56.250000 (38.724224)
Epoch: [46][112/591]	Time  0.659 ( 0.658)	Data  0.561 ( 0.559)	Loss 6.1992e-01 (7.1980e-01)	Acc@1 50.000000 (38.993362)
Epoch: [46][128/591]	Time  0.638 ( 0.664)	Data  0.539 ( 0.566)	Loss 7.6162e-01 (7.1848e-01)	Acc@1 25.000000 (38.953487)
Epoch: [46][144/591]	Time  0.621 ( 0.664)	Data  0.523 ( 0.565)	Loss 6.1829e-01 (7.1537e-01)	Acc@1 50.000000 (39.224136)
Epoch: [46][160/591]	Time  0.659 ( 0.663)	Data  0.562 ( 0.564)	Loss 8.3413e-01 (7.1474e-01)	Acc@1 31.250000 (39.246895)
Epoch: [46][176/591]	Time  0.663 ( 0.659)	Data  0.565 ( 0.561)	Loss 4.2915e-01 (7.0835e-01)	Acc@1 50.000000 (39.406780)
Epoch: [46][192/591]	Time  0.628 ( 0.659)	Data  0.530 ( 0.560)	Loss 7.1041e-01 (7.0756e-01)	Acc@1 75.000000 (39.702072)
Epoch: [46][208/591]	Time  0.625 ( 0.656)	Data  0.528 ( 0.557)	Loss 7.0609e-01 (7.0357e-01)	Acc@1 43.750000 (39.503586)
Epoch: [46][224/591]	Time  0.619 ( 0.660)	Data  0.521 ( 0.562)	Loss 6.4542e-01 (7.0332e-01)	Acc@1 50.000000 (39.777779)
Epoch: [46][240/591]	Time  0.649 ( 0.659)	Data  0.551 ( 0.561)	Loss 4.8765e-01 (7.0269e-01)	Acc@1 37.500000 (39.522823)
Epoch: [46][256/591]	Time  0.650 ( 0.657)	Data  0.552 ( 0.559)	Loss 7.4524e-01 (7.0161e-01)	Acc@1 37.500000 (39.348248)
Epoch: [46][272/591]	Time  0.717 ( 0.658)	Data  0.619 ( 0.560)	Loss 6.8645e-01 (7.0348e-01)	Acc@1 56.250000 (39.400185)
Epoch: [46][288/591]	Time  0.681 ( 0.657)	Data  0.583 ( 0.559)	Loss 7.2814e-01 (7.0290e-01)	Acc@1 31.250000 (39.316608)
Epoch: [46][304/591]	Time  0.875 ( 0.659)	Data  0.772 ( 0.561)	Loss 6.7816e-01 (7.0503e-01)	Acc@1 56.250000 (39.385246)
Epoch: [46][320/591]	Time  0.635 ( 0.661)	Data  0.537 ( 0.563)	Loss 4.8315e-01 (7.0376e-01)	Acc@1 50.000000 (39.641743)
Epoch: [46][336/591]	Time  0.752 ( 0.661)	Data  0.654 ( 0.563)	Loss 6.6105e-01 (7.0404e-01)	Acc@1 25.000000 (39.651337)
Epoch: [46][352/591]	Time  0.702 ( 0.660)	Data  0.604 ( 0.562)	Loss 6.6532e-01 (7.0529e-01)	Acc@1 37.500000 (39.660057)
Epoch: [46][368/591]	Time  0.625 ( 0.660)	Data  0.526 ( 0.561)	Loss 6.9589e-01 (7.0732e-01)	Acc@1 50.000000 (39.684959)
Epoch: [46][384/591]	Time  0.638 ( 0.659)	Data  0.540 ( 0.560)	Loss 6.2391e-01 (7.0736e-01)	Acc@1 37.500000 (39.772728)
Epoch: [46][400/591]	Time  0.747 ( 0.661)	Data  0.649 ( 0.563)	Loss 6.0516e-01 (7.0740e-01)	Acc@1 50.000000 (39.775562)
Epoch: [46][416/591]	Time  0.611 ( 0.661)	Data  0.514 ( 0.563)	Loss 7.2743e-01 (7.0728e-01)	Acc@1 56.250000 (39.688251)
Epoch: [46][432/591]	Time  0.644 ( 0.661)	Data  0.545 ( 0.563)	Loss 6.3982e-01 (7.0732e-01)	Acc@1 50.000000 (39.780602)
Epoch: [46][448/591]	Time  0.720 ( 0.661)	Data  0.620 ( 0.563)	Loss 6.5198e-01 (7.0573e-01)	Acc@1 43.750000 (39.810692)
Epoch: [46][464/591]	Time  0.705 ( 0.661)	Data  0.607 ( 0.563)	Loss 8.2386e-01 (7.0555e-01)	Acc@1 43.750000 (39.879032)
Epoch: [46][480/591]	Time  0.604 ( 0.661)	Data  0.506 ( 0.563)	Loss 5.2750e-01 (7.0448e-01)	Acc@1 50.000000 (39.929832)
Epoch: [46][496/591]	Time  0.689 ( 0.664)	Data  0.591 ( 0.566)	Loss 1.0575e+00 (7.0639e-01)	Acc@1 43.750000 (39.776157)
Epoch: [46][512/591]	Time  0.678 ( 0.664)	Data  0.580 ( 0.566)	Loss 7.3310e-01 (7.0607e-01)	Acc@1 37.500000 (39.814816)
Epoch: [46][528/591]	Time  0.604 ( 0.663)	Data  0.507 ( 0.565)	Loss 7.0632e-01 (7.0616e-01)	Acc@1 50.000000 (39.851135)
Epoch: [46][544/591]	Time  0.635 ( 0.662)	Data  0.537 ( 0.563)	Loss 6.2478e-01 (7.0771e-01)	Acc@1 50.000000 (40.011467)
Epoch: [46][560/591]	Time  0.634 ( 0.662)	Data  0.536 ( 0.564)	Loss 5.8284e-01 (7.0821e-01)	Acc@1 62.500000 (40.006683)
Epoch: [46][576/591]	Time  0.604 ( 0.663)	Data  0.506 ( 0.565)	Loss 9.6839e-01 (7.0912e-01)	Acc@1 25.000000 (39.969669)
##################################################
train_loss:  0.707789208330277
train_acc:  tensor(39.8794, device='cuda:0')
##################################################
Best model was saved.
Epoch: [47][  0/591]	Time  0.679 ( 0.679)	Data  0.582 ( 0.582)	Loss 6.5934e-01 (6.5934e-01)	Acc@1 43.750000 (43.750000)
Epoch: [47][ 16/591]	Time  0.721 ( 0.661)	Data  0.624 ( 0.563)	Loss 7.7335e-01 (6.5462e-01)	Acc@1 43.750000 (41.544117)
Epoch: [47][ 32/591]	Time  0.587 ( 0.648)	Data  0.490 ( 0.550)	Loss 4.7587e-01 (6.7092e-01)	Acc@1 50.000000 (41.098488)
Epoch: [47][ 48/591]	Time  0.608 ( 0.645)	Data  0.510 ( 0.548)	Loss 7.5621e-01 (6.8498e-01)	Acc@1 43.750000 (41.581631)
Epoch: [47][ 64/591]	Time  0.630 ( 0.640)	Data  0.533 ( 0.542)	Loss 1.0739e+00 (6.8827e-01)	Acc@1 37.500000 (41.538460)
Epoch: [47][ 80/591]	Time  0.605 ( 0.652)	Data  0.508 ( 0.554)	Loss 7.4851e-01 (6.8652e-01)	Acc@1 31.250000 (42.669754)
Epoch: [47][ 96/591]	Time  0.641 ( 0.647)	Data  0.544 ( 0.549)	Loss 5.7502e-01 (6.8977e-01)	Acc@1 56.250000 (42.332474)
Epoch: [47][112/591]	Time  0.614 ( 0.652)	Data  0.517 ( 0.554)	Loss 7.6334e-01 (6.9249e-01)	Acc@1 37.500000 (41.758850)
Epoch: [47][128/591]	Time  0.675 ( 0.648)	Data  0.578 ( 0.550)	Loss 7.4622e-01 (6.9324e-01)	Acc@1 18.750000 (41.230621)
Epoch: [47][144/591]	Time  0.622 ( 0.649)	Data  0.524 ( 0.551)	Loss 6.1029e-01 (6.9402e-01)	Acc@1 56.250000 (40.862068)
Epoch: [47][160/591]	Time  0.621 ( 0.650)	Data  0.524 ( 0.552)	Loss 5.9564e-01 (6.9958e-01)	Acc@1 43.750000 (40.256210)
Epoch: [47][176/591]	Time  0.611 ( 0.654)	Data  0.514 ( 0.556)	Loss 5.5198e-01 (7.0175e-01)	Acc@1 50.000000 (40.501411)
Epoch: [47][192/591]	Time  0.599 ( 0.653)	Data  0.502 ( 0.555)	Loss 8.3627e-01 (7.0107e-01)	Acc@1 43.750000 (40.479275)
Epoch: [47][208/591]	Time  0.638 ( 0.652)	Data  0.541 ( 0.554)	Loss 8.3445e-01 (7.0775e-01)	Acc@1 37.500000 (40.251194)
Epoch: [47][224/591]	Time  0.645 ( 0.650)	Data  0.548 ( 0.552)	Loss 6.0943e-01 (7.0507e-01)	Acc@1 12.500000 (40.250000)
Epoch: [47][240/591]	Time  0.633 ( 0.648)	Data  0.535 ( 0.551)	Loss 1.0491e+00 (7.0681e-01)	Acc@1 31.250000 (40.352699)
Epoch: [47][256/591]	Time  0.967 ( 0.649)	Data  0.862 ( 0.551)	Loss 5.1851e-01 (7.0948e-01)	Acc@1 18.750000 (40.345329)
Epoch: [47][272/591]	Time  0.578 ( 0.652)	Data  0.481 ( 0.554)	Loss 7.7758e-01 (7.0879e-01)	Acc@1 37.500000 (40.041210)
Epoch: [47][288/591]	Time  0.608 ( 0.651)	Data  0.511 ( 0.553)	Loss 5.3045e-01 (7.1296e-01)	Acc@1 43.750000 (40.268166)
Epoch: [47][304/591]	Time  0.626 ( 0.650)	Data  0.528 ( 0.552)	Loss 8.4978e-01 (7.1176e-01)	Acc@1 50.000000 (40.409836)
Epoch: [47][320/591]	Time  0.785 ( 0.650)	Data  0.687 ( 0.552)	Loss 5.5307e-01 (7.1206e-01)	Acc@1 50.000000 (40.459499)
Epoch: [47][336/591]	Time  0.645 ( 0.649)	Data  0.548 ( 0.551)	Loss 7.0813e-01 (7.1362e-01)	Acc@1 37.500000 (40.337536)
Epoch: [47][352/591]	Time  0.768 ( 0.653)	Data  0.671 ( 0.555)	Loss 7.7208e-01 (7.1634e-01)	Acc@1 37.500000 (40.138100)
Epoch: [47][368/591]	Time  0.608 ( 0.652)	Data  0.510 ( 0.554)	Loss 1.0247e+00 (7.1684e-01)	Acc@1 37.500000 (40.091465)
Epoch: [47][384/591]	Time  0.584 ( 0.651)	Data  0.486 ( 0.553)	Loss 6.5994e-01 (7.1657e-01)	Acc@1 50.000000 (40.048702)
Epoch: [47][400/591]	Time  0.659 ( 0.651)	Data  0.561 ( 0.553)	Loss 5.3914e-01 (7.1411e-01)	Acc@1 18.750000 (40.009354)
Epoch: [47][416/591]	Time  0.620 ( 0.650)	Data  0.521 ( 0.552)	Loss 7.4498e-01 (7.1467e-01)	Acc@1 37.500000 (39.898083)
Epoch: [47][432/591]	Time  0.586 ( 0.650)	Data  0.488 ( 0.552)	Loss 7.7540e-01 (7.1337e-01)	Acc@1 62.500000 (39.910507)
Epoch: [47][448/591]	Time  0.598 ( 0.653)	Data  0.500 ( 0.555)	Loss 4.8392e-01 (7.1451e-01)	Acc@1 31.250000 (39.908131)
Epoch: [47][464/591]	Time  0.607 ( 0.652)	Data  0.509 ( 0.554)	Loss 9.4830e-01 (7.1502e-01)	Acc@1 56.250000 (39.919357)
Epoch: [47][480/591]	Time  0.601 ( 0.652)	Data  0.504 ( 0.554)	Loss 6.2279e-01 (7.1506e-01)	Acc@1 50.000000 (39.968815)
Epoch: [47][496/591]	Time  0.632 ( 0.652)	Data  0.535 ( 0.554)	Loss 1.0675e+00 (7.1372e-01)	Acc@1 25.000000 (39.939636)
Epoch: [47][512/591]	Time  0.612 ( 0.651)	Data  0.515 ( 0.553)	Loss 7.2955e-01 (7.1275e-01)	Acc@1 37.500000 (40.009747)
Epoch: [47][528/591]	Time  0.645 ( 0.651)	Data  0.548 ( 0.553)	Loss 9.8823e-01 (7.1343e-01)	Acc@1 31.250000 (39.910210)
Epoch: [47][544/591]	Time  0.623 ( 0.653)	Data  0.525 ( 0.555)	Loss 4.1010e-01 (7.1202e-01)	Acc@1 62.500000 (39.885323)
Epoch: [47][560/591]	Time  0.609 ( 0.652)	Data  0.511 ( 0.554)	Loss 5.8186e-01 (7.1155e-01)	Acc@1 25.000000 (39.884136)
Epoch: [47][576/591]	Time  0.611 ( 0.651)	Data  0.513 ( 0.553)	Loss 6.1393e-01 (7.1124e-01)	Acc@1 43.750000 (39.926342)
##################################################
train_loss:  0.7108013099926176
train_acc:  tensor(40.0063, device='cuda:0')
##################################################
Epoch: [48][  0/591]	Time  0.695 ( 0.695)	Data  0.597 ( 0.597)	Loss 9.1226e-01 (9.1226e-01)	Acc@1 50.000000 (50.000000)
Epoch: [48][ 16/591]	Time  0.615 ( 0.672)	Data  0.517 ( 0.574)	Loss 5.6579e-01 (6.9456e-01)	Acc@1 18.750000 (38.970589)
Epoch: [48][ 32/591]	Time  0.976 ( 0.700)	Data  0.872 ( 0.602)	Loss 6.6019e-01 (6.6237e-01)	Acc@1 50.000000 (39.204548)
Epoch: [48][ 48/591]	Time  0.773 ( 0.698)	Data  0.675 ( 0.600)	Loss 6.1950e-01 (6.8398e-01)	Acc@1 50.000000 (39.413265)
Epoch: [48][ 64/591]	Time  0.668 ( 0.684)	Data  0.571 ( 0.586)	Loss 4.1814e-01 (6.9953e-01)	Acc@1 43.750000 (39.807693)
Epoch: [48][ 80/591]	Time  0.644 ( 0.673)	Data  0.546 ( 0.575)	Loss 7.2289e-01 (7.0372e-01)	Acc@1 31.250000 (40.740742)
Epoch: [48][ 96/591]	Time  0.631 ( 0.668)	Data  0.533 ( 0.570)	Loss 6.5756e-01 (7.1134e-01)	Acc@1 37.500000 (40.914948)
Epoch: [48][112/591]	Time  0.639 ( 0.662)	Data  0.541 ( 0.564)	Loss 9.8623e-01 (7.0635e-01)	Acc@1 18.750000 (41.261063)
Epoch: [48][128/591]	Time  0.672 ( 0.672)	Data  0.575 ( 0.574)	Loss 9.3144e-01 (7.0946e-01)	Acc@1 31.250000 (40.794575)
Epoch: [48][144/591]	Time  0.604 ( 0.670)	Data  0.506 ( 0.572)	Loss 6.1644e-01 (7.0991e-01)	Acc@1 25.000000 (40.818966)
Epoch: [48][160/591]	Time  0.630 ( 0.669)	Data  0.532 ( 0.571)	Loss 5.5557e-01 (7.1268e-01)	Acc@1 56.250000 (40.566772)
Epoch: [48][176/591]	Time  0.661 ( 0.667)	Data  0.564 ( 0.569)	Loss 6.1338e-01 (7.0772e-01)	Acc@1 31.250000 (40.501411)
Epoch: [48][192/591]	Time  0.649 ( 0.666)	Data  0.551 ( 0.568)	Loss 5.9439e-01 (7.0802e-01)	Acc@1 37.500000 (40.673573)
Epoch: [48][208/591]	Time  0.614 ( 0.665)	Data  0.517 ( 0.567)	Loss 7.5962e-01 (7.0741e-01)	Acc@1 18.750000 (40.520332)
Epoch: [48][224/591]	Time  0.630 ( 0.668)	Data  0.533 ( 0.570)	Loss 7.4755e-01 (7.0707e-01)	Acc@1 31.250000 (39.944447)
Epoch: [48][240/591]	Time  0.628 ( 0.665)	Data  0.531 ( 0.567)	Loss 7.0947e-01 (7.0590e-01)	Acc@1 25.000000 (39.678425)
Epoch: [48][256/591]	Time  0.696 ( 0.663)	Data  0.599 ( 0.565)	Loss 1.0709e+00 (7.1259e-01)	Acc@1 37.500000 (39.858948)
Epoch: [48][272/591]	Time  0.644 ( 0.661)	Data  0.547 ( 0.563)	Loss 1.0019e+00 (7.1369e-01)	Acc@1 37.500000 (39.926739)
Epoch: [48][288/591]	Time  0.637 ( 0.659)	Data  0.539 ( 0.561)	Loss 7.5295e-01 (7.1030e-01)	Acc@1 31.250000 (39.965401)
Epoch: [48][304/591]	Time  0.918 ( 0.659)	Data  0.812 ( 0.561)	Loss 5.0223e-01 (7.0891e-01)	Acc@1 43.750000 (39.979507)
Epoch: [48][320/591]	Time  0.655 ( 0.660)	Data  0.557 ( 0.562)	Loss 8.7475e-01 (7.1133e-01)	Acc@1 25.000000 (40.031151)
Epoch: [48][336/591]	Time  0.621 ( 0.659)	Data  0.522 ( 0.561)	Loss 5.5602e-01 (7.0996e-01)	Acc@1 37.500000 (40.077892)
Epoch: [48][352/591]	Time  0.602 ( 0.659)	Data  0.504 ( 0.561)	Loss 9.3602e-01 (7.1067e-01)	Acc@1 37.500000 (40.173512)
Epoch: [48][368/591]	Time  0.728 ( 0.659)	Data  0.630 ( 0.560)	Loss 6.2002e-01 (7.1119e-01)	Acc@1 37.500000 (40.057590)
Epoch: [48][384/591]	Time  0.593 ( 0.658)	Data  0.495 ( 0.560)	Loss 7.3052e-01 (7.1168e-01)	Acc@1 37.500000 (39.983765)
Epoch: [48][400/591]	Time  0.577 ( 0.659)	Data  0.479 ( 0.561)	Loss 9.6419e-01 (7.1239e-01)	Acc@1 43.750000 (40.243145)
Epoch: [48][416/591]	Time  0.591 ( 0.658)	Data  0.494 ( 0.560)	Loss 6.3835e-01 (7.1325e-01)	Acc@1 50.000000 (40.167866)
Epoch: [48][432/591]	Time  0.570 ( 0.657)	Data  0.473 ( 0.559)	Loss 4.5242e-01 (7.1181e-01)	Acc@1 50.000000 (40.213627)
Epoch: [48][448/591]	Time  0.667 ( 0.656)	Data  0.570 ( 0.558)	Loss 7.6695e-01 (7.1148e-01)	Acc@1 18.750000 (40.089088)
Epoch: [48][464/591]	Time  0.622 ( 0.655)	Data  0.524 ( 0.557)	Loss 8.7241e-01 (7.1292e-01)	Acc@1 31.250000 (40.336021)
Epoch: [48][480/591]	Time  0.636 ( 0.654)	Data  0.538 ( 0.556)	Loss 7.0957e-01 (7.1209e-01)	Acc@1 37.500000 (40.449585)
Epoch: [48][496/591]	Time  0.605 ( 0.656)	Data  0.508 ( 0.558)	Loss 5.3486e-01 (7.1279e-01)	Acc@1 31.250000 (40.379776)
Epoch: [48][512/591]	Time  0.600 ( 0.655)	Data  0.502 ( 0.557)	Loss 7.4452e-01 (7.1229e-01)	Acc@1 50.000000 (40.460526)
Epoch: [48][528/591]	Time  0.625 ( 0.654)	Data  0.527 ( 0.556)	Loss 6.0913e-01 (7.1157e-01)	Acc@1 56.250000 (40.500946)
Epoch: [48][544/591]	Time  0.631 ( 0.655)	Data  0.532 ( 0.557)	Loss 7.4331e-01 (7.1004e-01)	Acc@1 37.500000 (40.470184)
Epoch: [48][560/591]	Time  0.596 ( 0.654)	Data  0.499 ( 0.556)	Loss 7.6880e-01 (7.1126e-01)	Acc@1 18.750000 (40.597145)
Epoch: [48][576/591]	Time  0.650 ( 0.654)	Data  0.552 ( 0.556)	Loss 5.0945e-01 (7.1092e-01)	Acc@1 56.250000 (40.684574)
##################################################
train_loss:  0.710644436417094
train_acc:  tensor(40.6726, device='cuda:0')
##################################################
Epoch: [49][  0/591]	Time  0.607 ( 0.607)	Data  0.509 ( 0.509)	Loss 7.2388e-01 (7.2388e-01)	Acc@1 31.250000 (31.250000)
Epoch: [49][ 16/591]	Time  0.771 ( 0.635)	Data  0.673 ( 0.537)	Loss 4.6554e-01 (6.8705e-01)	Acc@1 68.750000 (41.544117)
Epoch: [49][ 32/591]	Time  0.756 ( 0.654)	Data  0.658 ( 0.556)	Loss 8.5237e-01 (6.8556e-01)	Acc@1 31.250000 (42.613636)
Epoch: [49][ 48/591]	Time  0.761 ( 0.652)	Data  0.663 ( 0.554)	Loss 6.5588e-01 (6.6791e-01)	Acc@1 37.500000 (41.581631)
Epoch: [49][ 64/591]	Time  0.658 ( 0.653)	Data  0.559 ( 0.555)	Loss 7.1618e-01 (6.9177e-01)	Acc@1 50.000000 (42.019230)
Epoch: [49][ 80/591]	Time  0.852 ( 0.650)	Data  0.715 ( 0.552)	Loss 9.4451e-01 (7.0186e-01)	Acc@1 31.250000 (41.975307)
Epoch: [49][ 96/591]	Time  0.644 ( 0.660)	Data  0.546 ( 0.561)	Loss 7.4774e-01 (7.0306e-01)	Acc@1 31.250000 (41.430412)
Epoch: [49][112/591]	Time  0.610 ( 0.654)	Data  0.512 ( 0.556)	Loss 5.8260e-01 (6.9985e-01)	Acc@1 37.500000 (41.426991)
Epoch: [49][128/591]	Time  0.683 ( 0.652)	Data  0.586 ( 0.554)	Loss 4.8970e-01 (7.1139e-01)	Acc@1 43.750000 (41.521317)
Epoch: [49][144/591]	Time  0.577 ( 0.651)	Data  0.480 ( 0.553)	Loss 5.3023e-01 (7.0820e-01)	Acc@1 62.500000 (41.637932)
Epoch: [49][160/591]	Time  0.603 ( 0.651)	Data  0.505 ( 0.553)	Loss 8.3209e-01 (7.1369e-01)	Acc@1 37.500000 (40.644409)
Epoch: [49][176/591]	Time  0.881 ( 0.656)	Data  0.783 ( 0.558)	Loss 4.3545e-01 (7.0998e-01)	Acc@1 43.750000 (40.783897)
Epoch: [49][192/591]	Time  0.652 ( 0.654)	Data  0.554 ( 0.556)	Loss 5.6128e-01 (7.0468e-01)	Acc@1 50.000000 (40.965023)
Epoch: [49][208/591]	Time  0.605 ( 0.652)	Data  0.508 ( 0.554)	Loss 8.5689e-01 (7.0629e-01)	Acc@1 37.500000 (40.938995)
Epoch: [49][224/591]	Time  0.650 ( 0.651)	Data  0.552 ( 0.553)	Loss 7.4539e-01 (7.0563e-01)	Acc@1 43.750000 (40.722221)
Epoch: [49][240/591]	Time  0.635 ( 0.649)	Data  0.536 ( 0.551)	Loss 6.3037e-01 (7.0337e-01)	Acc@1 18.750000 (40.689835)
Epoch: [49][256/591]	Time  0.591 ( 0.648)	Data  0.493 ( 0.550)	Loss 7.0361e-01 (7.0477e-01)	Acc@1 18.750000 (40.637161)
Epoch: [49][272/591]	Time  0.593 ( 0.652)	Data  0.496 ( 0.553)	Loss 6.8639e-01 (7.0434e-01)	Acc@1 31.250000 (40.796703)
Epoch: [49][288/591]	Time  0.659 ( 0.651)	Data  0.561 ( 0.553)	Loss 4.3004e-01 (7.0072e-01)	Acc@1 50.000000 (40.960209)
Epoch: [49][304/591]	Time  0.642 ( 0.651)	Data  0.545 ( 0.553)	Loss 9.3494e-01 (7.0266e-01)	Acc@1 31.250000 (41.024590)
Epoch: [49][320/591]	Time  0.593 ( 0.650)	Data  0.496 ( 0.552)	Loss 6.8376e-01 (7.0266e-01)	Acc@1 62.500000 (40.965733)
Epoch: [49][336/591]	Time  0.603 ( 0.651)	Data  0.505 ( 0.553)	Loss 8.2720e-01 (7.0084e-01)	Acc@1 50.000000 (40.727001)
Epoch: [49][352/591]	Time  0.672 ( 0.651)	Data  0.575 ( 0.553)	Loss 6.9917e-01 (7.0535e-01)	Acc@1 31.250000 (40.651558)
Epoch: [49][368/591]	Time  0.634 ( 0.652)	Data  0.536 ( 0.554)	Loss 6.5065e-01 (7.0696e-01)	Acc@1 37.500000 (40.396343)
Epoch: [49][384/591]	Time  0.562 ( 0.651)	Data  0.463 ( 0.553)	Loss 9.4244e-01 (7.0771e-01)	Acc@1 31.250000 (40.422077)
Epoch: [49][400/591]	Time  0.577 ( 0.650)	Data  0.480 ( 0.552)	Loss 7.3082e-01 (7.0582e-01)	Acc@1 37.500000 (40.274315)
Epoch: [49][416/591]	Time  0.724 ( 0.650)	Data  0.627 ( 0.552)	Loss 6.5382e-01 (7.0405e-01)	Acc@1 31.250000 (40.257793)
Epoch: [49][432/591]	Time  0.861 ( 0.650)	Data  0.763 ( 0.552)	Loss 6.7451e-01 (7.0302e-01)	Acc@1 50.000000 (40.415703)
Epoch: [49][448/591]	Time  0.596 ( 0.649)	Data  0.473 ( 0.551)	Loss 8.5322e-01 (7.0135e-01)	Acc@1 56.250000 (40.520603)
Epoch: [49][464/591]	Time  0.710 ( 0.652)	Data  0.612 ( 0.554)	Loss 8.4680e-01 (7.0162e-01)	Acc@1 62.500000 (40.591400)
Epoch: [49][480/591]	Time  0.674 ( 0.652)	Data  0.577 ( 0.553)	Loss 6.0410e-01 (7.0184e-01)	Acc@1 56.250000 (40.566528)
Epoch: [49][496/591]	Time  0.695 ( 0.651)	Data  0.598 ( 0.553)	Loss 1.0393e+00 (7.0367e-01)	Acc@1 18.750000 (40.530682)
Epoch: [49][512/591]	Time  0.622 ( 0.651)	Data  0.524 ( 0.553)	Loss 7.9060e-01 (7.0282e-01)	Acc@1 50.000000 (40.582359)
Epoch: [49][528/591]	Time  0.712 ( 0.651)	Data  0.614 ( 0.552)	Loss 7.9773e-01 (7.0309e-01)	Acc@1 37.500000 (40.654537)
Epoch: [49][544/591]	Time  0.690 ( 0.653)	Data  0.592 ( 0.555)	Loss 6.5444e-01 (7.0089e-01)	Acc@1 62.500000 (40.837154)
Epoch: [49][560/591]	Time  0.611 ( 0.654)	Data  0.513 ( 0.556)	Loss 7.8329e-01 (7.0118e-01)	Acc@1 37.500000 (40.920231)
Epoch: [49][576/591]	Time  0.602 ( 0.653)	Data  0.504 ( 0.555)	Loss 5.9286e-01 (7.0307e-01)	Acc@1 62.500000 (40.987869)
##################################################
train_loss:  0.7048793231371897
train_acc:  tensor(40.9264, device='cuda:0')
##################################################
Best model was saved.
Milestone 50 model was saved.
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.236 MB uploaded (0.000 MB deduped)wandb: \ 0.236 MB of 0.236 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Train Acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: Train Loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  Train Acc 40.9264
wandb: Train Loss 0.70488
wandb: 
wandb: Synced hopeful-jazz-7: https://wandb.ai/self-classifier/big_run/runs/s3zmgvxj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221122_145626-s3zmgvxj/logs
